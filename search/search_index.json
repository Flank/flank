{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Flank","text":"<p>Flank is a massively parallel Android and iOS test runner for Firebase Test Lab.</p> <p>Flank is YAML compatible with the gcloud CLI. Flank provides extra features to accelerate velocity and increase quality.</p>"},{"location":"#download","title":"Download","text":"<p>https://github.com/Flank/flank/releases/latest/download/flank.jar</p>"},{"location":"#contributing","title":"Contributing","text":"<ul> <li>Install JDK 15 (it works also correctly on the previous version, a newer version is not guaranteed to work properly):</li> <li>Oracle</li> <li>OpenJDK</li> <li>AdoptJDK</li> <li>Use JetBrains Toolbox to install <code>IntelliJ IDEA Community</code></li> <li>Clone the repo <code>git clone --recursive https://github.com/Flank/flank.git</code></li> <li><code>git submodule update --init --recursive</code> updates the submodules</li> <li>Open <code>build.gradle.kts</code> in the main Flank base directory with <code>IntelliJ IDEA Community</code>, this will open the entire Flank mono repo</li> <li>test runner contributions can be made in the <code>test_runner\\</code> subdirectory</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>Test sharding</li> <li>Cost reporting</li> <li>Stability testing</li> <li>HTML report</li> <li>JUnit XML report</li> <li>Smart Flank</li> </ul>"},{"location":"#exit-codes","title":"Exit Codes","text":"Exit code Description 0 All tests passed 1 A general failure occurred. Possible causes include: a filename that does not exist or an HTTP/network error. 2 Usually indicates missing or wrong usage of flags, incorrect parameters, errors in config files. 10 At least one matrix not finished (usually a FTL internal error) or unexpected error occurred. 15 Firebase Test Lab could not determine if the test matrix passed or failed, because of an unexpected error. 18 The test environment for this test execution is not supported because of incompatible test dimensions. This error might occur if the selected Android API level is not supported by the selected device type. 19 The test matrix was canceled by the user. 20 A test infrastructure error occurred."},{"location":"#cli","title":"CLI","text":"<p>Flank supports CLI flags for each YAML parameter. The CLI flags are useful to selectively override YAML file values. Pass the <code>--help</code> flag to see the full documentation. For example: <code>flank android run --help</code></p> <p>CLI flags work well with environment variables. You can override a value like this:</p> <p>flank android run --local-result-dir=$APP_NAME</p>"},{"location":"#flank-configuration","title":"Flank configuration","text":"<p>app, test, and xctestrun-file support <code>~</code>, environment variables, and globs (, *) when resolving paths</p>"},{"location":"#ios-example","title":"iOS example","text":"<p>Run <code>test_runner/flank.ios.yml</code> with flank to verify iOS execution is working.</p> <ul> <li><code>./gradlew clean test_runner:build test_runner:shadowJar</code></li> <li><code>java -jar ./test_runner/build/libs/flank-*.jar firebase test ios run</code></li> </ul> <pre><code># gcloud args match the official gcloud cli\n# https://cloud.google.com/sdk/gcloud/reference/alpha/firebase/test/ios/run\ngcloud:\n  # -- GcloudYml --\n\n  ### Results Bucket\n  ## The name of a Google Cloud Storage bucket where raw test results will be stored\n  # results-bucket: tmp_flank\n\n  ### Results Directory\n  ## The name of a unique Google Cloud Storage object within the results bucket where raw test results will be stored\n  ## (default: a timestamp with a random suffix). \n  # results-dir: tmp # Caution: this argument must be unique for each test matrix you create, otherwise results from multiple test matrices will be overwritten or intermingled, using \"tmp\" will not be unique.\n\n  ### Record Video flag\n  ## Enable video recording during the test. Disabled by default. Use --record-video to enable.\n  # record-video: true\n\n  ### Timeout\n  ## The max time this test execution can run before it is cancelled (default: 15m).\n  ## It does not include any time necessary to prepare and clean up the target device.\n  ## The maximum possible testing time is 45m on physical devices and 60m on virtual devices.\n  ## The TIMEOUT units can be h, m, or s. If no unit is given, seconds are assumed.\n  # timeout: 30m\n\n  ### Asynchronous flag\n  ## Invoke a test asynchronously without waiting for test results.\n  # async: false\n\n  ### Client Details\n  ## A key-value map of additional details to attach to the test matrix.\n  ## Arbitrary key-value pairs may be attached to a test matrix to provide additional context about the tests being run.\n  ## When consuming the test results, such as in Cloud Functions or a CI system,\n  ## these details can add additional context such as a link to the corresponding pull request.\n  # client-details\n  #   key1: value1\n  #   key2: value2\n\n  ### Network Profile\n  ## The name of the network traffic profile, for example LTE, HSPA, etc,\n  ## which consists of a set of parameters to emulate network conditions when running the test\n  ## (default: no network shaping; see available profiles listed by the `flank test network-profiles list` command).\n  ## This feature only works on physical devices.\n  # network-profile: LTE\n\n  ### Result History Name\n  ## The history name for your test results (an arbitrary string label; default: the application's label from the APK manifest).\n  ## All tests which use the same history name will have their results grouped together in the Firebase console in a time-ordered test history list.\n  # results-history-name: android-history\n\n  ### Number of Flaky Test Attempts\n  ## The number of times a TestExecution should be re-attempted if one or more\\nof its test cases fail for any reason.\n  ## The maximum number of reruns allowed is 10. Default is 0, which implies no reruns.\n  # num-flaky-test-attempts: 0\n\n  ### Fail Fast\n  ## If true, only a single attempt at most will be made to run each execution/shard in the matrix.\n  ## Flaky test attempts are not affected. Normally, 2 or more attempts are made if a potential\n  ## infrastructure issue is detected. This feature is for latency sensitive workloads. The\n  ## incidence of execution failures may be significantly greater for fail-fast matrices and support\n  ## is more limited because of that expectation.\n  # fail-fast: false\n\n  # -- IosGcloudYml --\n\n  ### IOS Test Package Path\n  ## The path to the test package (a zip file containing the iOS app and XCTest files).\n  ## The given path may be in the local filesystem or in Google Cloud Storage using a URL beginning with gs://.\n  ## Note: any .xctestrun file in this zip file will be ignored if --xctestrun-file is specified.\n  test: ./src/test/kotlin/ftl/fixtures/tmp/earlgrey_example.zip\n\n  ### IOS XCTestrun File Path\n  ## The path to an .xctestrun file that will override any .xctestrun file contained in the --test package.\n  ## Because the .xctestrun file contains environment variables along with test methods to run and/or ignore,\n  ## this can be useful for customizing or sharding test suites. The given path should be in the local filesystem.\n  ## Note: this path should usually be pointing to the xctestrun file within the derived data folder\n  ## For example ./derivedDataPath/Build/Products/EarlGreyExampleSwiftTests_iphoneos13.4-arm64e.xctestrun\n  xctestrun-file: ./src/test/kotlin/ftl/fixtures/tmp/EarlGreyExampleSwiftTests_iphoneos13.4-arm64e.xctestrun\n\n  ### Xcode Version\n  ## The version of Xcode that should be used to run an XCTest.\n  ## Defaults to the latest Xcode version supported in Firebase Test Lab.\n  ## This Xcode version must be supported by all iOS versions selected in the test matrix.\n  # xcode-version: 10.1\n\n  ### IOS Device Parameters\n  ## A list of DIMENSION=VALUE pairs which specify a target device to test against.\n  ## This flag may be repeated to specify multiple devices.\n  ## The four device dimensions are: model, version, locale, and orientation.\n  # device:\n  #  - model: iphone13pro\n  #   version: 15.7\n  #   locale: en\n  #   orientation: portrait\n  # - model: iphonex\n  #   version: 12.0\n  #   locale: es_ES\n  #   orientation: landscape\n\n  ### Directories to Pull\n  ## A list of paths that will be copied from the device's storage to the designated results bucket after the test\n  ## is complete. These must be absolute paths under /private/var/mobile/Media or /Documents\n  ## of the app under test. If the path is under an app's /Documents, it must be prefixed with the app's bundle id and a colon\n  # directories-to-pull:\n  #   - /private/var/mobile/Media\n\n  ### Other File paths\n  ## A list of device-path=file-path pairs that specify the paths of the test device and the files you want pushed to the device prior to testing.\n  ## Device paths should either be under the Media shared folder (e.g. prefixed with /private/var/mobile/Media) or\n  ## within the documents directory of the filesystem of an app under test (e.g. /Documents). Device paths to app\n  ## filesystems should be prefixed by the bundle ID and a colon. Source file paths may be in the local filesystem or in Google Cloud Storage (gs://\u2026).\n  # other-files\n  #   com.my.app:/Documents/file.txt: local/file.txt\n  #   /private/var/mobile/Media/file.jpg: gs://bucket/file.jpg\n\n  ### Additional IPA's\n  ## List of up to 100 additional IPAs to install, in addition to the one being directly tested.\n  ## The path may be in the local filesystem or in Google Cloud Storage using gs:// notation.\n  # additional-ipas:\n  #   - gs://bucket/additional.ipa\n  #   - path/to/local/ipa/file.ipa\n\n  ### Scenario Numbers\n  ## A list of game-loop scenario numbers which will be run as part of the test (default: all scenarios).\n  ## A maximum of 1024 scenarios may be specified in one test matrix, but the maximum number may also be limited by the overall test --timeout setting.\n  # scenario-numbers:\n  #   - 1\n  #   - 2\n  #   - 3\n\n  ### Test type\n  ## The type of iOS test to run. TYPE must be one of: xctest, game-loop. Default: xctest\n  # type: xctest\n\n  ### Application Path\n  ## The path to the application archive (.ipa file) for game-loop testing.\n  ## The path may be in the local filesystem or in Google Cloud Storage using gs:// notation.\n  ## This flag is only valid when --type=game-loop is also set\n  # app:\n  #  - gs://bucket/additional.ipa OR path/to/local/ipa/file.ipa\n\n  ### Testing with Special Entitlements\n  ## Enables testing special app entitlements. Re-signs an app having special entitlements with a new application-identifier.\n  ## This currently supports testing Push Notifications (aps-environment) entitlement for up to one app in a project.\n  ## Note: Because this changes the app's identifier, make sure none of the resources in your zip file contain direct references to the test app's bundle id.\n  # test-special-entitlements: false\n\nflank:\n  # -- FlankYml --\n\n  ### Max Test Shards\n  ## test shards - the amount of groups to split the test suite into\n  ## set to -1 to use one shard per test. default: 1\n  # max-test-shards: 1\n\n  ## Shard Time\n  ## shard time - the amount of time tests within a shard should take\n  ## when set to &gt; 0, the shard count is dynamically set based on time up to the maximum limit defined by max-test-shards\n  ## 2 minutes (120) is recommended.\n  ## default: -1 (unlimited)\n  # shard-time: -1\n\n  ### Number of Test Runs\n  ## test runs - the amount of times to run the tests.\n  ## 1 runs the tests once. 10 runs all the tests 10x\n  # num-test-runs: 1\n\n  ### Smart Flank GCS Paths\n  ## Google cloud storage path to store the JUnit XML results from the last run.\n  ## NOTE: Empty results will not be uploaded\n  # smart-flank-gcs-path: gs://tmp_flank/flank/test_app_ios.xml\n\n  ### Smart Flank Disable Upload flag\n  ## Disables smart flank JUnit XML uploading. Useful for preventing timing data from being updated.\n  ## Default: false\n  # smart-flank-disable-upload: false\n\n  ### Use Average Test Time For New Tests flag\n  ## Enable using average time from previous tests duration when using SmartShard and tests did not run before.\n  ## Default: false\n  # use-average-test-time-for-new-tests: true\n\n  ### Default Test Time\n  ## Set default test time used for calculating shards.\n  ## Default: 120.0\n  # default-test-time: 15\n\n  ### Default Class Test Time\n  ## Set default test time (in seconds) used for calculating shards of parametrized classes when previous tests results are not available.\n  ## Default test time for classes should be different from the default time for test\n  ## Default: 240.0\n  # default-class-test-time: 30\n\n  ### Disable Sharding flag\n  ## Disables sharding. Useful for parameterized tests.\n  # disable-sharding: false\n\n  ### Test targets always Run\n  ## always run - these tests are inserted at the beginning of every shard\n  ## Execution order is not guaranteed by Flank. Users are responsible for configuring their own device test runner logic.\n  # test-targets-always-run:\n  #   - className/testName\n\n  ### Files to Download\n  ## regex is matched against bucket paths, for example: 2019-01-09_00:18:07.314000_hCMY/shard_0/EarlGreyExampleSwiftTests_iphoneos12.1-arm64e.xctestrun\n  # files-to-download:\n  #   - .*\\.mp4$\n\n  # -- IosFlankYml --\n\n  ### Test Targets\n  ## test targets - a list of tests to run. omit to run all tests.\n  # test-targets:\n  #   - className/testName\n\n  ### Billing Project ID\n  ## The billing enabled Google Cloud Platform project id to use\n  # project: ftl-flank-open-source\n\n  ### Local Result Directory Storage\n  ## Local folder to store the test result. Folder is DELETED before each run to ensure only artifacts from the new run are saved.\n  # local-result-dir: flank\n\n  ### Run Timeout\n  ## The max time this test run can execute before it is cancelled (default: unlimited).\n  # run-timeout: 60m\n\n  ### Keep File Path flag\n  ## Keeps the full path of downloaded files. Required when file names are not unique.\n  ## Default: false\n  # keep-file-path: false\n\n  ### Ignore Failed Tests flag\n  ## Terminate with exit code 0 when there are failed tests.\n  ## Useful for Fladle and other gradle plugins that don't expect the process to have a non-zero exit code.\n  ## The JUnit XML is used to determine failure. (default: false)\n  # ignore-failed-tests: true\n\n  ### Output Style flag\n  ## Output style of execution status. May be one of [verbose, multi, single, compact].\n  ## For runs with only one test execution the default value is 'verbose', in other cases\n  ## 'multi' is used as the default. The output style 'multi' is not displayed correctly on consoles\n  ## which don't support ansi codes, to avoid corrupted output use single or verbose.\n  ## The output style `compact` is used to produce less detailed output, it prints just Args, test and matrix count, weblinks, cost, and result reports.\n  # output-style: single\n\n  ### Full Junit Result flag\n  ## Enable create additional local junit result on local storage with failure nodes on passed flaky tests.\n  # full-junit-result: false\n\n  ### Disable Result Upload flag\n  ## Disables flank results upload on gcloud storage.\n  ## Default: false\n  # disable-results-upload: false\n\n  ### Disable usage statistics flag\n  ## Disable sending usage statistics (without sensitive data) to the analytic tool.\n  ## Default: false\n  # disable-usage-statistics: false\n\n  ### Only Test Configuration\n  ## Constrains a test action to only test a specified test configuration within a test plan and exclude all other test configurations.\n  ## Flank can combine multiple constraint options, but -only-test-configuration has precedence over -skip-test-configuration.\n  ## Each test configuration name must match the name of a configuration specified in a test plan and is case-sensitive.\n  ## Default: null (run all test configurations)\n  # only-test-configuration: en\n\n  ### Skip Test Configuration\n  ## Constrains a test action to skip a specified test configuration and include all other test configurations.\n  ## Flank can combine multiple constraint options, but -only-test-configuration has precedence over -skip-test-configuration.\n  ## Each test configuration name must match the name of a configuration specified in a test plan and is case-sensitive.\n  ## Default: null (run all test configurations)\n  # skip-test-configuration: en\n\n ### Enable output report with set type\n ## Saves output results as parsable file and optionally upload it to Gcloud..\n ## Default: none\n # output-report: none\n\n ### Disable config validation (for both, yml and command line)\n ## If true, Flank won't validate options provided by the user. In general, it's not a good idea but,\n ## there are cases when this could be useful for a user\n ## (example: project can use devices that are not commonly available, the project has higher sharding limits, etc).\n ## Default: false\n # skip-config-validation: false\n\n ### Path to the custom sharding JSON file\n ## Flank will apply provided sharding to the configuration.\n ## For detailed explanation please check https://github.com/Flank/flank/blob/master/docs/feature/1665-custom-sharding.md\n # custom-sharding-json: ./custom_sharding.json\n</code></pre>"},{"location":"#android-example","title":"Android example","text":"<p>Run <code>test_runner/flank.yml</code> with flank to verify Android execution is working.</p> <ul> <li><code>./gradlew clean test_runner:build test_runner:shadowJar</code></li> <li><code>java -jar ./test_runner/build/libs/flank-*.jar firebase test android run</code></li> </ul> <pre><code># gcloud args match the official gcloud cli\n# See the docs for full gcloud details https://cloud.google.com/sdk/gcloud/reference/firebase/test/android/run\ngcloud:\n  # -- GcloudYml --\n\n  ### Result Bucket\n  ## The name of a Google Cloud Storage bucket where raw test results will be stored\n  # results-bucket: tmp_flank\n\n  ### Result Directory\n  ## The name of a unique Google Cloud Storage object within the results bucket where raw test results will be stored\n  ## (default: a timestamp with a random suffix).\n  # results-dir: tmp\n\n  ### Record Video flag\n  ## Enable video recording during the test. Disabled by default. Use --record-video to enable.\n  # record-video: true\n\n  ### Timeout\n  ## The max time this test execution can run before it is cancelled (default: 15m).\n  ## It does not include any time necessary to prepare and clean up the target device.\n  ## The maximum possible testing time is 45m on physical devices and 60m on virtual devices.\n  ## The TIMEOUT units can be h, m, or s. If no unit is given, seconds are assumed.\n  # timeout: 30m\n\n  ### Asynchronous flag\n  ## Invoke a test asynchronously without waiting for test results.\n  # async: false\n\n  ### Client Details\n  ## A key-value map of additional details to attach to the test matrix.\n  ## Arbitrary key-value pairs may be attached to a test matrix to provide additional context about the tests being run.\n  ## When consuming the test results, such as in Cloud Functions or a CI system,\n  ## these details can add additional context such as a link to the corresponding pull request.\n  # client-details\n  #   key1: value1\n  #   key2: value2\n\n  ### Network Profile\n  ## The name of the network traffic profile, for example LTE, HSPA, etc,\n  ## which consists of a set of parameters to emulate network conditions when running the test\n  ## (default: no network shaping; see available profiles listed by the `flank test network-profiles list` command).\n  ## This feature only works on physical devices.\n  # network-profile: LTE\n\n  ### Result History Name\n  ## The history name for your test results (an arbitrary string label; default: the application's label from the APK manifest).\n  ## All tests which use the same history name will have their results grouped together in the Firebase console in a time-ordered test history list.\n  # results-history-name: android-history\n\n  ### Number of Flaky Test Attempts\n  ## The number of times a TestExecution should be re-attempted if one or more\\nof its test cases fail for any reason.\n  ## The maximum number of reruns allowed is 10. Default is 0, which implies no reruns.\n  # num-flaky-test-attempts: 0\n\n  ### Fail Fast\n  ## If true, only a single attempt at most will be made to run each execution/shard in the matrix.\n  ## Flaky test attempts are not affected. Normally, 2 or more attempts are made if a potential\n  ## infrastructure issue is detected. This feature is for latency sensitive workloads. The\n  ## incidence of execution failures may be significantly greater for fail-fast matrices and support\n  ## is more limited because of that expectation.\n  # fail-fast: false\n\n  # -- AndroidGcloudYml --\n\n  ## Android Application Path\n  ## The path to the application binary file.\n  ## The path may be in the local filesystem or in Google Cloud Storage using gs:// notation.\n  ## Android App Bundles are specified as .aab, all other files are assumed to be APKs.\n  app: ../test_projects/android/apks/app-debug.apk\n\n  ### Android Binary File Path\n  ## The path to the binary file containing instrumentation tests.\n  ## The given path may be in the local filesystem or in Google Cloud Storage using a URL beginning with gs://.\n  test: ../test_projects/android/apks/app-debug-androidTest.apk\n\n  ### Additional APK's\n  ## A list of up to 100 additional APKs to install, in addition to those being directly tested.\n  ## The path may be in the local filesystem or in Google Cloud Storage using gs:// notation.\n  # additional-apks: additional-apk1.apk,additional-apk2.apk,additional-apk3.apk\n\n  ### Auto Google Login flag\n  ## Automatically log into the test device using a preconfigured Google account before beginning the test.\n  ## Disabled by default. Use --auto-google-login to enable.\n  # auto-google-login: true\n\n  ### Use Orchestrator Flag\n  ## Whether each test runs in its own Instrumentation instance with the Android Test Orchestrator\n  ## (default: Orchestrator is used). Disable with --no-use-orchestrator.\n  ## See https://developer.android.com/training/testing/junit-runner.html#using-android-test-orchestrator\n  # use-orchestrator: true\n\n  ### Environment Variables\n  ## A comma-separated, key=value map of environment variables and their desired values. This flag is repeatable.\n  ## The environment variables are mirrored as extra options to the am instrument -e KEY1 VALUE1 \u2026 command and\n  ## passed to your test runner (typically AndroidJUnitRunner)\n  # environment-variables:\n  #  coverage: true\n  #  coverageFilePath: /sdcard/\n  #  clearPackageData: true\n\n  ### Directories to Pull\n  ## A list of paths that will be copied from the device's storage to the designated results bucket after the test\n  ## is complete. These must be absolute paths under /sdcard or /data/local/tmp\n  # directories-to-pull:\n  #   - /sdcard/\n\n  ### Grant Permissions flag\n  ## Whether to grant runtime permissions on the device before the test begins.\n  ## By default, all permissions are granted. PERMISSIONS must be one of: all, none\n  # grant-permissions: all\n\n  ### Test Type\n  ## The type of test to run. TYPE must be one of: instrumentation, robo, game-loop.\n  # type: instrumentation\n\n  ### Other Files\n  ## A list of device-path: file-path pairs that indicate the device paths to push files to the device before starting tests, and the paths of files to push.\n  ## Device paths must be under absolute, whitelisted paths (${EXTERNAL_STORAGE}, or ${ANDROID_DATA}/local/tmp).\n  ## Source file paths may be in the local filesystem or in Google Cloud Storage (gs://\u2026).\n  # other-files\n  #   - /sdcard/dir1/file1.txt: local/file.txt\n  #   - /sdcard/dir2/file2.jpg: gs://bucket/file.jpg\n\n  ### OBB Files\n  ## A list of one or two Android OBB file names which will be copied to each test device before the tests will run (default: None).\n  ## Each OBB file name must conform to the format as specified by Android (e.g. [main|patch].0300110.com.example.android.obb) and will be installed into &lt;shared-storage&gt;/Android/obb/&lt;package-name&gt;/ on the test device.\n  # obb-files:\n  #   - local/file/path/test1.obb\n  #   - local/file/path/test2.obb\n\n  ### Scenario Numbers\n  ## A list of game-loop scenario numbers which will be run as part of the test (default: all scenarios).\n  ## A maximum of 1024 scenarios may be specified in one test matrix, but the maximum number may also be limited by the overall test --timeout setting.\n  # scenario-numbers:\n  #   - 1\n  #   - 2\n  #   - 3\n\n  ### Scenario Labels\n  ## A list of game-loop scenario labels (default: None). Each game-loop scenario may be labeled in the APK manifest file with one or more arbitrary strings, creating logical groupings (e.g. GPU_COMPATIBILITY_TESTS).\n  ## If --scenario-numbers and --scenario-labels are specified together, Firebase Test Lab will first execute each scenario from --scenario-numbers.\n  ## It will then expand each given scenario label into a list of scenario numbers marked with that label, and execute those scenarios.\n  # scenario-labels:\n  #  - label1\n  #  - label2\n\n  ### OBB filenames\n  ## A list of OBB required filenames. OBB file name must conform to the format as specified by Android e.g.\n  ## [main|patch].0300110.com.example.android.obb which will be installed into &lt;shared-storage&gt;/Android/obb/&lt;package-name&gt;/ on the device.\n  # obb-names:\n  #   - [main|patch].&lt;VERSION&gt;.com.example.android.obb\n\n  ### Performance Metric flag\n  ## Monitor and record performance metrics: CPU, memory, network usage, and FPS (game-loop only).\n  ## Disabled by default. Use --performance-metrics to enable.\n  # performance-metrics: true\n\n  ### Number of Uniform Shards\n  ## Specifies the number of shards into which you want to evenly distribute test cases.\n  ## The shards are run in parallel on separate devices. For example,\n  ## if your test execution contains 20 test cases and you specify four shards, each shard executes five test cases.\n  ## The number of shards should be less than the total number of test cases.\n  ## The number of shards specified must be &gt;= 1 and &lt;= 50.\n  ## This option cannot be used along max-test-shards and is not compatible with smart sharding.\n  ## If you want to take benefits of smart sharding use max-test-shards instead.\n  ## default: null\n  # num-uniform-shards: 50\n\n  ### Instrumentation Test Runner Class\n  ## The fully-qualified Java class name of the instrumentation test runner\n  ## (default: the last name extracted from the APK manifest).\n  # test-runner-class: com.foo.TestRunner\n\n  ### Test Targets\n  ## A list of one or more test target filters to apply (default: run all test targets).\n  ## Each target filter must be fully qualified with the package name, class name, or test annotation desired.\n  ## Supported test filters by am instrument -e \u2026 include:\n  ## class, notClass, size, annotation, notAnnotation, package, notPackage, testFile, notTestFile\n  ## See https://developer.android.com/reference/android/support/test/runner/AndroidJUnitRunner for more information.\n  # test-targets:\n  #  - class com.example.app.ExampleUiTest#testPasses\n\n  ### Robo Directives\n  ## A map of robo_directives that you can use to customize the behavior of Robo test.\n  ## The type specifies the action type of the directive, which may take on values click, text or ignore.\n  ## If no type is provided, text will be used by default.\n  ## Each key should be the Android resource name of a target UI element and each value should be the text input for that element.\n  ## Values are only permitted for text type elements, so no value should be specified for click and ignore type elements.\n  # robo-directives:\n  #   \"text:input_resource_name\": message\n  #   \"click:button_resource_name\": \"\"\n\n  ### Robo Scripts\n  ## The path to a Robo Script JSON file.\n  ## The path may be in the local filesystem or in Google Cloud Storage using gs:// notation.\n  ## You can guide the Robo test to perform specific actions by recording a Robo Script in Android Studio and then specifying this argument.\n  ## Learn more at https://firebase.google.com/docs/test-lab/robo-ux-test#scripting.\n  # robo-script: path_to_robo_script\n\n  ### Android Device Parameters\n  ## A list of DIMENSION=VALUE pairs which specify a target device to test against.\n  ## This flag may be repeated to specify multiple devices.\n  ## The four device dimensions are: model, version, locale, and orientation.\n  # device:\n  # - model: NexusLowRes\n  #   version: 28\n  #   locale: en\n  #   orientation: portrait\n  # - model: NexusLowRes\n  #   version: 27\n\n  ### test-targets-for-shard\n  ## Specifies a group of packages, classes, and/or test cases to run in each shard (a group of test cases).\n  ## The shards are run in parallel on separate devices. You can repeat this flag up to 50 times to specify multiple shards when one or more physical devices are selected,\n  ## or up to 500 times when no physical devices are selected.\n  ## Note: If you include the flags environment-variable or test-targets when running test-targets-for-shard, the flags are applied to all the shards you create.\n  # test-target-for-shard:\n  # - package com.package1.for.shard1\n  # - class com.package2.for.shard2.Class\n\n  ### parameterized-tests\n  ## Specifies how to handle tests which contain the parameterization annotation.\n  ## 4 options are available\n  ## default: treat Parameterized tests as normal and shard accordingly\n  ## ignore-all: Parameterized tests are ignored and not sharded\n  ## shard-into-single: Parameterized tests are collected and put into a single shard\n  ## shard-into-multiple: Parameterized tests are collected and sharded into different shards based upon matching names. (Experimental)\n  ## Note: If left blank default is used. Default usage may result in significant increase/difference of shard times observed\n  ## Note: If shard-into-single is used, a single additional shard is created that will run the Parameterized tests separately.\n  ## Note: If shard-into-multiple is used, each parameterized test will be matched by its corresponding name and sharded into a separate shard.\n  ##       This may dramatically increase the amount of expected shards depending upon how many parameterized tests are discovered.\n  # parameterized-tests: default\n\nflank:\n  # -- FlankYml --\n\n  ### Max Test Shards\n  ## test shards - the amount of groups to split the test suite into\n  ## set to -1 to use one shard per test. default: 1\n  # max-test-shards: 1\n\n  ### Shard Time\n  ## shard time - the amount of time tests within a shard should take\n  ## when set to &gt; 0, the shard count is dynamically set based on time up to the maximum limit defined by max-test-shards\n  ## 2 minutes (120) is recommended.\n  ## default: -1 (unlimited)\n  # shard-time: -1\n\n  ### Number of Test Runs\n  ## test runs - the amount of times to run the tests.\n  ## 1 runs the tests once. 10 runs all the tests 10x\n  # num-test-runs: 1\n\n  ### Smart Flank GCS Path\n  ## Google cloud storage path where the JUnit XML results from the last run is stored.\n  ## NOTE: Empty results will not be uploaded\n  # smart-flank-gcs-path: gs://tmp_flank/tmp/JUnitReport.xml\n\n  ### Smart Flank Upload Disable flag\n  ## Disables smart flank JUnit XML uploading. Useful for preventing timing data from being updated.\n  ## Default: false\n  # smart-flank-disable-upload: false\n\n  ### Use Average Test Time for New Tests flag\n  ## Enable using average time from previous tests duration when using SmartShard and tests did not run before.\n  ## Default: false\n  # use-average-test-time-for-new-tests: true\n\n  ### Default Test Time\n  ## Set default test time used for calculating shards.\n  ## Default: 120.0\n  # default-test-time: 15\n\n  ### Default Class Test Time\n  ## Set default test time (in seconds) used for calculating shards of parametrized classes when previous tests results are not available.\n  ## Default test time for classes should be different from the default time for test\n  ## Default: 240.0\n  # default-class-test-time: 30\n\n  ### Disable Sharding flag\n  ## Disables sharding. Useful for parameterized tests.\n  # disable-sharding: false\n\n  ### Test Targets Always Run\n  ## always run - these tests are inserted at the beginning of every shard\n  ## Execution order is not guaranteed by Flank. Users are responsible for configuring their own device test runner logic.\n  # test-targets-always-run:\n  #   - class com.example.app.ExampleUiTest#testPasses\n\n  ### Files to Download\n  ## regex is matched against bucket paths, for example: 2019-01-09_00:13:06.106000_YCKl/shard_0/NexusLowRes-28-en-portrait/bugreport.txt\n  # files-to-download:\n  #   - .*\\.mp4$\n\n  ### Billing Project ID\n  ## The billing enabled Google Cloud Platform id name to use\n  # project: ftl-flank-open-source\n\n  ### Local Results Directory\n  ## Local folder to store the test result. Folder is DELETED before each run to ensure only artifacts from the new run are saved.\n  # local-result-dir: flank\n\n  ### Keep File Path flag\n  ## Keeps the full path of downloaded files. Required when file names are not unique.\n  ## Default: false\n  # keep-file-path: false\n\n  ### Additional App/Test APKS\n  ## Include additional app/test apk pairs in the run. Apks are unique by just filename and not by path!\n  ## If app is omitted, then the top level app is used for that pair.\n  ## You can overwrite global config per each test pair.\n  ## Currently supported options are: max-test-shards, test-targets, client-details, environment-variables, device\n  # additional-app-test-apks:\n  #  - app: ../test_projects/android/apks/app-debug.apk\n  #    test: ../test_projects/android/apks/app1-debug-androidTest.apk\n  #    device:\n  #      - model: Nexus6P\n  #        version: 27\n  #  - test: ../test_projects/android/apks/app2-debug-androidTest.apk\n  #    max-test-shards: 5\n\n  ### Run Timeout\n  ## The max time this test run can execute before it is cancelled (default: unlimited).\n  # run-timeout: 60m\n\n  ### Ignore Failed Test flag\n  ## Terminate with exit code 0 when there are failed tests.\n  ## Useful for Fladle and other gradle plugins that don't expect the process to have a non-zero exit code.\n  ## The JUnit XML is used to determine failure. (default: false)\n  # ignore-failed-tests: true\n\n  ### Legacy Junit Results flag\n  ## Flank provides two ways for parsing junit xml results.\n  ## New way uses google api instead of merging xml files, but can generate slightly different output format.\n  ## This flag allows fallback for legacy xml junit results parsing\n  ## Currently available for android, iOS still uses only legacy way.\n  # legacy-junit-result: false\n\n  ### Output Style flag\n  ## Output style of execution status. May be one of [verbose, multi, single, compact].\n  ## For runs with only one test execution the default value is 'verbose', in other cases\n  ## 'multi' is used as the default. The output style 'multi' is not displayed correctly on consoles\n  ## which don't support ansi codes, to avoid corrupted output use single or verbose.\n  ## The output style `compact` is used to produce less detailed output, it prints just Args, test and matrix count, weblinks, cost, and result reports.\n  # output-style: single\n\n  ### Full Junit Result flag\n  ## Enable create additional local junit result on local storage with failure nodes on passed flaky tests.\n  # full-junit-result: false\n\n  ### Disable Results Upload flag\n  ## Disables flank results upload on gcloud storage.\n  ## Default: false\n  # disable-results-upload: false\n\n  ### Disable usage statistics flag\n  ## Disable sending usage statistics (without sensitive data) to the analytic tool.\n  ## Default: false\n  # disable-usage-statistics: false\n\n  ### Enable output report with set type\n  ## Saves output results as parsable file and optionally upload it to Gcloud. Possible values are [none, json].\n  ## Default: none\n  # output-report: none\n\n ### Disable config validation (for both, yml and command line)\n ## If true, Flank won't validate options provided by the user. In general, it's not a good idea but,\n ## there are cases when this could be useful for a user\n ## (example: project can use devices that are not commonly available, the project has higher sharding limits, etc).\n ## Default: false\n # skip-config-validation: false\n\n ### Path to the custom sharding JSON file\n ## Flank will apply provided sharding to the configuration.\n ## For detailed explanation please check https://github.com/Flank/flank/blob/master/docs/feature/1665-custom-sharding.md\n # custom-sharding-json: ./custom_sharding.json\n</code></pre>"},{"location":"#flank-wrapper","title":"Flank Wrapper","text":"<p>Flank wrapper is a solution to always run the latest version of Flank. It will download the latest version of Flank itself always when it changed. Using Flank wrapper is similar to using Flank, all options provided to Flank wrapper will be passed to Flank itself. To download the latest version of Flank wrapper, please visit GitHub releases and search for tag <code>flank_wrapper-XXX</code>. There are also shell and a batch wrapper over <code>.jar</code> file included.</p>"},{"location":"#android-code-coverage","title":"Android code coverage","text":"Update your app's build.gradle to build with coverage and use orchestrator. A custom gradle task is defined to generate the coverage report. <pre><code>def coverageEnabled = project.hasProperty('coverage')\n\nandroid {\n\n  defaultConfig {\n    testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\n    // runs pm clear after each test invocation\n    testInstrumentationRunnerArguments clearPackageData: 'true'\n  }\n\n  buildTypes {\n    debug {\n      testCoverageEnabled true\n    }\n  }\n\n  // https://google.github.io/android-gradle-dsl/current/com.android.build.gradle.internal.dsl.TestOptions.html#com.android.build.gradle.internal.dsl.TestOptions:animationsDisabled\n  testOptions {\n        execution 'ANDROIDX_TEST_ORCHESTRATOR'\n        animationsDisabled = true\n    }\n}\n\ndependencies {\n  androidTestUtil 'androidx.test:orchestrator:1.1.1'\n\n  androidTestImplementation(\"androidx.test:runner:1.1.1\")\n  androidTestImplementation(\"androidx.test.ext:junit:1.1.0\")\n  androidTestImplementation(\"androidx.test.ext:junit-ktx:1.1.0\")\n  androidTestImplementation(\"androidx.test.ext:truth:1.1.0\")\n  androidTestImplementation(\"androidx.test.espresso.idling:idling-concurrent:3.1.1\")\n  androidTestImplementation(\"androidx.test.espresso.idling:idling-net:3.1.1\")\n  androidTestImplementation(\"androidx.test.espresso:espresso-accessibility:3.1.1\")\n  androidTestImplementation(\"androidx.test:rules:1.1.1\")\n  androidTestImplementation(\"androidx.test.espresso:espresso-core:3.1.1\")\n  androidTestImplementation(\"androidx.test.espresso:espresso-contrib:3.1.1\")\n  androidTestImplementation(\"androidx.test.espresso:espresso-idling-resource:3.1.1\")\n  androidTestImplementation(\"androidx.test.espresso:espresso-intents:3.1.1\")\n  androidTestImplementation(\"androidx.test.espresso:espresso-web:3.1.1\")\n}\n\nif (coverageEnabled) {\n    // gradle -Pcoverage firebaseJacoco\n    task firebaseJacoco(type: JacocoReport) {\n        group = \"Reporting\"\n        description = \"Generate Jacoco coverage reports for Firebase test lab.\"\n\n        def excludes = [\n                '**/R.class',\n                '**/R$*.class',\n                '**/BuildConfig.*',\n                \"**/androidx\"]\n        def javaClasses = fileTree(dir: \"${project.buildDir}/intermediates/javac/debug/classes\", excludes: excludes)\n        def kotlinClasses = fileTree(dir: \"${project.buildDir}/tmp/kotlin-classes/debug\", excludes: excludes)\n        getClassDirectories().setFrom(files([javaClasses, kotlinClasses]))\n\n        getSourceDirectories().setFrom(files([\n                'src/main/java', 'src/main/kotlin',\n                'src/androidTest/java', 'src/androidTest/kotlin']))\n\n        def ecFiles = project.fileTree(dir: '..', include: 'results/coverage_ec/**/sdcard/*.ec')\n        ecFiles.forEach { println(\"Reading in $it\") }\n        getExecutionData().setFrom(ecFiles)\n\n        reports {\n            html { enabled true }\n            xml { enabled false }\n        }\n    }\n}\n</code></pre> Starting from Android Marshmallow we must grant runtime permissions to write to external storage. Following snippet in test class solves that issue. If you want to get coverage files when using orchestrator, you must set this Rule for each test class.  <pre><code>import androidx.test.rule.GrantPermissionRule;\nimport static android.Manifest.permission.READ_EXTERNAL_STORAGE;\nimport static android.Manifest.permission.WRITE_EXTERNAL_STORAGE;\n\nclass MyEspressoTest {\n\n  @Rule\n  GrantPermissionRule grantPermissionRule = GrantPermissionRule.grant(\n          READ_EXTERNAL_STORAGE, WRITE_EXTERNAL_STORAGE);\n\n  // other configuration and tests\n}\n</code></pre>  Here's an example flank.yml. Note that `coverage` and `coverageFilePath` must be set when using orchestrator with coverage. `coverageFile` is not used. Orchestrator will generate one coverage file per test. `coverageFilePath` must be a directory, not a file.  <pre><code>gcloud:\n  app: ./app/build/outputs/apk/debug/app-debug.apk\n  test: ./app/build/outputs/apk/androidTest/debug/app-debug-androidTest.apk\n  environment-variables:\n    coverage: true\n    coverageFilePath: /sdcard/\n    clearPackageData: true\n  directories-to-pull:\n    - /sdcard/\n  # use a named results dir that's used by the gradle task\n  results-dir: coverage_ec\n\nflank:\n  disableSharding: true\n  files-to-download:\n    - .*/sdcard/[^/]+\\.ec$\n</code></pre>  - Build the app with coverage: `./gradlew -Pcoverage build` - Run flank `flank android run` - Generate the report `./gradlew -Pcoverage firebaseJacoco` - Open the report in `./build/reports/jacoco/firebaseJacoco/html/index.html`"},{"location":"#ci-integration","title":"CI integration","text":"<p>Download Flank from GitHub releases.</p> <p>Stable. Get the latest stable version number and replace the <code>XXX</code> with the version number.</p> <pre><code>wget --quiet https://github.com/Flank/flank/releases/download/vXXX/flank.jar -O ./flank.jar\njava -jar ./flank.jar android run\n</code></pre> <p>Snapshot (published after every commit)</p> <pre><code>wget --quiet https://github.com/Flank/flank/releases/download/flank_snapshot/flank.jar -O ./flank.jar\njava -jar ./flank.jar android run\n</code></pre> <p>In CI, it may be useful to generate the file via a shell script:</p> <pre><code>cat &lt;&lt; 'EOF' &gt; ./flank.yml\ngcloud:\n  app: ../../test_projects/android/apks/app-debug.apk\n  test: ../../test_projects/android/apks/app-debug-androidTest.apk\nEOF\n</code></pre>"},{"location":"#circle-ci","title":"Circle CI","text":"<p>Circle CI has a firebase testlab orb that supports Flank.</p>"},{"location":"#bitrise","title":"Bitrise","text":"<p>Bitrise has an official flank step.</p>"},{"location":"#gradle-plugin","title":"Gradle Plugin","text":"<p>Fladle is a Gradle plugin for Flank that provides DSL configuration and task based execution.</p>"},{"location":"#flank-on-windows","title":"Flank on Windows","text":"<p>In order to build or run Flank using Windows please follow guide of building/running it using Windows WSL. Native support is not currently supported.</p>"},{"location":"#authenticate-with-a-google-account","title":"Authenticate with a Google account","text":"<p>Run <code>flank auth login</code>. Flank will save the credential to <code>~/.flank</code>. Google account authentication allows each person to have a unique non-shared credential. A service account is still recommended for CI.</p>"},{"location":"#authenticate-with-a-service-account","title":"Authenticate with a service account","text":"<p>Follow the test lab docs to create a service account.</p> <ul> <li>Save the credential to <code>$HOME/.config/gcloud/application_default_credentials.json</code> or set <code>GOOGLE_APPLICATION_CREDENTIALS</code> when using a custom path.</li> <li>Set the project id in flank.yml or set the <code>GOOGLE_CLOUD_PROJECT</code> environment variable.</li> <li>(Since 21.01) if <code>projectId</code> is not set in a config yml file, flank uses the first available project ID among the following sources:<ol> <li>The project ID specified in the JSON credentials file pointed by the GOOGLE_APPLICATION_CREDENTIALS environment variable fladle</li> <li>The project ID specified by the GOOGLE_CLOUD_PROJECT environment variable</li> <li>The project ID specified in the JSON credentials file <code>$HOME/.config/gcloud/application_default_credentials.json</code></li> </ol> </li> </ul> <p>For continuous integration, base64 encode the credential as <code>GCLOUD_KEY</code>. Then write the file using a shell script. Note that gcloud CLI does not need to be installed. Flank works without any dependency on gcloud CLI.</p> <p>Encode JSON locally.</p> <pre><code>base64 -i \"$HOME/.config/gcloud/application_default_credentials.json\" | pbcopy\n</code></pre> <p>Then in CI decode the JSON.</p> <pre><code>GCLOUD_DIR=\"$HOME/.config/gcloud/\"\nmkdir -p \"$GCLOUD_DIR\"\necho \"$GCLOUD_KEY\" | base64 --decode &gt; \"$GCLOUD_DIR/application_default_credentials.json\"\n</code></pre>"},{"location":"#running-with-gcloud-directly","title":"Running with gcloud directly","text":"<p>flank.yml is compatible with the gcloud CLI.</p> <ul> <li><code>gcloud firebase test android run flank.yml:gcloud</code></li> <li><code>gcloud alpha firebase test ios run flank.ios.yml:gcloud</code></li> </ul> <p>NOTE: You will need to activate gcloud's service account for the above commands to work.</p>"},{"location":"#doctor","title":"Doctor","text":"<p>Use the doctor command to check for errors in the YAML.</p> <ul> <li><code>flank firebase test android doctor</code></li> <li><code>flank firebase test ios doctor</code></li> </ul>"},{"location":"#check-version","title":"Check version","text":"<p>Flank supports printing the current version.</p> <pre><code>$ flank -v\nv3.0-SNAPSHOT\n</code></pre>"},{"location":"#maven","title":"Maven","text":"<p>You can consume Flank via maven. See the maven repo for all supported versions.</p> <pre><code>repositories {\n    mavenCentral()\n}\n\ndependencies {\n    compile(\"flank:flank:master-SNAPSHOT\")\n}\n</code></pre> <p>or GitHub packages</p> Groovy <pre><code>dependencies {\n    implementation \"com.github.flank:flank:&lt;latest version&gt;\"\n}\n</code></pre> Kotlin <pre><code>dependencies {\n    implementation(\"com.github.flank:flank:&lt;latest version&gt;\")\n}\n</code></pre>"},{"location":"#gradle-enterprise-export-api","title":"Gradle Enterprise Export API","text":"<p>It is possible to fetch metrics from Gradle builds. For detailed info please visit Gradle Export API and flank's example gradle-export-api.</p>"},{"location":"#faq","title":"FAQ","text":"<p>1) &gt; Access Not Configured. Cloud Tool Results API has not been used in project 764086051850 before or it is disabled.</p> <pre><code>This error means authentication hasn't been setup properly. See `Authenticate with a service account` in this readme.\n</code></pre> <p>2)  &gt; How do I use Flank without typing long commands?</p> <pre><code>Add Flank's [bash helper folder](https://github.com/Flank/flank/blob/master/test_runner/bash/) to your $PATH environment variable. This will allow you to call the shell scripts in that helper folder from anywhere.\n\nWith the [flank](https://github.com/Flank/flank/blob/master/test_runner/bash/flank) shell script, you can use `flank` instead of `java -jar flank.jar`. Examples:\n\n- `flank android run`\n- `flank ios run`\n\nWith the [update_flank.sh](https://github.com/Flank/flank/blob/master/test_runner/bash/update_flank.sh) shell script, you can rebuild `flank.jar`.\n</code></pre> <p>3)  &gt; Test run failed to complete. Expected 786 tests, received 660</p> <pre><code>Try setting `use-orchestrator: false`. Parameterized tests [are not compatible with orchestrator](https://stackoverflow.com/questions/48735268/unable-to-run-parameterized-tests-with-android-test-orchestrator). Flank uses [orchestrator by default on Android.](https://developer.android.com/training/testing/junit-runner)\n</code></pre> <p>4) &gt; I have an issue when attempting to sync the Flank Gradle project</p> <p>Task 'prepareKotlinBuildScriptModel' not found in project ':test_runner'. or similar</p> <pre><code>- Make sure you do not change any module specific settings for Gradle\n- Clear IDE cache using `File &gt; Invalidate Caches / Restart`\n- Re-import project using root `build.gradle.kts`\n- Sync project again\n</code></pre> <p>5) &gt; Does Flank support Cucumber?</p> <p>Please check document for more info</p> <p>6) &gt; How can I find project id?</p> <p>Please check the firebase documentation about finding the project id</p> <p>7) &gt; How do I run Flank with a proxy?</p> <p><code>java -Dhttp.proxyHost=localhost -Dhttp.proxyPort=8080 -Dhttp.proxyUser=user -Dhttp.proxyPassword=pass -jar ./test_runner/build/libs/flank.jar firebase test android run</code></p> <p>See google-auth-library-java for details.</p>"},{"location":"#resources","title":"Resources","text":"<ul> <li>Instrumenting Firebase Test Lab</li> </ul>"},{"location":"architecture/","title":"Architecture","text":"<p>This document describes abstract architecture design which should be able to apply to any use-case in flank scope, starting from user interface and ending on remote API calls. Use it as a reference for explaining common abstract problems around implementation.</p>"},{"location":"architecture/#table-of-contents","title":"Table of contents","text":"<ol> <li>Motivation</li> <li>Goals</li> <li>Scalability</li> <li>Layers</li> <li>Presentation<ol> <li>Responsibilities</li> <li>Constrains</li> <li>How to scale</li> <li>Dependencies</li> </ol> </li> <li>Domain<ol> <li>Execution context</li> <li>Top-level function</li> <li>Low-level function</li> <li>Responsibilities</li> <li>Constrains</li> <li>How to scale</li> <li>Dependencies</li> <li>Static</li> <li>Dynamic</li> <li>Both</li> </ol> </li> <li>Tool<ol> <li>How to scale</li> <li>Dependencies</li> </ol> </li> <li>API<ol> <li>How to scale</li> <li>Dependencies</li> </ol> </li> <li>Client<ol> <li>How to scale</li> <li>Dependencies</li> </ol> </li> <li>Adapter<ol> <li>How to scale</li> <li>Dependencies</li> </ol> </li> <li>Implementation<ol> <li>Public API</li> <li>Components composition</li> <li>Code composition</li> <li>Vertical</li> <li>Horizontal</li> <li>Horizontal Layered</li> </ol> </li> </ol>"},{"location":"architecture/#motivation","title":"Motivation","text":"<p>Without well-defined architecture, the application can grow in an uncontrolled way. This typically increases the amount of unwanted redundancy, unneeded calls, and unnecessary logical operations which as result makes code harder to understand, more error-prone, and sometimes even impossible to scale.</p>"},{"location":"architecture/#goals","title":"Goals","text":"<p>The architecture should help achieve the following goals:</p> <ul> <li>Organize implementation into restricted logical layers.</li> <li>Divide implementation into small and easy-to-understand parts.</li> <li>Identify scalability vectors for each part of the architecture.</li> <li>Make implementation easy to navigate through.</li> <li>Optimize the amount of code for implementation.</li> <li>Make implementation less error-prone.</li> </ul>"},{"location":"architecture/#scalability","title":"Scalability","text":"<p>The design is specifying two types of scaling:</p> <ul> <li><code>Horizontal</code> - by adding atomic components that are not related to each other, but must meet common requirements.</li> <li><code>Vertical</code> - by expanding one component for new features.</li> </ul> <p>Typically, <code>horizontal</code> scaling is preferred when <code>vertical</code> scaling become to break the single responsibility principle.</p>"},{"location":"architecture/#layers","title":"Layers","text":"<p>The example diagram that is exposing relations between layers:</p> <p></p>"},{"location":"architecture/#presentation","title":"Presentation","text":"<p>The front-end layer of the flank application.</p> <ul> <li>From the higher level of view, the presentation layer is a bridge between end-user and business logic.</li> <li>From the implementation perspective it is just adapter for <code>domain</code> <code>top-level function</code> call.</li> </ul>"},{"location":"architecture/#responsibilities","title":"Responsibilities","text":"<ul> <li>Implements user interface and adapt it to <code>domain</code> API.</li> <li>Converts input from user into <code>domain</code> <code>top-level functions</code> calls.</li> <li>Converts structural output result from the <code>domain</code> into the output specific for the <code>presentation</code>.</li> <li>Passes  <code>dynamic</code> dependencies to <code>domain</code> if needed.</li> </ul>"},{"location":"architecture/#constrains","title":"Constrains","text":"<ul> <li>SHOULD<ul> <li>avoid logical operations</li> </ul> </li> <li>CAN<ul> <li>base on third-part framework or library</li> <li>invoke <code>domain</code> public functions</li> </ul> </li> <li>CAN'T<ul> <li>access <code>API</code> layer directly</li> <li>access tools deserved for <code>domain</code></li> </ul> </li> </ul>"},{"location":"architecture/#how-to-scale","title":"How to scale","text":"<ul> <li><code>Horizontal</code> - by adding different UI implementations</li> <li>Along with <code>domain</code> <code>top-level functions</code>.</li> </ul>"},{"location":"architecture/#dependencies","title":"Dependencies","text":"<ul> <li><code>Domain</code> layer</li> <li><code>Adapter</code> layer (required meet domain interface)</li> </ul>"},{"location":"architecture/#domain","title":"Domain","text":"<p>Is the implementation of the application business logic.</p> <p>Exposes its own API as a one, or many public extension functions, called <code>top-level functions</code>. Each <code>top-level function</code> have its own <code>execution context</code>, can produce a <code>structured output</code> during the <code>execution</code> and can be composed of one or more <code>low-level functions</code>.</p> <p>This layer can be considered as a standalone library, that is providing access to business logic through pure kotlin functions.</p>"},{"location":"architecture/#execution-context","title":"Execution context","text":"<p>The context can provide arguments and <code>dynamic</code> functions required by the execution. Its name should reflect the related use case.</p>"},{"location":"architecture/#top-level-function","title":"Top-level function","text":"<p>Is a public function placed in root of the domain package. Is responsible to implement domain logic directly or compose it using <code>low-level functions</code>, <code>tools</code> or <code>API</code>. For simplification, consider a simple common type for all <code>top-level functions</code>.</p> <pre><code>typealias UseCase&lt;A&gt; = A.() -&gt; Unit\n</code></pre> <p>Where <code>A</code> is a generic type that is representing the <code>execution context</code>.</p>"},{"location":"architecture/#low-level-function","title":"Low-level function","text":"<p>The low-level function is useful when it comes to dividing complex <code>top-level function</code> into the composition of smaller chunks or the reuse of some logic in many top-level functions. It is crucial in keeping the composition of low-level functions flat. More nesting in-depth can make a code much harder to understand and maintain.</p>"},{"location":"architecture/#responsibilities_1","title":"Responsibilities","text":"<ul> <li>Contains the business logic of the application</li> <li>Provide access to the use cases through formalized API</li> </ul>"},{"location":"architecture/#constrains_1","title":"Constrains","text":"<ul> <li>MUST<ul> <li>define a dedicated <code>execution context</code> for each <code>top-level function</code>.</li> <li>keep the <code>top-level functions</code> directly inside root package.</li> <li>keep the low-level functions inside nested packages of the root.</li> </ul> </li> <li>SHOULD<ul> <li>access third-party clients through <code>API</code> layer abstraction.</li> <li>keep the <code>execution context</code> with related <code>top-level function</code> in the same file.</li> </ul> </li> <li>CAN<ul> <li>use <code>tools</code> directly.</li> <li>use <code>API</code> directly.</li> </ul> </li> <li>CAN'T<ul> <li>specify anything else than <code>top-level functions</code> &amp; related <code>contexts</code>   directly inside root package</li> </ul> </li> </ul>"},{"location":"architecture/#how-to-scale_1","title":"How to scale","text":"<ul> <li><code>Horizontal</code> - by adding new <code>top-level functions</code>.</li> <li><code>Vertically</code> - by adding new <code>low-level functions</code> for a single <code>top-level function</code>.</li> </ul>"},{"location":"architecture/#dependencies_1","title":"Dependencies","text":"<p>The domain layer shouldn't implement complicated or specialized operations by itself or use third-party libraries directly. Instead of this, it can depend on dedicated internal tools and APIs, that are designed to exactly meet domain requirements. There are 2 types of domain dependencies:</p>"},{"location":"architecture/#static","title":"Static","text":"<p>The dependencies that are providing its API through static imports.</p> <p>It's dedicated to the tools that don't need to be mocked for unit testing.</p> <p>In details the static dependency:</p> <ul> <li>CAN:<ul> <li>Implement algorithms.</li> <li>Generate files.</li> <li>Parse files (only if can generate it also)</li> <li>Format data.</li> <li>Parse data</li> </ul> </li> <li>CANNOT:<ul> <li>Make network calls.</li> <li>Use external applications (shell, SQL server, etc..).</li> <li>Operate on binary files that need to be provided.</li> </ul> </li> </ul>"},{"location":"architecture/#dynamic","title":"Dynamic","text":"<p>The dependencies that are provided to the <code>domain</code> through the <code>execution context</code>, as a reference.</p> <p>It's dedicated to the tools that need to be mocked for unit testing.</p> <ul> <li>CAN:<ul> <li>Make network calls.</li> <li>Use external applications (shell, SQL server, etc..).</li> <li>Operate on binary files that need to be provided.</li> <li>Generate data structures.</li> </ul> </li> <li>CANNOT:<ul> <li>Generate files.</li> <li>Implement algorithms.</li> </ul> </li> <li>SHOULD NOT:<ul> <li>Parse formatted data (except simple strings like date).</li> <li>Format data (except simple string formatting).</li> </ul> </li> </ul>"},{"location":"architecture/#both","title":"Both","text":"<p>Additionally, both  <code>static</code> and  <code>dynamic</code>:</p> <ul> <li>CAN:<ul> <li>Specify data structures.</li> <li>Map data structures.</li> </ul> </li> </ul>"},{"location":"architecture/#tool","title":"Tool","text":"<p>The layer that groups various atomic tools required by the domain. Mainly  <code>static</code> dependencies or not client specific  <code>dynamic</code> dependencies. Typically, tools are specialized to solve one, or a group of related problems like:</p> <ul> <li>parsing and formatting</li> <li>calculating</li> <li>mapping</li> </ul> <p>Notice that, tools are solving specialized problems that are meeting <code>domain</code> requirements, but should be designed as standalone libraries that do know nothing about the whole domain problem. Instead, just solving well the small highly isolated part. Designing tools as standalone libraries makes the code more decoupled and easier to reuse if needed.</p>"},{"location":"architecture/#how-to-scale_2","title":"How to scale","text":"<ul> <li><code>Horizontal</code> - as a group of libs just by adding more standalone tools if needed.</li> </ul>"},{"location":"architecture/#dependencies_2","title":"Dependencies","text":"<ul> <li>third-party library</li> </ul>"},{"location":"architecture/#api","title":"API","text":"<p>The light-weight layer that is specifying structures and functional interfaces for <code>client</code> operations. Like <code>tool</code> this layer must exactly meet the <code>domain</code> requirements and specify public API designed for it. Unlike the <code>tool</code>, it cannot define any implementation, so it can be scaled horizontally by adding new not unrelated scopes.</p>"},{"location":"architecture/#how-to-scale_3","title":"How to scale","text":"<ul> <li><code>Horizontal</code> - by adding more namespaces for structures and functional interfaces.</li> </ul>"},{"location":"architecture/#dependencies_3","title":"Dependencies","text":"<ul> <li>Only standard libraries</li> </ul>"},{"location":"architecture/#client","title":"Client","text":"<p>The client-side specific operations not related directly to the domain. Typically, there are two purposes for this layer implementation:</p> <ul> <li>Is necessary to create a library wrapper for remote protocol, driven on WS, REST, TCP, etc...</li> <li>The third-party library is not convenient and requires some adjustments.</li> </ul>"},{"location":"architecture/#how-to-scale_4","title":"How to scale","text":"<ul> <li>Along with third-party API changes.</li> </ul>"},{"location":"architecture/#dependencies_4","title":"Dependencies","text":"<ul> <li>Network libraries</li> <li>third-party client library</li> </ul>"},{"location":"architecture/#adapter","title":"Adapter","text":"<p>This layer is adapting <code>client</code> or third-party libraries to structures and interfaces, specified in the <code>API</code> layer.</p>"},{"location":"architecture/#how-to-scale_5","title":"How to scale","text":"<ul> <li>Along with <code>API</code> changes.</li> </ul>"},{"location":"architecture/#dependencies_5","title":"Dependencies","text":"<p>one of or many:</p> <ul> <li>internal <code>client</code> library</li> <li>third-party client library</li> </ul>"},{"location":"architecture/#implementation","title":"Implementation","text":"<p>For convenience and clarity, the code should be written in a functional programming style. It's mandatory to avoid the OOP style which almost always makes things much more complicated than should be.</p>"},{"location":"architecture/#public-api","title":"Public API","text":"<p>Any application or library must always have a public API and an internal/private part. For convenience keep public functions and structures in the root package, so the API will be easy to find. Additionally, if the <code>component</code>:</p> <ul> <li>is providing accessibility to public API's with additional structures. -It is mandatory to keep the public structures and functions distinct from internal implementation which should be kept in nested package(s).</li> <li>is just a simple tool with a compact implementation that is not specifying many structures. - Private implementations can be kept in the same file, just behind the public API or even the whole tool can be delivered as one public function if the implementation is simple enough.</li> </ul> <p>DO NOT keep multiple public functions along with internal implementations in the same file or package, because it is messes up the public API, which makes code harder to analyze and navigate.</p>"},{"location":"architecture/#components-composition","title":"Components composition","text":"<p>Business logic shouldn't implement complicated tools on its own because it is can mess up crucial high-level implementations making it harder to understand. Instead, it should be decomposed into high-level use-case implementations that operate on tools provided by specialized components.</p>"},{"location":"architecture/#code-composition","title":"Code composition","text":"<p>Typically, when huge features are divided into smaller functions and one of those functions is a (public) root, the functions can be composed in two different ways.</p>"},{"location":"architecture/#vertical","title":"Vertical","text":"<p>The preceding function is calling the following, so the composition of functions is similar to a linked list.</p> <p></p> <p>Try to AVOID this pattern where possible, especially in business logic. In some situations it can be even worse than one huge monolithic function with comments, for example when internal functions are not ordered correctly. Understanding the feature composed in vertical style, almost always require analyzing the whole chain of functions which typically is not efficient.</p>"},{"location":"architecture/#horizontal","title":"Horizontal","text":"<p>Root function is controlling independent internal and specialized functions.</p> <p></p> <p>This approach gives a fast overview of high-level implementation but is hiding the details not important from the high-level perspective. Comparing to <code>vertical</code> composition where the cost of manual access to internal functions (jumping on references in IDE) in the worst-case scenario is <code>n</code>, the horizontal composition almost always gives <code>1</code> on the same layer (or <code>2</code> taking private functions into account if exist).</p>"},{"location":"architecture/#horizontal-layered","title":"Horizontal-Layered","text":"<p>An example of horizontal composition in layered architecture can look as following:</p> <p></p>"},{"location":"binaries_used_in_flank_ios_testing/","title":"Binaries used in Flank's iOS testing","text":""},{"location":"binaries_used_in_flank_ios_testing/#location","title":"Location","text":"<p>Binaries are placed in Flank binaries repository</p>"},{"location":"binaries_used_in_flank_ios_testing/#usage","title":"Usage","text":"<p>The binaries are downloaded at runtime when they needed for Linux and Windows from Flank binaries repository. They are unpacked to <code>&lt;user directory&gt;/.flank</code>. If they already exist on this path, they are not downloaded again.</p>"},{"location":"binaries_used_in_flank_ios_testing/#updating","title":"Updating","text":"<p>In order to update binaries just follow below steps: 1. checkout binaries repository 1. update them using:    - <code>updateBinariesWithFlankBash</code> will update binaries for Linux and Windows using <code>flank-scripts</code>    - <code>update.sh</code> (old method). It will update binaries for Linux OS 1. commit and push files (create PR with changes) 1. once they will be on master branch. CI job will update artifacts with proper files based on OS</p>"},{"location":"building_updating_flank/","title":"Building and Updating Flank","text":"<p>Ensure that you have followed all steps for contributing and building Flank</p>"},{"location":"building_updating_flank/#building-an-updated-flank","title":"Building an updated flank","text":"<p>To build an updated version of flank from source simply run (This assumes you are in the root Flank directory)</p> <p>./gradlew flankFullRun</p> <p>The flank full run task, builds a clean Flan, runs all tests and runs the updateFlank gradle task.</p> <p>This will create the <code>Flank.jar</code> file and place it in <code>/test_runner/bash</code></p>"},{"location":"building_updating_flank/#building-a-minimized-and-optimized-version-of-flank-proguard","title":"Building a minimized and optimized version of Flank (Proguard)","text":"<p>To build a proguarded version of Flank</p> <p>./gradlew applyProguard</p> <p>This will generate a second <code>Flank.jar</code>, named <code>Flank-proguard.jar</code> found at <code>/test_runner/bash</code></p> <p>To make use of this jar copy and rename it to <code>Flank.jar</code></p>"},{"location":"client_generation/","title":"Overview","text":"<p>The <code>google-api-*-client</code> projects are officially marked as <code>maintenance mode</code>. They don't have a consistent code generation approach. Each binding appears to do something different. <code>apis-client-generator</code> is used to generate REST bindings.</p> <p>The new clients are <code>google-cloud-*</code>. They are in the process of adopting the latest code generation tech <code>googleapis/toolkit</code> which is gRPC based.</p> <p>These handwritten packages are going to migrate to live on top of clients generated from the Google API Code Generator</p> <p>https://github.com/GoogleCloudPlatform/google-cloud-go/issues/266#issuecomment-221083266</p>"},{"location":"client_generation/#api-client-summary","title":"API client summary","text":"<p>Google API clients (<code>google-api-*-client</code>) - Low level - Auto generated - Made for JSON REST APIs - Older project - maintenance mode</p> <p>Google APIs toolkit (<code>googleapis/toolkit</code>) - Low level - Auto generated - Made for gRPC APIs - New project - actively developed</p> <p>Google Cloud libraries (<code>google-cloud-*</code>) - High level - Hand written - Built on top of the low level clients</p>"},{"location":"client_generation/#google-api-client-maintenance-mode","title":"google-api-client - <code>maintenance mode</code>","text":"<ul> <li>google-api-nodejs-client</li> <li>google-api-php-client</li> <li>google-api-python-client</li> <li>google-api-ruby-client</li> <li>google-api-go-client</li> <li>google-api-go-generator</li> <li>google-api-java-client</li> <li>google-api-javascript-client - not officially marked as maintenance, however no new updates since May 2017.</li> <li>google-api-dotnet-client</li> <li>google-api-objectivec-client</li> <li>Deprecated. Replaced entirely by google-api-objectivec-client-for-rest</li> <li>google-api-cpp-client</li> </ul>"},{"location":"client_generation/#apis-client-generator-active","title":"apis-client-generator - <code>active</code>","text":"<ul> <li>apis-client-generator</li> <li>Java, C++, C#, GWT, PHP, Dart</li> <li>Used to generate <code>google-api-java-client</code></li> <li>Recommended way to generate bindings for REST APIs</li> </ul>"},{"location":"client_generation/#apitools-maintenance-mode","title":"apitools - <code>maintenance mode</code>","text":"<ul> <li>apitools</li> <li>Generates Python only. Used by gcloud CLI</li> <li>Writes protobuf files from API discovery</li> </ul>"},{"location":"client_generation/#google-cloud-active","title":"google-cloud - <code>active</code>","text":"<p>Actively developed. Google Cloud APIs only.</p> <ul> <li>google-cloud-ruby</li> <li>google-cloud-node</li> <li>google-cloud-python</li> <li>google-cloud-go</li> <li>google-cloud-java</li> <li>google-cloud-php</li> <li>google-cloud-dotnet</li> </ul>"},{"location":"client_generation/#googleapistoolkit-active","title":"googleapis/toolkit - <code>active</code>","text":"<p>The latest code generation tech from Google.</p> <ul> <li>googleapis/toolkit</li> <li>googleapis/api-compiler</li> </ul>"},{"location":"client_generation/#generating-java-apis-with-apis-client-generator","title":"Generating Java APIs with <code>apis-client-generator</code>","text":"<p>Install Google API client generator from source.</p> <pre><code>git clone https://github.com/google/apis-client-generator.git\npip install .\n</code></pre> <p>Generate the library manually:</p> <pre><code> generate_library \\\n    --input=./testing_v1.json \\\n    --language=java \\\n    --output_dir=./testing\n</code></pre> <p>Alternatively, generate the library by running <code>generate.sh</code></p>"},{"location":"cucumber_support/","title":"Cucumber support","text":"<p>Firebase test lab and Flank do not support Cucumber.  However, you could run these tests.   - To make them work properly please disable sharding using <code>.yml</code> options:     <pre><code>flank:\n  disable-sharding: true\n</code></pre>     or by using command-line option     <code>shell script       --disable-sharding</code></p> <ul> <li>If you would like to use orchestrator please make sure that you are using at least version <code>1.3.0</code> of it.</li> <li>Currently, Flank will run Cucumber tests only if there are other Instrumented tests to run in your test apk.      In other cases Flank will fast fail with <code>There are no tests to run</code> message. </li> </ul>"},{"location":"dependencies_update_process/","title":"Dependencies update process","text":""},{"location":"dependencies_update_process/#description","title":"Description","text":"<p>Process run commands and update files with defined versions in the provided file and create PR with changes.</p>"},{"location":"dependencies_update_process/#modules","title":"Modules","text":"<ol> <li>Gradle Versions Plugin which check dependencies version and generate report</li> <li>Command in <code>flank-scripts</code> which update dependencies versions</li> <li>GitHub action job which runs dependencies check every Monday at 5 AM UTC or on-demand</li> </ol>"},{"location":"dependencies_update_process/#usage","title":"Usage","text":""},{"location":"dependencies_update_process/#manually-root-directory","title":"Manually (root directory)","text":"<ol> <li>Generate report using command <code>./gradlew dependencyUpdates -DoutputFormatter=json -DoutputDir=.</code></li> <li>Build flank scripts using script <code>./flank-scripts/bash/buildFlankScripts.sh</code></li> <li>Run <code>./flank-scripts/bash/flankScripts dependencies update</code></li> </ol>"},{"location":"dependencies_update_process/#github-action","title":"GitHub action","text":"<p>Run <code>Update dependencies</code> job using GitHub action menu by clicking <code>Run workflow</code> button</p>"},{"location":"dependencies_update_process/#merging-to-master","title":"Merging to master","text":""},{"location":"dependencies_update_process/#success-path","title":"Success path","text":"<p>If all PR jobs will succeed it means that dependencies update will not break the current code base and pull requests could be successfully merged.</p>"},{"location":"dependencies_update_process/#failure-path","title":"Failure path","text":"<p>If any of PR job will fail, it means that dependencies update will break our codebase and code should be aligned before merging</p>"},{"location":"exit_codes_and_exceptions/","title":"Flank exit codes and exceptions","text":"<p>Exit code  | Returned by exception | Description  --        |                    -- |            -- | 0          | | All tests passed 1          | FlankGeneralError, FlankTimeoutError | A general failure occurred. Possible causes include: a filename that does not exist or an HTTP/network error. 2          | FlankConfigurationError, YmlValidationError | Usually indicates missing or wrong usage of flags, incorrect parameters, errors in config files. 3          | FlankNoTestsError | No tests detected in the test apk, or they have been filtered out.  10         | FailedMatrixError | At least one matrix not finished (usually a FTL internal error) or unexpected error occurred. 15         | FTLError | Firebase Test Lab could not determine if the test matrix passed or failed, because of an unexpected error. 18         | IncompatibleTestDimensionError | The test environment for this test execution is not supported because of incompatible test dimensions. This error might occur if the selected Android API level is not supported by the selected device type. 19         | MatrixCanceledError | The test matrix was canceled by the user. 20         | InfrastructureError | A test infrastructure error occurred.</p>"},{"location":"flank_corellium/","title":"Flank - Corellium","text":"<p>Run mobile tests in parallel on virtual devices driven by Corellium backend.</p>"},{"location":"flank_corellium/#status","title":"Status","text":"<p>The Flank - Corellium integration is at the MVP stage, so only the core and most important features are available.</p> <p>Read more about Minimum Viable Product.</p>"},{"location":"flank_corellium/#supported-api-levels","title":"Supported API levels","text":"<p>The following Android API levels are supported: 25, 27, 28, 29, and 30. Additional API levels may be added based on customer feedback.</p>"},{"location":"flank_corellium/#why-corellium","title":"Why Corellium","text":"<p>Flank is just a client-side application that can prepare a time-efficient parallel test plan to run on several devices. It requires a third-party provider that can serve a huge amount of devices to run tests on them.  Corellium is solving this problem as follows:</p> <ul> <li>Provides technology to virtualize mobile operating systems on servers powered by ARM cores. - This gives an incredible ability for scaling with regards to the amount of devices.</li> <li>Gives access to the bare operating system (Android or iOS). - Which allows a run optimized sharding algorithm that improves test execution time and reduces costs.</li> </ul>"},{"location":"flank_corellium/#how-to-get","title":"How to get","text":""},{"location":"flank_corellium/#the-latest-build","title":"The Latest build","text":"<p>Flank - Corellium integration is built in the <code>flank.jar</code> executable, so the latest Flank build gives you access to the features driven on the Corellium backend.</p>"},{"location":"flank_corellium/#manual-compilation","title":"Manual compilation","text":"<p>Clone the repository and go to dir:</p> <pre><code>git clone git@github.com:Flank/flank.git\ncd flank\n</code></pre> <p>Build flank using flank-scripts (this method will give you access to <code>flank.jar</code> through <code>flank</code> shell command):</p> <pre><code>. .env\nflankScripts assemble flank\n</code></pre> <p>Or build directly using gradle command:</p> <pre><code>./gradlew :test_runner:build :test_runner:shadowJar\n</code></pre>"},{"location":"flank_corellium/#how-to-run","title":"How to run","text":"<p>To call the root command for Corellium related features:</p> <p>locate your flank.jar in terminal and run:</p> <pre><code>flank.jar corellium\n</code></pre> <p>or if flank was build using <code>. .env &amp;&amp; flankScripts assemble flank</code>, just type:</p> <pre><code>flank corellium\n</code></pre>"},{"location":"flank_corellium/#authorization","title":"Authorization","text":"<p>To allow Flank working with Corellium backend is necessary to provide authentication data. By default, Flank is recognizing <code>corellium_auth.yml</code> as an authentication file, which should look as follows:</p> <pre><code>host: your.corellium.backend.host\nusername: your_username\npassword: your_password\n</code></pre>"},{"location":"flank_corellium/#android-test-execution","title":"Android test execution","text":"<p>To execute android instrumented tests, run following command:</p> <pre><code>$ flank.jar corellium test android run -c=\"./flank_corellium.yml\"\n</code></pre>"},{"location":"flank_corellium/#config","title":"Config","text":"<p>The example configuration file looks following:</p> <pre><code>### Test apks\n## The list of app and test apks.\n## Each app apk must have one or more corresponding test apks.\napks:\n  - path: \"app1.apk\"\n    tests:\n      - path: \"app1-test1.apk\"\n  - path: \"app2.apk\"\n    tests:\n      - path: \"app2-test1.apk\"\n      - path: \"app2-test2.apk\"\n\n### Test Targets\n## A list of one or more test target filters to apply (default: run all test targets).\n## Each target filter must be fully qualified with the package name, class name, or test annotation desired.\n## Supported test filters by am instrument -e \u2026 include:\n## class, notClass, size, annotation, notAnnotation, package, notPackage, testFile, notTestFile\n## See https://developer.android.com/reference/android/support/test/runner/AndroidJUnitRunner for more information.\n# test-targets:\n#  - class com.example.app.ExampleUiTest#testPasses\n#  - package com.example.app.foo\n#  - notPackage com.example.app.bar\n\n### Authorization file\n## Path to YAML file with host address and credentials.\n## default: corellium_auth.yml\n# auth: auth_file.yml\n\n### Project name\n## The name of Corellium project.\n## default: \"Default project\"\n# project: \"project name\"\n\n### Max Test Shards\n## The amount of groups to split the test suite into.\n## default: 1\n# max-test-shards: 10000\n\n### Results Directory\n## The name of a local directory where test results will be stored.\n## default: results/corellium/android/yyyy-MM-dd_HH-mm-ss-SSS\n# local-result-dir: test-results\n\n### Obfuscate dump\n## Replace internal test names with unique identifiers, before dumping them to \"android-shards.json\".\n## This option is hiding sensitive details about tests.\n## default: false\n# obfuscate: true\n\n### Configure JUnit reports\n## A map of name suffixes related to set of result types required to include in custom junit report.\n## Available result types to include are: [Skipped, Passed, Failed, Flaky] (values are not case-sensitive).\n## As results, this option will generate additional amount of junit reports named `JUnitReport-$suffix.xml`.\n## For example the default configuration will generate JUnitReport-failures.xml.  \n## default: failures: [Failed, Flaky]\n# junit-report-config:\n#   skipped: [Skipped]\n#   passed: [PASSED]\n#   failures: [failed, flaky]\n</code></pre>"},{"location":"flank_corellium/#command-line-arguments","title":"Command-line arguments","text":"<p>These can be included alongside the configuration file. They will override or supplement the configuration file depending on the usage.</p>"},{"location":"flank_corellium/#execution","title":"Execution","text":"<p>The test execution is composing small steps to fulfill operations like:</p> <ul> <li>Calculating time-efficient sharding.</li> <li>Preparing (creating or reusing) virtual devices for test execution.</li> <li>Executing tests on prepared virtual devices.</li> <li>Generating report.</li> </ul> <p>To learn more about the execution process check the:</p> <ul> <li>Architecture design - which is explaining some core abstract concepts.</li> <li>Corellium integration diagrams - to visualise relations and dependencies between layers.</li> <li>Domain module design &amp; implementation - for detailed information about business logic and low-level implementation design.</li> </ul>"},{"location":"flank_corellium/#results","title":"Results","text":"<p>The command execution process is generating different types of output.</p>"},{"location":"flank_corellium/#console-logs","title":"Console logs","text":"<p>The process during its runtime is printing detailed information about execution steps to console log.</p>"},{"location":"flank_corellium/#output-files","title":"Output files","text":"<p>The successful run should generate the following files:</p> <ul> <li>JUnitReport.xml - raw report with reruns.</li> <li>JUnitReport_failures.xml - only failed and flaky tests.</li> <li>or any report files generated according to <code>junit-report-config</code> option.</li> <li>android_shards.json</li> <li>adb_log</li> <li>Directory that contains dumped log from <code>am instrument</code> commands.</li> <li>Each dump name is related instance id.</li> </ul>"},{"location":"flank_corellium/#errors","title":"Errors","text":"<p>The execution or its part can fail due to exceptions occur.  Typically, most of the errors can be sourced in incorrect initial arguments or network issues.  </p> <p>List of known possible errors:</p>"},{"location":"flank_corellium/#test-result-parsing","title":"Test result parsing","text":"<p>Flank is using <code>am instrument</code> command to execute tests on Corellium devices. The console output of the device is collected and parsed until all expected tests return their results. Due to an invalid apk file, the console can print unexpected output that cannot be parsed by Flank. In this case, Flank will print an error message similar to the following:</p> <pre><code>Error while parsing results from instance { instance id }.\nFor details check \"results/corellium/android/{ report_dir }/adb_log/{ instance id }\" lines { from..to }.\njava.lang.Exception\n    at flank.corellium.cli.RunTestCorelliumAndroidCommandTest.outputTest(RunTestCorelliumAndroidCommandTest.kt:242)\n    { ... }\n</code></pre> <p>The visible exception is related directly to the parsing issue. To see the source of the problem check the log file referenced in the error message. The file should contain a direct dump from <code>am instrument command</code>. </p>"},{"location":"flank_corellium/#features","title":"Features","text":"<ul> <li>Filtering tests using test-targets.</li> <li>Calculating multi-module shards.</li> <li>Reusing test cases duration for sharding.</li> <li>Creating or reusing instances (devices).</li> <li>Installing APKs on remote devices.</li> <li>Running android tests.</li> <li>Flaky test detection.</li> <li>Dumping shards to file.</li> <li>Parsing <code>adb am instrument</code> logs.</li> <li>Generating JUnit report.</li> </ul>"},{"location":"flank_corellium/#roadmap","title":"Roadmap","text":"<ul> <li>Cleaning devices after test execution.</li> <li>iOS support.</li> <li>and much more...</li> </ul>"},{"location":"flank_secrets/","title":"Flank Secrets","text":"<p>Flank securely communicates to Firebase Test Lab using Google's official Java SDKs for authorization.</p>"},{"location":"flank_secrets/#2fa","title":"2FA","text":"<p>Two-factor authentication is required for everyone in the Flank organization.</p>"},{"location":"flank_secrets/#running-flank","title":"Running Flank","text":"<p>Flank runs require authorization with either a Google user account or a service account. Service accounts are the recommended way to authenticate to Flank instead of using a personal account. The authorization credential is saved by default to: <code>$HOME/.config/gcloud/application_default_credentials.json</code></p>"},{"location":"flank_secrets/#developing-flank","title":"Developing Flank","text":"<p>The Flank release job requires secrets as part of continuous delivery. We use our Sonatype account for releasing a new version of Flank to the Maven Central Repository.</p>"},{"location":"flank_vision/","title":"Flank Vision","text":"<p>Flank is a massively parallel Android and iOS test runner for Firebase Test Lab.</p>"},{"location":"flank_vision/#gcloud-compatible","title":"GCloud Compatible","text":"<p>Flank is a Kotlin reimplementation of gcloud firebase test commands. Flank strives to implement all gcloud test commands using compatible YAML syntax. The CLI flags match when possible.</p> <p>The same <code>flank.yml</code> file can be run with both gcloud and Flank.</p> <ul> <li><code>gcloud firebase test android run flank.yml:gcloud</code></li> <li><code>flank firebase test android run -c flank.yml</code></li> </ul>"},{"location":"flank_vision/#industry-enabling-features","title":"Industry enabling features","text":"<p>Flank adds features on top of gcloud CLI, such as test sharding for iOS, to improve the developer experience. The goal of Flank's features is to be implemented in the server so that all test lab customers may benefit, not just those who use Flank. By upstreaming Flank features, a new set of even more awesome capabilities can be developed on top of the server API.</p>"},{"location":"flank_vision/#vision","title":"Vision","text":"<p>Today the Flank team is focused on bug fixes and stabilization in both the test runner and the Fladle plugin. In the future Flank may adopt a gRPC API to enable other software to easily be built on top of Flank. Examples include test analytics and test flakiness management.</p>"},{"location":"flutter_status/","title":"Current Flutter status","text":"<p>Investigation of flutter-android support on gcloud including test sharding.</p>"},{"location":"flutter_status/#gcloud","title":"Gcloud","text":"<p>In the gcloud we can use following commands to run tests in shards:</p> <ul> <li><code>--num-uniform-shards</code></li> <li><code>--test-targets-for-shard</code></li> <li><code>--test-targets</code> - this option is not designed directly for sharding but filtering</li> </ul>"},{"location":"flutter_status/#preparing-flutter-app","title":"Preparing flutter app","text":"<p>All following tests require a flutter app for testing that can be build using following script:</p> <pre><code>flutter build apk\ndir=$(pwd)\npushd android\n\n./gradlew app:assembleAndroidTest\n\n./gradlew app:assembleDebug -Ptarget=$dir\"/integration_tests/integration_tests.dart\"\n\npopd\n</code></pre>"},{"location":"flutter_status/#-num-uniform-shards","title":"--num-uniform-shards","text":"<p>Test:</p> <pre><code>gcloud alpha firebase test android run \\\n  --project flank-open-source \\\n  --type instrumentation \\\n  --app build/app/outputs/apk/debug/app-debug.apk \\\n  --test build/app/outputs/apk/androidTest/debug/app-debug-androidTest.apk \\\n  --num-uniform-shards=3 \\\n  --timeout 5m\n</code></pre> <p>Result:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 OUTCOME \u2502    TEST_AXIS_VALUE     \u2502          TEST_DETAILS         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Failed  \u2502 walleye-27-en-portrait \u2502 1 test cases failed, 5 passed \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"flutter_status/#expected-behaviour","title":"Expected behaviour","text":"<p>The Flutter example app contains 6 test methods, so according to doc,  the gcloud should create 3 shards,  each shard should contain 2 methods.</p>"},{"location":"flutter_status/#investigation-results","title":"Investigation results","text":"<ul> <li>One shard contains all test's</li> <li>Two other shards are being empty.</li> </ul>"},{"location":"flutter_status/#conclusions","title":"Conclusions","text":"<p>The result is different from expected behaviour.</p>"},{"location":"flutter_status/#-test-targets-for-shard","title":"--test-targets-for-shard","text":"<p>Using this option you can specify shards targets by:</p> <ul> <li><code>method</code> - test method name</li> <li><code>class</code> - test class name</li> <li><code>package</code> - test package name</li> <li><code>annotation</code></li> </ul>"},{"location":"flutter_status/#sharding-by-method","title":"Sharding by method","text":"<p>Test:</p> <pre><code>gcloud alpha firebase test android run \\\n  --project flank-open-source \\\n  --type instrumentation \\\n  --app build/app/outputs/apk/debug/app-debug.apk \\\n  --test build/app/outputs/apk/androidTest/debug/app-debug-androidTest.apk \\\n  --test-targets-for-shard \"class org.flank.flutter_example.MainActivityTest#success_test_example_5\" \\\n  --timeout 5m\n</code></pre> <p>Where: <code>success_test_example_5</code> is a dart test.</p> <p>Result:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 OUTCOME \u2502    TEST_AXIS_VALUE     \u2502    TEST_DETAILS    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Failed  \u2502 walleye-27-en-portrait \u2502 Test failed to run \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"flutter_status/#expected-behaviour_1","title":"Expected behaviour","text":"<p>The gcloud should run only one shard with one test method: <code>org.flank.flutter_example.MainActivityTest#success_test_example_5</code></p>"},{"location":"flutter_status/#investigation-results_1","title":"Investigation results","text":"<p>Gcloud is returning <code>Test failed to run</code> as test details, no test are being run.</p>"},{"location":"flutter_status/#conclusions_1","title":"Conclusions","text":"<ul> <li>gcloud can't find dart tests.</li> <li>gcloud will create an empty shard.</li> </ul>"},{"location":"flutter_status/#sharding-by-class-or-package","title":"Sharding by class or package","text":"<p>Test:</p> <pre><code>gcloud alpha firebase test android run \\\n  --project flank-open-source \\\n  --type instrumentation \\\n  --app build/app/outputs/apk/debug/app-debug.apk \\\n  --test build/app/outputs/apk/androidTest/debug/app-debug-androidTest.apk \\\n  --test-targets-for-shard \"class org.flank.flutter_example.MainActivityTest\" \\\n  --timeout 5m\n</code></pre> <p>or</p> <pre><code>gcloud alpha firebase test android run \\\n  --project flank-open-source \\\n  --type instrumentation \\\n  --app build/app/outputs/apk/debug/app-debug.apk \\\n  --test build/app/outputs/apk/androidTest/debug/app-debug-androidTest.apk \\\n  --test-targets-for-shard \"package org.flank.flutter_example\" \\\n  --timeout 5m\n</code></pre> <p>Result:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 OUTCOME \u2502    TEST_AXIS_VALUE     \u2502          TEST_DETAILS         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Failed  \u2502 walleye-27-en-portrait \u2502 1 test cases failed, 5 passed \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"flutter_status/#expected-behaviour_2","title":"Expected behaviour","text":"<p>The gcloud should run all tests, one tests is failing intentionally.</p>"},{"location":"flutter_status/#investigation-results_2","title":"Investigation results","text":"<p>Test results are same as expected.</p>"},{"location":"flutter_status/#conclusions_2","title":"Conclusions","text":"<p>The gcloud can run tests by class or package if there are exists in test apk as normal android test.</p>"},{"location":"flutter_status/#-test-targets","title":"--test-targets","text":"<p>This option works similar to Using this option you can filter test cases for running only the specified units:</p> <ul> <li><code>method</code> - test method name</li> <li><code>class</code> - test class name</li> <li><code>package</code> - test package name</li> <li><code>annotation</code></li> </ul>"},{"location":"flutter_status/#filtering-by-method","title":"Filtering by method:","text":"<p>Test:</p> <pre><code>gcloud alpha firebase test android run \\\n  --project flank-open-source \\\n  --type instrumentation \\\n  --app build/app/outputs/apk/debug/app-debug.apk \\\n  --test build/app/outputs/apk/androidTest/debug/app-debug-androidTest.apk \\\n  --test-targets \"class org.flank.flutter_example.MainActivityTest#success_test_example_5\" \\\n  --timeout 5m\n</code></pre> <p>Result:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 OUTCOME \u2502    TEST_AXIS_VALUE     \u2502    TEST_DETAILS    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Failed  \u2502 walleye-27-en-portrait \u2502 Test failed to run \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"flutter_status/#filtering-by-class-or-package","title":"Filtering by class or package:","text":"<p>Test:</p> <pre><code>gcloud alpha firebase test android run \\\n  --project flank-open-source \\\n  --type instrumentation \\\n  --app build/app/outputs/apk/debug/app-debug.apk \\\n  --test build/app/outputs/apk/androidTest/debug/app-debug-androidTest.apk \\\n  --test-targets \"class org.flank.flutter_example.MainActivityTest\" \\\n  --timeout 5m\n</code></pre> <p>or</p> <pre><code>gcloud alpha firebase test android run \\\n  --project flank-open-source \\\n  --type instrumentation \\\n  --app build/app/outputs/apk/debug/app-debug.apk \\\n  --test build/app/outputs/apk/androidTest/debug/app-debug-androidTest.apk \\\n  --test-targets \"package org.flank.flutter_example\" \\\n  --timeout 5m\n</code></pre> <p>Result:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 OUTCOME \u2502    TEST_AXIS_VALUE     \u2502          TEST_DETAILS         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Failed  \u2502 walleye-27-en-portrait \u2502 1 test cases failed, 5 passed \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"flutter_status/#expected-behaviour_3","title":"Expected behaviour","text":"<p>The gcloud should run all tests, one tests is failing intentionally.</p>"},{"location":"flutter_status/#investigation-results_3","title":"Investigation results","text":"<p>Test results are same as expected.</p>"},{"location":"flutter_status/#conclusions_3","title":"Conclusions","text":"<p>The gcloud can filter tests by class or package if there are exists in test apk as normal android test.</p>"},{"location":"flutter_status/#summary-conclusion","title":"Summary conclusion","text":"<ul> <li> <p>Gcloud can run flutter tests without sharding. You can find example   in flutter_example, simple   run build_and_run_tests_firebase.sh.</p> </li> <li> <p>Gcloud is not supporting sharding for Flutter, because all <code>dart</code> tests according to   the flutter integration tests doc are hidden   behind android test class   and are not visible for gcloud.</p> </li> </ul>"},{"location":"flutter_status/#flank","title":"Flank","text":"<pre><code>gcloud:\n  app: ./test_projects/flutter/flutter_example/build/app/outputs/apk/debug/app-debug.apk\n  test: ./test_projects/flutter/flutter_example/build/app/outputs/apk/androidTest/debug/app-debug-androidTest.apk\n\nflank:\n  disable-sharding: true\n</code></pre> <p>Result:</p> <pre><code>  Saved 0 shards to [...]/android_shards.json\n  Uploading [android_shards.json] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-23_12-02-26.392553_lYnS/...\n\nThere are no tests to run.\n</code></pre>"},{"location":"flutter_status/#expected-behaviour_4","title":"Expected behaviour","text":"<p>The gcloud should run all tests, one tests is failing intentionally.</p>"},{"location":"flutter_status/#investigation-results_4","title":"Investigation results","text":"<p>Currently, Flank cannot run any flutter tests. That happens because flank is calculating test methods using  Flank using DexParser even with option <code>disable-sharding</code>. This behaviour probably could be fixed but requires more investigation.</p>"},{"location":"flutter_status/#how-to-create-flutter-tests-for-firebase","title":"How to create flutter tests for firebase","text":"<p>See the Flutter Integration test plugin documentation with example.</p>"},{"location":"flutter_status/#android-side","title":"Android side","text":"<pre><code>@RunWith(FlutterTestRunner.class)\npublic class MainActivityTest {\n    @Rule\n    public ActivityTestRule&lt;MainActivity&gt; rule = new ActivityTestRule&lt;&gt;(MainActivity.class, true, false);\n}\n</code></pre>"},{"location":"flutter_status/#flutter-side","title":"Flutter side","text":"<p>This is the test app entry point.</p> <pre><code>void main() {\n  IntegrationTestWidgetsFlutterBinding.ensureInitialized();\n  testWidgets(\"success test example\", (WidgetTester tester) async {\n    // Wait for app widget\n    await tester.pumpWidget(MyApp());\n\n    // Verify that our counter starts at 0.\n    expect(find.text('0'), findsOneWidget);\n    expect(find.text('1'), findsNothing);\n\n    // Tap the '+' icon and trigger a frame.\n    await tester.tap(find.byIcon(Icons.add));\n    await tester.pump();\n\n    // Verify that our counter has incremented.\n    expect(find.text('0'), findsNothing);\n    expect(find.text('1'), findsOneWidget);\n  });\n}\n</code></pre> <p>You need to compile the Flutter app with few steps</p> <pre><code>flutter build apk\n</code></pre> <pre><code>./gradlew app:assembleAndroidTest\n</code></pre> <pre><code>./gradlew app:assembleDebug -Ptarget=\"path to test entry point eg. $dir/integration_tests/integration_tests.dart\"\n</code></pre> <p>All dart tests are placed in <code>app-debug.apk</code> instead of <code>app-debug-androidTest.apk</code>. That's why Flank doesn't see flutter tests.</p>"},{"location":"flutter_status/#how-flutter-tests-work-in-firebase","title":"How flutter tests work in firebase","text":"<p>Flutter Integration Test plugin use <code>channel</code> to communicate between <code>FlutterTestRunner</code>on android side and dart code.  When dart tests was finished, flutter send information about test results to native code.  Native code receive information's in <code>IntegrationTestPlugin.onMethodCall()</code>.  <code>FlutterTestRunner</code> sets test statuses in method <code>FlutterTestRunner.run()</code> in lines:</p> <ol> <li><code>notifier.fireTestStarted(d);</code></li> <li><code>notifier.fireTestFailure(new Failure(d, dummyException));</code></li> <li><code>notifier.fireTestFinished(d);</code></li> </ol>"},{"location":"flutter_status/#hypothetical-solution-to-allow-flank-run-flutter-tests","title":"Hypothetical solution to allow flank run flutter tests","text":""},{"location":"flutter_status/#run-test-without-sharding","title":"Run test without sharding","text":"<ul> <li>We can try to turn off fetching test methods by dexparser when <code>disable-sharding</code> is set to true</li> </ul>"},{"location":"flutter_status/#sharding-support","title":"Sharding support","text":"<ol> <li> <p>Create a channel to communicate native tests with dart code.</p> </li> <li> <p>Send from native code information about the test to run.</p> </li> <li> <p>Receive the test name and run it on dart code.</p> </li> <li> <p>After the test end send results to native code.</p> </li> <li> <p>Report results.</p> </li> </ol> <p>Probably this solution needs flutter plugin development. We need to create POC to check if it's possible to do. </p>"},{"location":"getting_delete_permission_exception_when_using_results-dir_option/","title":"Getting delete permission exception when using results-dir option #790","text":""},{"location":"getting_delete_permission_exception_when_using_results-dir_option/#changelog","title":"Changelog","text":"Date Who? Action 7th July 2020 pawelpasterz created"},{"location":"getting_delete_permission_exception_when_using_results-dir_option/#description","title":"Description","text":"<p>I am trying enable code-coverage and seeing this error <code>java.lang.RuntimeException: com.google.cloud.storage.StorageException: firebase-test-lab@sofi-test.iam.gserviceaccount.com</code> does not have storage.objects.delete access to cloud-test-sofi-test/coverage_ec/app-debug-androidTest.apk. Does the service account need higher permissions? wondering why delete is needed though (edited) I also tried with orchestrator, that didn't change anything.</p> <p>User's yml file <pre><code>gcloud:\n   results-bucket: cloud-test-sofi-test\n   record-video: true\n   app: ../app/build/outputs/apk/debug/app-debug.apk\n   test: ../app/build/outputs/apk/androidTest/debug/app-debug-androidTest.apk\n   use-orchestrator: false\n   environment-variables:\n    endpoint: https://testendponit.com/\n   performance-metrics: false\n   num-flaky-test-attempts: 1\n   device:\n   - model: Nexus5X\n     version: 26\n     locale: en\n     orientation: portrait\nflank:\n   local-result-dir: ../app/build/test-results/ui-tests/\n</code></pre></p> <p>Stacktrace: <pre><code>RunTests\n   Uploading app-debug-androidTest.apk .  Uploading app-debug.apk .\n java.lang.RuntimeException: com.google.cloud.storage.StorageException: firebase-test-lab@sofi-test.iam.gserviceaccount.com does not have storage.objects.delete access to cloud-test-sofi-test/coverage_ec/app-debug-androidTest.apk.\n    at ftl.gc.GcStorage.upload(GcStorage.kt:144)\n    at ftl.gc.GcStorage.upload(GcStorage.kt:50)\n    at ftl.run.AndroidTestRunner$resolveApks$2$invokeSuspend$$inlined$forEach$lambda$2.invokeSuspend(AndroidTestRunner.kt:77)\n    at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)\n    at kotlinx.coroutines.DispatchedTask.run(Dispatched.kt:241)\n    at kotlinx.coroutines.scheduling.CoroutineScheduler.runSafely(CoroutineScheduler.kt:594)\n    at kotlinx.coroutines.scheduling.CoroutineScheduler.access$runSafely(CoroutineScheduler.kt:60)\n    at kotlinx.coroutines.scheduling.CoroutineScheduler$Worker.run(CoroutineScheduler.kt:740)\n    Suppressed: java.lang.RuntimeException: com.google.cloud.storage.StorageException: firebase-test-lab@sofi-test.iam.gserviceaccount.com does not have storage.objects.delete access to cloud-test-sofi-test/coverage_ec/app-debug.apk.\n        at ftl.gc.GcStorage.upload(GcStorage.kt:144)\n        at ftl.gc.GcStorage.upload(GcStorage.kt:50)\n        at ftl.run.AndroidTestRunner$resolveApks$2$invokeSuspend$$inlined$forEach$lambda$1.invokeSuspend(AndroidTestRunner.kt:76)\n        ... 5 more\n    Caused by: com.google.cloud.storage.StorageException: firebase-test-lab@sofi-test.iam.gserviceaccount.com does not have storage.objects.delete access to cloud-test-sofi-test/coverage_ec/app-debug.apk.\n</code></pre></p>"},{"location":"getting_delete_permission_exception_when_using_results-dir_option/#steps-to-reproduce","title":"Steps to reproduce","text":"<p>Unfortunately I was unable to reproduce this error (state for 7th July 2020). If any new information will be available -- this paragraph should be updated.</p> <p>What was done: 1. new FTL project with admin account + one service account (default editor permissions)     1. two flank's run with the same apks and <code>result-dir</code> (for both admin and service accounts)     2. first flank run as admin account and second as service account 2. new FTL project with two service accounts (default editor permissions) -- let's call them A &amp; B     1. first flank run as A and second as B     2. repeat above but with reversed order     3. all above with the same apks and <code>results-dir</code></p>"},{"location":"getting_delete_permission_exception_when_using_results-dir_option/#comments-and-thoughts","title":"Comments and thoughts","text":"<ol> <li>According to google docs <code>--results-dir</code> it is recommended use unique value for each run. Google Docs</li> <li><code>Caution: if specified, this argument must be unique for each test matrix you create, otherwise results from multiple test matrices will be overwritten or intermingled.</code> -- that indicates there is deletion action performed when file with the same name is being uploaded. Therefor <code>storage.object.delete</code> is required to do so.</li> <li>Google Cloud IAM Permissions: <code>Note: In order to overwrite existing objects, both storage.objects.create and storage.objects.delete permissions are required.</code> -- as confirmation of above</li> <li>Service account with <code>Editor</code> role does not have <code>storage.object.delete</code> Permissions</li> <li> <p>Flank uploads files to storage with the Google client and its logic is rather simple (no additional logic with creating/changing/modifying roles and permissions):</p> <pre><code>val fileBlob = BlobInfo.newBuilder(rootGcsBucket, validGcsPath).build()\nstorage.create(fileBlob, fileBytes)\n</code></pre> </li> <li> <p>There might have been some changes on the Google Cloud Storage side with permissions (guessing)</p> </li> <li>There were lots of changes since flank <code>8.1.0</code>. We know <code>8.1.0</code> version had some issues with upload,caching and overlapping results.</li> </ol>"},{"location":"getting_delete_permission_exception_when_using_results-dir_option/#conclusion","title":"Conclusion","text":"<p>Some time was spent on this issue but no results, with given input and info, were achieved. Team should track any future issues similar to this one and update doc if any new input will be available.</p>"},{"location":"host_binaries_solutions_comparison/","title":"Host binaries solutions comparison","text":""},{"location":"host_binaries_solutions_comparison/#git-lfs","title":"git-lfs","text":"<p>Docs can be found at git-lfs.github.com</p>"},{"location":"host_binaries_solutions_comparison/#costs","title":"Costs","text":"<p>about-storage-and-bandwidth-usage</p> <p>Each data pack cost is $5 per month. It contains:</p> <ol> <li>50gb bandwidth</li> <li>50gb storage</li> </ol>"},{"location":"host_binaries_solutions_comparison/#is-git-lfs-versioning-files","title":"Is git lfs versioning files?","text":"<p>Yes. Git LFS versioning files and show changed md5 sum and size.</p> <p>On main repository git diff looks like:</p> <pre><code>diff --git a/app/build/outputs/apk/release/app-release-unsigned.apk b/app/build/outputs/apk/release/app-release-unsigned.apk\nindex bba31d0..d165ca1 100644\n--- a/app/build/outputs/apk/release/app-release-unsigned.apk\n+++ b/app/build/outputs/apk/release/app-release-unsigned.apk\n@@ -1,3 +1,3 @@\n version https://git-lfs.github.com/spec/v1\n-oid sha256:bf48d577836f07a3d625ee30f04eb356c0b1158770f613df0d82b6ef40d300d3\n-size 1938709\n+oid sha256:3349370934f8a1695b6ace6db53e58c0f24a1d9c02ce703b4a78870175c8c066\n+size 1938769\n</code></pre>"},{"location":"host_binaries_solutions_comparison/#how-to-configure-git-lfs","title":"How to configure git lfs?","text":"<p>To add a file extension to git lfs you should execute the following command:</p> <pre><code>git lfs track \"*.apk\"\n</code></pre> <p>Now all files with <code>.apk</code> extensions will be added to git lfs</p>"},{"location":"host_binaries_solutions_comparison/#how-to-add-file","title":"How to add file","text":"<p>The file should be added in <code>normal</code> way to git</p> <pre><code>git add app-debug.apk\ngit commit -m \"Add apk file\"\ngit push origin master\n</code></pre>"},{"location":"host_binaries_solutions_comparison/#how-to-play-with-branches","title":"How to play with branches","text":"<p>There is nothing to configure. When you modify files on branch changes not shown on the master.</p>"},{"location":"host_binaries_solutions_comparison/#git-submodules","title":"git-submodules","text":"<p>Docs can be found at gist.github.com/gitaarik/8735255</p>"},{"location":"host_binaries_solutions_comparison/#is-git-submodules-versioning-files","title":"Is git submodules versioning files?","text":"<p>Git submodule is another git repository linked to the main repository. On main repository git diff looks like:</p> <pre><code>diff --git a/apks b/apks\n--- a/apks\n+++ b/apks\n@@ -1 +1 @@\n-Subproject commit 7036bcb56be19490b4445a7e31e821e80b9ff870\n+Subproject commit 7036bcb56be19490b4445a7e31e821e80b9ff870-dirty\n</code></pre> <p>So from the main repository, we don't see what files changed. To check details we need to execute git diff from the submodule.</p>"},{"location":"host_binaries_solutions_comparison/#is-git-submodule-versioning-files","title":"Is git submodule versioning files?","text":"<p>Yes. Git Submodule versioning binary files like standard git repository.</p>"},{"location":"host_binaries_solutions_comparison/#how-to-configure-git-submodule","title":"How to configure git submodule?","text":"<ol> <li> <p>Create a submodule repository</p> </li> <li> <p>On <code>main</code> execute repository git submodule add git@github.com:url_to/awesome_submodule.git path_to_awesome_submodule.</p> </li> <li> <p>Execute <code>git submodule init</code></p> </li> </ol>"},{"location":"host_binaries_solutions_comparison/#how-to-add-file_1","title":"How to add file","text":"<p>Goto submodule directory</p> <pre><code>git add app-debug.apk\ngit commit -m \"Add apk file\"\ngit push origin master\n</code></pre>"},{"location":"host_binaries_solutions_comparison/#how-to-play-with-branches_1","title":"How to play with branches","text":"<p>Actually there is an option to track specific branch on submodule. https://stackoverflow.com/questions/9189575/git-submodule-tracking-latest</p>"},{"location":"host_binaries_solutions_comparison/#git-annex","title":"git-annex","text":"<p>Docs can be found at git-annex Docs for github at git-annex</p> <p>We can configure git-annex to store files in places like ftp, amazon s3, etc. Probably it can reduce costs on many large files. link</p>"},{"location":"host_binaries_solutions_comparison/#costs_1","title":"Costs","text":"<p>Depends on the chosen storage provider</p> <ol> <li>Google drive</li> <li>Limitation to 15gb (free quota)</li> <li>After 15gb need to switch to google one or use Gsuite (10$/month and quota 100gb per user)</li> <li>OneDrive</li> <li>Pricing table: https://www.opendrive.com/pricing</li> <li>Free quota 5gb</li> <li>From table: Custom Plan: 500gb storage and 25gb daily bandwidth : 5$/month 50$/year</li> <li>Droplet/VPS - depend on the provider</li> <li>FTP/SFTP - depend on provider</li> </ol>"},{"location":"host_binaries_solutions_comparison/#is-git-annex-versioning-files","title":"Is git annex versioning files?","text":"<p>Git-annex like git lfs versioning control sum</p> <p>Git diff looks like:</p> <pre><code>@ -1 +1 @@\n../../../../../.git/annex/objects/QJ/ZX/SHA256E-s1938733--a5bd978c2a6a9ff32bdf0ad5bd94c1362d6904c80c8f6d7890a40303a5d1d703.apk/SHA256E-s1938733--a5bd978c2a6a9ff32bdf0ad5bd94c1362d6904c80c8f6d7890a40303a5d1d703.apk\n../../../../../.git/annex/objects/xG/5q/SHA256E-s1938761--038902c65338873f5936f7c5d764fc98839746036a9fffb46223bb742fd1556f.apk/SHA256E-s1938761--038902c65338873f5936f7c5d764fc98839746036a9fffb46223bb742fd1556f.apk\n</code></pre>"},{"location":"host_binaries_solutions_comparison/#how-to-configure-git-annex","title":"How to configure git annex?","text":"<ol> <li> <p>First, you need to install git-annex</p> <pre><code>brew install git-annex\n</code></pre> <p>If you don't have brew installed. Install it from brew.sh</p> <p>Installing on other systems can be found at git-annex install</p> </li> <li> <p>Initialize</p> <p>On root repository</p> <pre><code>git annex init\n</code></pre> </li> </ol>"},{"location":"host_binaries_solutions_comparison/#how-to-add-file_2","title":"How to add file","text":"<pre><code>git annex add app-debug.apk\ngit commit -m \"Add apk file\"\ngit push origin master\n</code></pre>"},{"location":"host_binaries_solutions_comparison/#how-to-override-file","title":"How to override file","text":"<ol> <li> <p>Unlock file</p> <pre><code>git annex unlock app-debug.apk\n</code></pre> </li> <li> <p>Change file</p> </li> <li> <p>Add file to annex</p> <pre><code>git annex add app-debug.apk\n</code></pre> </li> </ol>"},{"location":"host_binaries_solutions_comparison/#where-to-host","title":"Where to host","text":"<p>Git-annex allows to host binary files in different locations, after a little discussion with @jan-gogo we chose top 3:</p> <ol> <li>Google Drive</li> <li>OneDrive</li> <li>Droplet/VPS</li> <li>FTP/SFTP</li> </ol> <p>This list is only our idea feel free to suggest another one.</p> <p>All of the supported storage types can be seen at git-annex special_remotes</p>"},{"location":"host_binaries_solutions_comparison/#how-to-play-with-branches_2","title":"How to play with branches","text":"<p>When you change branch you can override file and commit changes (remember to unlock file first). File will be uploaded on configured storage.</p>"},{"location":"host_binaries_solutions_comparison/#how-to-configure-new-git-annex-repository-with-google-drive","title":"How to configure new git-annex repository with google drive","text":"<ol> <li>Install rclone from downloads.rclone.org</li> <li>Install git-annex-rclone from git-annex-remote-rclone</li> <li>Go to repository directory and in console enter <code>rclone config</code></li> <li>Init remote by <code>git annex initremote CONFIG_NAME type=external externaltype=rclone target=CONFIG_NAME prefix=git-annex chunk=50MiB encryption=shared mac=HMACSHA512 rclone_layout=lower</code></li> <li>You can test remote by <code>git annex testremote</code></li> </ol>"},{"location":"host_binaries_solutions_comparison/#how-to-push-changes-to-remote","title":"How to push changes to remote","text":"<ol> <li> <p>Unlock file <code>git-annex unlock file_name</code></p> </li> <li> <p>Modify file</p> </li> <li> <p>Add file <code>git annex add file_name --force</code></p> </li> <li> <p>Sync changes <code>git annex sync file_name --content</code></p> </li> </ol>"},{"location":"host_binaries_solutions_comparison/#how-to-sync-changes-from-remote","title":"How to sync changes from remote","text":"<ol> <li> <p>If you don't have configured git clone and git-annex with rclone check 1 to 3 points from <code>How to configure new git-annex repository with google drive</code> section</p> </li> <li> <p>execute command <code>git annex enableremote CONFIG_NAME</code></p> </li> <li> <p>After clone repo sync with git-annex <code>git annex sync --content</code></p> </li> </ol>"},{"location":"host_binaries_solutions_comparison/#conclusion","title":"conclusion","text":"GIT LFS GIT SUBMODULES GIT ANNEX Costs 5$/month per pack (50gb) Cannot find clear answer Depend on storage provider Versioning Files Yes Yes Yes Branch support Yes Now there is an option to track specific branch on submodule. https://stackoverflow.com/questions/9189575/git-submodule-tracking-latest Yes Flexibility Yes, you can set your lfs server. Check here No Yes, can use different storage providers. <p>Our requirement is to have remote storage for test artifacts that should cover the following points: * Allow having dedicated artifacts for specific branches. * Free to use * Public read access and restricted write  Git annex was the most promising but we didn't find remote storage that will meet all our requirements. By comparing these three solutions, we decide to stay with GitHub releases and automate the release process using custom Gradle tasks.</p>"},{"location":"hypershard_android/","title":"Hypershard Android","text":"<p>This is an introduction and breakdown of the steps required to make use of Hypershard-android.</p> <p>It should be used in cases where an application has a significant number of UI tests that need to be sharded correctly to run efficiently. On Android UI tests sharding require the entire application to be built first. The hypershard library removes the need for building and outputs a list of all available tests.</p> <p>More information on this can be found at the official library: Hypershard-android</p>"},{"location":"hypershard_android/#installation","title":"Installation","text":"<ol> <li>Releases can be found downloaded from Maven Central<ol> <li>Ensure that you download the correct suffixed as follows <code>*-all.jar</code> library</li> </ol> </li> <li>Alternatively cloning the repository github.com/dropbox/hypershard-android <ol> <li>Then running <code>./gradlew install</code> will produce a valid jarfile in the build directory.</li> </ol> </li> </ol>"},{"location":"hypershard_android/#running","title":"Running","text":"<ol> <li> <p>Open Terminal/cmd/bash</p> </li> <li> <p>Make sure that the hypershard jar file is either copied to the correct location and/or available on the path. </p> </li> <li> <p>Hypershard options are as follows:     ```bash</p> <p>java -jar hypershard-1.1.2-all.jar --help    Usage: hypershardcommand [OPTIONS] [dirs]...</p> <p>Hypershard is a fast and simple test collector that uses the Kotlin and Java  ASTs. Hypershard CLI will print full qualified test names found in dir(s).</p> </li> </ol> <p>Options:      --annotation-name TEXT      Class annotation name to process. For example,                                  if this was set to 'UiTest', then Hypershard                                  will only process classes annotated with                                  @UiTest.      --not-annotation-name TEXT  Class annotation name not to process. For                                  example, if this was set to 'UiTest', then                                  Hypershard will not process classes annotated                                  with @UiTest.      -h, --help                  Show this message and exit</p> <p>Arguments:      dirs  Dir(s) to process. The location of the test classes to parse    ```</p> <ol> <li>An example run of hypershard for flank where the current directory is flank root:</li> </ol> <pre><code>&gt;java -jar hypershard-1.1.2-all.jar ./test_runner/src/test/kotlin/ftl/reports/util/\n</code></pre> <p>Results in the following output    <pre><code>ftl.reports.util.EndsWithTextWithOptionalSlashAtTheEndTest.should properly found end suffix matching text\n</code></pre> 4. Which can be saved by simple bash commands such as the &gt; character for example:     <pre><code>   &gt;java -jar hypershard-1.1.2-all.jar ./test_runner/src/test/kotlin/ftl/reports/util/ &gt; hypershardtests\n</code></pre></p>"},{"location":"hypershard_android/#more-examples","title":"More examples","text":"<p>A python usage example can be found: https://github.com/dropbox/hypershard-android/tree/master/example</p>"},{"location":"hypershard_android/#resources","title":"Resources","text":"<p>https://github.com/dropbox/hypershard-android</p>"},{"location":"hypershard_ios/","title":"Hypershard iOS","text":"<p>This is a step-by-step guide of using Hypershard for companies that are unable to use symbol table dumping on iOS.</p>"},{"location":"hypershard_ios/#installation","title":"Installation","text":"<ol> <li>Clone GitHub repository using<ol> <li>https - <code>git clone https://github.com/dropbox/hypershard-ios.git</code></li> <li>SSH - <code>git clone git@github.com:dropbox/hypershard-ios.git</code></li> <li>GitHub CLI - <code>gh repo clone dropbox/hypershard-ios</code></li> </ol> </li> <li>Install swift if you are not using macOS<ol> <li>https://swift.org/download/#releases</li> </ol> </li> <li>Open Terminal/cmd</li> <li>Change working directory to the path where you clone <code>hypershard-ios</code></li> <li>Build hyper shard-ios with command <code>swift build -c release</code></li> <li>It will build the binary into the <code>.build</code> folder</li> <li>The resulting binary will be placed in the <code>.build/release/hypershard</code>.</li> </ol>"},{"location":"hypershard_ios/#running","title":"Running","text":"<ol> <li> <p>Open Terminal/cmd</p> </li> <li> <p>change the working directory to <code>.build/release</code> or add it to <code>PATH</code></p> </li> <li> <p>To run hypershard make CLI invocation with the command:</p> </li> </ol> <pre><code>hypershard TEST_TARGET_NAME ROOT_PATH\n</code></pre> <p>where</p> <pre><code>- `TEST_TARGET_NAME` - the name of the Xcode test target containing the UI tests\n- `ROOT_PATH` - either a path where all the `XCUITest`s classes are stored, or the path of the Xcode project containing `TEST_TARGET_NAME`\n</code></pre> <p>for example based on Flank test project</p> <pre><code>./hypershard EarlGreyExample test_projects/ios/EarlGreyExample/EarlGreyExampleSwiftTests\n</code></pre> <ol> <li>The output will be printed to console</li> </ol> <pre><code>{\"path\":\"\",\"phase\":\"XCUI test shard\",\"env\":{},\"cmd\":\"\",\"tests\":[\"EarlGreyExample.EarlGreyExampleSwiftTests.testThatThrows\",\"EarlGreyExample.EarlGreyExampleSwiftTests.testBasicSelection\",\"EarlGreyExample.EarlGreyExampleSwiftTests.testBasicSelectionAndAction\",\"EarlGreyExample.EarlGreyExampleSwiftTests.testBasicSelectionAndAssert\",\"EarlGreyExample.EarlGreyExampleSwiftTests.testBasicSelectionActionAssert\",\"EarlGreyExample.EarlGreyExampleSwiftTests.testSelectionOnMultipleElements\",\"EarlGreyExample.EarlGreyExampleSwiftTests.testCollectionMatchers\",\"EarlGreyExample.EarlGreyExampleSwiftTests.testWithInRoot\",\"EarlGreyExample.EarlGreyExampleSwiftTests.testWithCustomMatcher\",\"EarlGreyExample.EarlGreyExampleSwiftTests.testTableCellOutOfScreen\",\"EarlGreyExample.EarlGreyExampleSwiftTests.testCatchErrorOnFailure\",\"EarlGreyExample.EarlGreyExampleSwiftTests.testCustomAction\",\"EarlGreyExample.EarlGreyExampleSwiftTests.testWithCustomAssertion\",\"EarlGreyExample.EarlGreyExampleSwiftTests.testWithCustomFailureHandler\",\"EarlGreyExample.EarlGreyExampleSwiftTests.testLayout\",\"EarlGreyExample.EarlGreyExampleSwiftTests.testWithCondition\",\"EarlGreyExample.EarlGreyExampleSwiftTests.testWithGreyAssertions\"]}\n</code></pre> <ol> <li>If you would like to store the output to a file just add a path to the file with <code>--path</code> option</li> </ol> <p>For example:</p> <pre><code>./hypershard EarlGreyExample test_projects/ios/EarlGreyExample/EarlGreyExampleSwiftTests --path results.json\n</code></pre>"},{"location":"hypershard_ios/#resources","title":"Resources","text":"<p>https://github.com/dropbox/hypershard-ios</p>"},{"location":"instrumentation_tests/","title":"Flank instrumentation tests","text":"<p>Flank contains a project for instrumentation tests placed on flank_tests directory.</p> <p>Tests can be run with Gradle wrapper and parametrized by command-line arguments</p>"},{"location":"instrumentation_tests/#commands","title":"Commands","text":"<ol> <li><code>flank-path</code>  location of flank.jar</li> <li><code>yml-path</code> location of test yml</li> <li><code>run-params</code> optional additional run parameters, default parameters depend on the platform</li> <li>for iOS is <code>firebase, test, ios, run</code></li> <li>for android <code>firebase, test, ios, run</code></li> <li><code>working-directory</code> optional parameter for set working directory default is: <code>./</code></li> <li><code>output-pattern</code> optional parameter for set regex to compare output</li> <li><code>expected-output-code</code> optional parameter for verify output code default: 0</li> </ol>"},{"location":"instrumentation_tests/#example-of-run-android-test","title":"Example of run android test","text":"<p><code>./gradlew test --tests IntegrationTests.shouldMatchAndroidSuccessExitCodeAndPattern -Dflank-path=../test_runner/build/libs/flank.jar -Dyml-path=./src/test/resources/flank_android.yml</code></p>"},{"location":"instrumentation_tests/#example-of-run-ios-test","title":"Example of run ios test","text":"<p><code>./gradlew test --tests IntegrationTests.shouldMatchIosSuccessExitCodeAndPattern -Dflank-path=../test_runner/build/libs/flank.jar -Dyml-path=./src/test/resources/flank_ios.yml</code></p>"},{"location":"investigate_flank_options/","title":"Investigate flank options","text":""},{"location":"investigate_flank_options/#list-of-options-android","title":"List of options android","text":""},{"location":"investigate_flank_options/#gcloud","title":"gcloud","text":"<ol> <li>app</li> <li>test</li> <li>additional-apks</li> <li>auto-google-login</li> <li>no-auto-google-login</li> <li>use-orchestrator</li> <li>no-use-orchestrator</li> <li>environment-variables</li> <li>directories-to-pull</li> <li>other-files</li> <li>performance-metrics</li> <li>no-performance-metrics</li> <li>num-uniform-shards</li> <li>test-runner-class</li> <li>test-targets</li> <li>robo-directives</li> <li>robo-script</li> <li>results-bucket</li> <li>results-dir</li> <li>record-video</li> <li>no-record-video</li> <li>timeout</li> <li>async</li> <li>client-details</li> <li>network-profile</li> <li>results-history-name</li> <li>num-flaky-test-attempts</li> <li>device</li> </ol>"},{"location":"investigate_flank_options/#flank","title":"flank","text":"<ol> <li>additional-app-test-apks</li> <li>legacy-junit-result</li> <li>max-test-shards</li> <li>shard-time</li> <li>num-test-runs</li> <li>smart-flank-gcs-path</li> <li>smart-flank-disable-upload</li> <li>disable-sharding</li> <li>test-targets-always-run</li> <li>files-to-download</li> <li>project</li> <li>local-result-dir</li> <li>run-timeout</li> <li>full-junit-result</li> <li>ignore-failed-tests</li> <li>keep-file-path</li> <li>output-style</li> <li>disable-results-upload</li> <li>default-test-time</li> <li>default-class-test-time</li> <li>use-average-test-time-for-new-tests</li> </ol>"},{"location":"investigate_flank_options/#list-of-options-ios","title":"List of options ios","text":""},{"location":"investigate_flank_options/#gcloud_1","title":"gcloud","text":"<ol> <li>test</li> <li>xctestrun-file</li> <li>xcode-version</li> <li>results-bucket</li> <li>results-dir</li> <li>record-video</li> <li>no-record-video</li> <li>timeout</li> <li>async</li> <li>client-details</li> <li>network-profile</li> <li>results-history-name</li> <li>num-flaky-test-attempts</li> <li>device</li> </ol>"},{"location":"investigate_flank_options/#flank_1","title":"flank","text":"<ol> <li>test-targets</li> <li>max-test-shards</li> <li>shard-time</li> <li>num-test-runs</li> <li>smart-flank-gcs-path</li> <li>smart-flank-disable-upload</li> <li>disable-sharding</li> <li>test-targets-always-run</li> <li>files-to-download</li> <li>project</li> <li>local-result-dir</li> <li>run-timeout</li> <li>full-junit-result</li> <li>ignore-failed-tests</li> <li>keep-file-path</li> <li>output-style</li> <li>disable-results-upload</li> <li>default-test-time</li> <li>default-class-test-time</li> <li>use-average-test-time-for-new-tests</li> </ol>"},{"location":"investigate_flank_options/#investigation-report","title":"Investigation report","text":""},{"location":"investigate_flank_options/#environment-variables-android","title":"environment-variables (Android)","text":"<p>Set the <code>directories-to-pull</code> variable to pull from the device directory with coverage report. There will be no warnings or failure messages when <code>environment-variables</code> is set without <code>directories-to-pull</code> A warning has been added about this.</p>"},{"location":"investigate_flank_options/#files-to-download-android","title":"files-to-download (Android)","text":"<p>In the case where coverage reports need to be downloaded set the <code>directories-to-pull</code> variable. There will be no warnings or failures when <code>files-to-download</code> is set without <code>directories-to-pull</code>. A warning is added regarding this.</p>"},{"location":"investigate_flank_options/#disable-sharding-common","title":"disable-sharding (Common)","text":"<p>Can be enabled by setting <code>max-test-shards</code> to greater than one. In this case flank will disable sharding A warning is added regarding this.</p>"},{"location":"investigate_flank_options/#num-uniform-shards-android","title":"num-uniform-shards (Android)","text":"<ol> <li>When set with <code>max-test-shards</code> Flank will fail fast.</li> <li>When set with <code>disable-sharding</code>, Flank will disable sharding without any warning</li> <li>Warning added about this.</li> </ol>"},{"location":"junit_xml_comparison/","title":"Junit xml comparison","text":"<p>iOS pass:</p> <pre><code>&lt;testsuite name=\"EarlGreyExampleSwiftTests\" hostname=\"localhost\" tests=\"16\" failures=\"0\" errors=\"0\" time=\"25.892\"&gt;\n  &lt;testcase name=\"testBasicSelection()\" classname=\"EarlGreyExampleSwiftTests\" time=\"2.0\"/&gt;\n  &lt;system-out/&gt;\n  &lt;system-err/&gt;\n</code></pre> <p>iOS fail:</p> <pre><code>&lt;testsuite name=\"EarlGreyExampleSwiftTests\" hostname=\"localhost\" tests=\"17\" failures=\"1\" errors=\"0\" time=\"25.881\"&gt;\n&lt;properties/&gt;\n&lt;testcase name=\"testBasicSelectionAndAction()\" classname=\"EarlGreyExampleSwiftTests\" time=\"0.584\"&gt;\n&lt;failure&gt;\n  ...\n</code></pre> <p>Android fail:</p> <pre><code>&lt;testsuite name=\"\" tests=\"2\" failures=\"1\" errors=\"0\" skipped=\"0\" time=\"3.87\" timestamp=\"2018-09-09T00:16:36\" hostname=\"localhost\"&gt;\n&lt;properties/&gt;\n&lt;testcase name=\"testFails\" classname=\"com.example.app.ExampleUiTest\" time=\"0.857\"&gt;\n&lt;failure&gt;\n  ...\n</code></pre> <p>Android pass:</p> <pre><code>&lt;testsuite name=\"\" tests=\"1\" failures=\"0\" errors=\"0\" skipped=\"0\" time=\"2.278\" timestamp=\"2018-09-14T20:45:55\" hostname=\"localhost\"&gt;\n&lt;properties/&gt;\n&lt;testcase name=\"testPasses\" classname=\"com.example.app.ExampleUiTest\" time=\"0.328\"/&gt;\n&lt;/testsuite&gt;\n</code></pre> <p>results / analysis:</p> <pre><code>    testsuite\n      name     - test target name\n      tests    - count of total tests\n      failures - count of failures (test assertion failed)\n      errors   - count of errors (unhandled exceptions)\n      time     - overall time of test suite in seconds\n      hostname - always localhost\n    testcase\n      name      - name of test method\n      classname - name of class that defines the test\n      time      - time in seconds\n\n  Android\n    testsuite\n      name - always empty string\n      tests\n      failures\n      errors\n      skipped* Android only.\n      time\n      timestamp* Android only.\n      hostname - always localhost\n    testcase\n      name\n      classname\n      time\n</code></pre>"},{"location":"logging/","title":"Logs in Flank","text":"<ol> <li>Log level depends on the output style.</li> <li><code>Simple, multi</code> and <code>verbose</code> output style prints logs from <code>SIMPLE</code> and <code>DETAILED</code> levels.</li> <li><code>Compact</code> style prints log only from <code>SIMPLE</code> level.</li> <li>If you want a print message for all output styles uses <code>log</code> or <code>logLn</code> with only <code>message</code> parameter.</li> <li>If you want print message more detailed message use <code>log</code> or <code>logLn</code> and set <code>level</code> to <code>OutputLogLevel.DETAILED</code></li> </ol>"},{"location":"mock_server/","title":"Mock Server","text":"<p>Goal: Test Flank using a mock server so we don't have to spend $$ to verify the test runner works.</p>"},{"location":"mock_server/#proof-of-concepts","title":"Proof of concepts","text":""},{"location":"mock_server/#prism","title":"prism","text":"<ul> <li>prism consumes Swagger v2 and uses json-schema-faker to return generated default responses. The fields are randomly null which crashes the runner. Prism is exceptionally slow and closed sourced. There's no way to customize the behavior. Not a viable option.</li> </ul>"},{"location":"mock_server/#mock_server_inflector","title":"<code>mock_server_inflector</code>","text":"<ul> <li>swagger-codegen consumes OpenAPI v3 and generates a fake server using swagger-inflector. Static canned responses are used based on the OpenAPI description. The responses aren't useful since they don't mimic a real server.  Swagger generates a massive amount of code. The build system lacks gradle support.</li> </ul>"},{"location":"mock_server/#mock_server_vertx","title":"<code>mock_server_vertx</code>","text":"<ul> <li>vertx-web-api-contract consumes OpenAPI v3 and generates a fake server using slush-vertx. Stub implementations for routes are provided. There are no precanned responses. Unfortunately the code generation is incompatible with the variable naming used in Firebase Test Lab. I opened an issue upstream. Of the three generated options, this looks like the nicest one. However the Google API surface is enormous and we don't need stubs for everything.</li> </ul>"},{"location":"mock_server/#mock_server","title":"<code>mock_server</code>","text":"<ul> <li>ktor is a nice Kotlin server based on Netty. In a single file, all the necessary routes are implemented for each API. The routes are easy to define manually. The complexity of OpenAPI / code generation is avoided. This is the approach that's working on the <code>kotlin_poc</code> runner.</li> </ul>"},{"location":"mock_server/#known-issues","title":"Known issues","text":"<ul> <li>Using a flag for mocked mode isn't ideal. Dependency injection with interfaces would be more robust.</li> </ul>"},{"location":"permissions_denied_behavior/","title":"Flank permissions denied behavior","text":"<p>Reported on: Clean flank not authorized error messages #874</p> <p>Changed on: Enhance permission denied exception logs #875</p>"},{"location":"permissions_denied_behavior/#1-user-dont-have-permission-to-project-403","title":"1. User don't have permission to project (403)","text":"<p>When user don't have permission to project Flank should returns message like:</p> <pre><code>Flank encountered a 403 error when running on project $project_name. Please verify this credential is authorized for the project.\nConsider authentication a with Service Account https://github.com/Flank/flank#authenticate-with-a-service-account\nor with a Google account https://github.com/Flank/flank#authenticate-with-a-google-account\n\nCaused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden\n{\n  \"code\" : 403,\n  \"errors\" : [ {\n    \"domain\" : \"global\",\n    \"message\" : \"The caller does not have permission\",\n    \"reason\" : \"forbidden\"\n  } ],\n  \"message\" : \"The caller does not have permission\",\n  \"status\" : \"PERMISSION_DENIED\"\n}\n</code></pre> <p>You can reproduce the error by setting PROJECT_ID to a project that the firebase account doesn't have permission to access.</p>"},{"location":"permissions_denied_behavior/#2-project-not-found-404","title":"2. Project not found (404)","text":"<p>When project not found on firebase Flank should return message like:</p> <pre><code>Flank was unable to find project $project_name. Please verify the project id.\n\nCaused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 404 Not Found\n{\n  \"code\" : 404,\n  \"errors\" : [ {\n    \"domain\" : \"global\",\n    \"message\" : \"Project not found: $project_name\",\n    \"reason\" : \"notFound\"\n  } ],\n  \"message\" : \"Project not found: $project_name\",\n  \"status\" : \"NOT_FOUND\"\n}\n</code></pre> <p>You can reproduce the error by setting PROJECT_ID to a project that doesn't exist.</p>"},{"location":"permissions_denied_behavior/#3-on-this-two-cases-flank-throws-flankcommonexception-and-exit-with-code-1","title":"3. On this two cases Flank throws FlankCommonException and exit with code: 1","text":""},{"location":"pr_titles/","title":"PR title using conventional commits","text":""},{"location":"pr_titles/#introduction","title":"Introduction","text":"<p>The Conventional Commits specification is a lightweight convention on top of commit messages.  It provides an easy set of rules for creating an explicit commit history; which makes it easier to write automated  tools on top of. </p>"},{"location":"pr_titles/#usage","title":"Usage","text":"<p>Every PR which is not in draft mode should follow conventional commit convention for PR title.  It allows us to generate release notes and avoid merge conflicts in release_notes.md file</p>"},{"location":"pr_titles/#pr-title","title":"PR title","text":"<p>Pull request title should be: <code>&lt;type&gt;([optional scope]): &lt;description&gt;</code></p> <p>where  <code>&lt;type&gt;</code> - one of following <code>[optional scope]</code> - additional information <code>&lt;description&gt;</code> - description of pr</p>"},{"location":"pr_titles/#type","title":"Type","text":"<ul> <li><code>build</code> - Changes that affect the build system or external dependencies (dependencies update)</li> <li><code>ci</code> - Changes to our CI configuration files and scripts (basically directory <code>.github/workflows</code>)</li> <li><code>docs</code> - Documentation only changes</li> <li><code>feat</code> - A new feature</li> <li><code>fix</code> - A bug fix</li> <li><code>chore</code> - Changes which does not touch the code (ex. manual update of release notes). It will not generate release notes changes</li> <li><code>refactor</code> - A code change that contains refactor</li> <li><code>style</code> - Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons, etc)</li> <li><code>test</code> - Adding missing tests or correcting existing tests and also changes for our test app</li> <li><code>perf</code> - A code change that improves performance (I do not think we will use it)</li> </ul>"},{"location":"pr_titles/#examples","title":"Examples","text":"<ul> <li><code>feat: Add locales description command for ios and android</code> -&gt; https://github.com/Flank/flank/pull/969</li> <li><code>fix: rate limit exceeded</code> -&gt; https://github.com/Flank/flank/pull/919</li> <li><code>ci: Added leading V to version name</code> -&gt; https://github.com/Flank/flank/pull/980</li> <li><code>refactor: config entities and arguments</code> -&gt; https://github.com/Flank/flank/pull/831</li> <li><code>docs: Add secrets and vision doc</code> -&gt; https://github.com/Flank/flank/pull/922</li> <li><code>build: Disable Auto Doc Generation</code> -&gt; https://github.com/Flank/flank/pull/942</li> <li><code>test: added multi modules to test app</code> -&gt; https://github.com/Flank/flank/pull/857</li> <li><code>chore: Release v20.08.1</code> -&gt; https://github.com/Flank/flank/pull/982</li> </ul>"},{"location":"readme/","title":"Flank Kotlin","text":"<p>Rewrite of Flank in Kotlin</p>"},{"location":"readme/#design-decisions","title":"Design decisions.","text":"<ul> <li>APIs are used for all Google Cloud interactions</li> <li>Firebase Test Lab transparently retries VMs 3x</li> <li>Infrastructure Failures may lead to 4 hours or more of wait times as a result, retrying VMs on failure isn't super helpful.</li> <li>VM timeout applies only once the VM has booted. Hours spent waiting for the VM to boot aren't included in the wait time.</li> <li>Test failures are best retried using a retry JUnit rule combined with Android Test Orchestrator and an app reset rule</li> <li>On device retry is free since we don't need to spin up a new VM.</li> <li>Each VM created is another opportunity for FTL to error. Even when VMs boot correctly, it's at least a 5m wait time.</li> </ul>"},{"location":"readme/#client-libraries","title":"Client libraries","text":"<p>Google provides two types of client libraries: <code>Google API Client Libraries</code> and <code>Google Cloud Client Libraries</code>.</p> <ul> <li><code>google-api-services-*</code> - legacy</li> <li><code>google-api-services-storage</code></li> <li><code>google-api-services-toolresults</code></li> <li><code>google-api-services-testing</code></li> <li><code>google-cloud-*</code> - newest</li> <li><code>google-cloud-storage</code></li> </ul>"},{"location":"readme/#discovery-json","title":"Discovery JSON","text":"<p>The discovery JSON is useful for understanding APIs and producing clients automatically. The discovery JSON contains the latest changes.</p> <ul> <li>toolresults/v1beta3/</li> <li>testing/v1 or testing</li> <li>storage/v1</li> <li><code>google-cloud-sdk\\lib\\googlecloudsdk\\third_party\\apis</code> has older JSON versions. Not recommended for use.</li> <li><code>storage_v1.json</code></li> <li><code>toolresults_v1beta3.json</code></li> <li><code>testing_v1.json</code></li> </ul> <p>See client generation for more information.</p>"},{"location":"readme/#google-cloud-storage","title":"google-cloud-storage","text":"<p>Published on maven central</p> <p><code>com.google.cloud:google-cloud-storage:1.15.0</code></p> <ul> <li>google-cloud-storage github</li> <li>google-cloud-storage JavaDoc</li> </ul>"},{"location":"readme/#google-api-services-toolresults","title":"google-api-services-toolresults","text":"<p>Published on maven central</p> <p><code>com.google.apis:google-api-services-toolresults:v1beta3-rev351-1.21.0</code></p> <ul> <li>Not on GitHub</li> <li>google-api-services-toolresults website</li> <li>google-api-services-toolresults javadoc</li> </ul>"},{"location":"readme/#google-api-services-testing","title":"google-api-services-testing","text":"<p>Client may be generated manually using <code>testing_v1.json</code> and the master branch of apis-client-generator. Google also publishes official clients:</p> <ul> <li>Java</li> <li>Python</li> <li>.NET</li> <li>Ruby</li> <li>Go</li> </ul>"},{"location":"readme/#clone","title":"Clone","text":"<ul> <li><code>git clone https://android.googlesource.com/platform/tools/studio/google/cloud/testing</code></li> <li><code>git checkout studio-master-dev</code></li> <li>Android Studio repo</li> </ul>"},{"location":"readme/#build","title":"Build","text":"<ul> <li><code>gradle build</code></li> </ul>"},{"location":"readme/#mock-servers","title":"Mock Servers","text":"<p>API Discovery JSON may be converted to OpenAPI 3 using apimatic.io/transformer. See mock_server.md for details.</p>"},{"location":"release_process/","title":"Release process","text":""},{"location":"release_process/#requirements","title":"Requirements","text":"<ol> <li>A release process should be run withing macOS environment</li> <li>The machine should contain:     <code>homebrew</code> - Package manager     <code>gh</code> - GitHub CLI tool</li> </ol>"},{"location":"release_process/#current-setup","title":"Current setup","text":"<p>Current scripts run on GitHub actions environment with <code>macos-latest</code> os. Script could be found on path</p> <p>Each push: - to <code>master</code> branch run Snapshot release - of tag <code>v*</code> run regular release</p>"},{"location":"release_process/#triggering-release","title":"Triggering release","text":""},{"location":"release_process/#manually","title":"Manually","text":"<ol> <li>Navigate to GitHub Actions</li> <li>Run job <code>Generate release notes for next commit</code> by using <code>Run Workflow</code> button</li> <li>After merging PR,  the next tag will be pushed to repository</li> <li>Wait for CI job to finish</li> </ol>"},{"location":"release_process/#automatically","title":"Automatically","text":"<ol> <li>Release job will run each 1st day of month</li> <li>After merging PR,  the next tag will be pushed to repository</li> <li>Wait for CI job to finish</li> </ol>"},{"location":"release_process/#ci-steps","title":"CI Steps","text":"<ol> <li>Gradle Build flankScripts and add it to PATH</li> <li>Set environment variables</li> <li>Delete old snapshot</li> <li>Gradle Build Flank</li> <li>Authenticate to hub</li> <li>Remove old release</li> <li>Rename old tag  </li> <li>Release flank<ol> <li>Snapshot for snapshot flow (push to master)</li> <li>Stable for regular flow (push tag <code>v*</code>)</li> </ol> </li> <li>Publish binary for Maven Central</li> <li>Publish binary to GithubPackages (non snapshot only)</li> </ol>"},{"location":"smart_flank/","title":"Smart Flank Design Doc","text":"<p>Smart Flank is a sharding algorithm that groups tests into equally sized buckets.</p>"},{"location":"smart_flank/#current-implementation","title":"Current implementation","text":"<p>At the start of a run, Flank checks to see if there's a JUnit XML with timing info from the previous run. If there's no previous test time recorded, then the test is estimated to be 10 seconds. The tests are then grouped into equally timed buckets. The bucket count is set by the user provided <code>maxTestShards</code> count.</p> <p>After each test run, the aggregated JUnit XML from the new run is merged with the old run. Any tests not in the new run are discarded. Tests that were skipped, errored, failed, or empty are discarded. The test time value of successful tests is set using the time from the latest run. If a test failed in the new run and passed in the old run, the timing info from the old run is carried over.</p> <p>The merged XML is uploaded to the user defined <code>smartFlankGcsPath</code>. If <code>smartFlankGcsPath</code> is not defined, then the smart flank feature will not activate. Empty results are not uploaded.</p> <p>Example:</p> <pre><code>&lt;!-- Old Run --&gt;\n&lt;?xml version='1.0' encoding='UTF-8' ?&gt;\n&lt;testsuites&gt;\n  &lt;testsuite name=\"EarlGreyExampleSwiftTests\" tests=\"4\" failures=\"1\" errors=\"0\" skipped=\"0\" time=\"51.773\" hostname=\"localhost\"&gt;\n    &lt;testcase name=\"a()\" classname=\"a\" time=\"5.0\"/&gt;\n    &lt;testcase name=\"b()\" classname=\"b\" time=\"6.0\"/&gt;\n    &lt;testcase name=\"c()\" classname=\"c\" time=\"7.0\"/&gt;\n    &lt;testcase name=\"d()\" classname=\"d\" time=\"8.0\"/&gt;\n  &lt;/testsuite&gt;\n&lt;/testsuites&gt;\n</code></pre> <pre><code>&lt;!-- New run --&gt;\n&lt;?xml version='1.0' encoding='UTF-8' ?&gt;\n&lt;testsuites&gt;\n  &lt;testsuite name=\"EarlGreyExampleSwiftTests\" tests=\"4\" failures=\"1\" errors=\"0\" skipped=\"0\" time=\"51.773\" hostname=\"localhost\"&gt;\n    &lt;testcase name=\"a()\" classname=\"a\" time=\"1.0\"/&gt;\n    &lt;testcase name=\"b()\" classname=\"b\" time=\"2.0\"/&gt;\n    &lt;testcase name=\"c()\" classname=\"c\" time=\"0.584\"&gt;\n      &lt;failure&gt;Exception: NoMatchingElementException&lt;/failure&gt;\n      &lt;failure&gt;failed: caught \"EarlGreyInternalTestInterruptException\", \"Immediately halt execution of testcase\"&lt;/failure&gt;\n    &lt;/testcase&gt;\n    &lt;testcase name=\"d()\" classname=\"d\" time=\"0.0\"&gt;\n        &lt;skipped/&gt;\n    &lt;/testcase&gt;\n  &lt;/testsuite&gt;\n&lt;/testsuites&gt;\n</code></pre> <pre><code>&lt;!-- Merged --&gt;\n&lt;?xml version='1.0' encoding='UTF-8' ?&gt;\n&lt;testsuites&gt;\n  &lt;testsuite name=\"EarlGreyExampleSwiftTests\" tests=\"3\" failures=\"0\" errors=\"0\" skipped=\"0\" time=\"10.0\" hostname=\"localhost\"&gt;\n    &lt;testcase name=\"a()\" classname=\"a\" time=\"1.0\"/&gt;\n    &lt;testcase name=\"b()\" classname=\"b\" time=\"2.0\"/&gt;\n    &lt;testcase name=\"c()\" classname=\"c\" time=\"7.0\"/&gt;\n  &lt;/testsuite&gt;\n&lt;/testsuites&gt;\n</code></pre>"},{"location":"smart_flank/#issues","title":"Issues","text":"<ul> <li>Merging XML files is complicated</li> <li>A local run of 1 test will upload a new XML file that contains only that one test. That will discard timing info for all other tests.</li> <li>Does not integrate properly with the typical local/PR/master workflow.</li> </ul>"},{"location":"smart_flank/#ideas-for-improvement","title":"Ideas for improvement","text":"<ul> <li>Keep a user configurable rolling number of aggregated xmls (1.xml, 2.xml, 3.xml) and shard based on the average time. Average time is expected to be more reliable than always using the last time in isolation.</li> <li>Identify a way of translating app binary to a default xml name (bundle id/package name) so that smart flank works out of the box for users. Talk with Firebase on how to do this locally and/or expose an API.</li> </ul>"},{"location":"test_artifacts/","title":"Test artifacts","text":"<p>Test artifacts are precompiled binaries necessary for CI and local testing. They can change over time so developers should be able to maintain and share them easy as possible.</p>"},{"location":"test_artifacts/#overview","title":"Overview","text":""},{"location":"test_artifacts/#storage","title":"Storage","text":""},{"location":"test_artifacts/#local","title":"Local","text":"<p>Local working copy of test artifacts can be find in test_artifacts directory inside local flank repository.  However, this directory MUST be added to .gitignore to prevent committing binaries to git. We accept few restrictions about storing test artifacts in test_artifacts directory. * test_artifacts directory CAN contain directories with binaries required for testing. * Names of directories inside test_artifacts SHOULD reflect names of working branches. * test_artifacts directory CAN contain test artifacts archives bundles. * The name of artifact archive should match following format <code>branchName-unixTimestamp.zip</code></p>"},{"location":"test_artifacts/#remote","title":"Remote","text":"<p>The remote copy of test artifacts can be find at test_artifacts/releases We accept few restrictions about using github releases as storage for test artifacts. * The release name and tag should reflect the name of related working branch. * Each release should contain only one asset with artifacts. * The name of test artifact assets archive should be [ ~~mdp5 checksum~~ | unix timestamp ] suffixed with <code>zip</code> extensions. </p>"},{"location":"test_artifacts/#linking-artifacts","title":"Linking artifacts","text":"<p>For convenient switching between test artifacts we are using symbolic links. Ensure you have symbolic link to correct directory inside test_artifacts directory, otherwise the unit tests will fail because of lack of binaries.</p>"},{"location":"test_artifacts/#test-projects","title":"Test projects","text":"<p>All source code of test artifacts binaries can be find in test_projects directory.</p>"},{"location":"test_artifacts/#generating-test-artifacts","title":"Generating test artifacts","text":"<pre><code>source .env\nupdate_test_artifacts android ios  # [ android | go | ios | all ]\n</code></pre>"},{"location":"test_artifacts/#working-with-artifacts","title":"Working with artifacts","text":"<p>All testArtifacts subcommands can be configured using base options. * <code>testArtifacts -b {name}</code> used to specify branch name for test artifacts.  For example if you want to run any subcommand on artifacts dedicated for your working branch <code>feature123</code> run <code>testArtifacts -b feature123 {subcommand}</code>. By default, it is the name of current working git branch.</p> <ul> <li><code>testArtifacts -p {path}</code> used to specify the path to local flank repository.  By default, the path is read from <code>FLANK_ROOT</code>env variable.  To export path to your local flank repository just source .env file. </li> </ul>"},{"location":"test_artifacts/#developer-scenarios","title":"Developer scenarios","text":"<p>As a developer I want to download test artifacts before test run.</p> <ul> <li>Just run <code>./gradlew test</code> command, this should trigger <code>resolveArtifacts</code> task which will update artifacts if needed.</li> </ul> <p>As a developer I want to switch between local test artifacts</p> <ul> <li>Run <code>flankScripts testArtifacts link</code> to create a symbolic link to test artifacts for the current branch.</li> <li>Run <code>flankScripts testArtifacts -b {name} link</code> to create a symbolic link to test artifacts for the specific branch.</li> </ul> <p>As a developer I want to edit existing test artifacts</p> <ol> <li>Edit required project in test_artifacts/releases directory.</li> <li>Ensure you have sourced .env file.</li> <li>Build required project and copy binaries using update_test_artifacts shell function or do it manually.</li> <li>Ensure you have linked a correct directory with artifacts.</li> <li>Your local tests now should you use updated artifacts.  </li> </ol> <p>As a developer I want to upload new test artifacts to remote repository.</p> <ol> <li>Make sure you have directory with artifacts in test_artifacts and the name same as working branch.</li> <li>Run <code>flankScripts testArtifacts zip</code> to create zip archive.</li> <li>Run <code>flankScripts testArtifacts upload</code> to upload zip as remote copy. The script will automatically resolve the latest archive and upload it.</li> </ol> <p>As a developer I want to remove test artifacts</p> <ul> <li>Run <code>flankScripts testArtifacts remove_remote</code> this will remove the remote copy of test artifacts for current working branch.</li> </ul>"},{"location":"test_artifacts/#ios-test-artifacts","title":"iOS test artifacts","text":"<p>Currently we have 4 different iOS test projects:</p> <ol> <li>EarlGreyExample</li> <li>FlankExample</li> <li>FlankGameLoopExample</li> <li>FlankTestPlansExample</li> </ol> <p>Source code of each of them is located under: test_projects/ios</p> <p>Test artifacts for each project contains:  * build output in Debug-iphoneos * zipped build output in PROJECT_NAME.zip, * .xctestrun file for each test target</p>"},{"location":"test_artifacts/#earlgreyexample","title":"EarlGreyExample","text":"<p>This project is basically clone of EarlGrey.  Source project contains two test targets: EarlGreyExampleSwiftTests, EarlGreyExampleTests.</p>"},{"location":"test_artifacts/#generate","title":"Generate","text":"<p>Run: <code>flankScripts assemble ios earl_grey</code>.</p>"},{"location":"test_artifacts/#source-code","title":"Source Code","text":"<p>test_projects/ios/EarlGreyExample</p>"},{"location":"test_artifacts/#flankexample","title":"FlankExample","text":"<p>Simple project with two test targets: FlankExampleTests, FlankExampleSecondTests.</p>"},{"location":"test_artifacts/#generate_1","title":"Generate","text":"<p>Run: <code>flankScripts assemble ios flank_example</code>.</p>"},{"location":"test_artifacts/#source-code_1","title":"Source Code","text":"<p>test_projects/ios/EarlGreyExample</p>"},{"location":"test_artifacts/#flankgameloopexample","title":"FlankGameLoopExample","text":"<p>Simple SpriteKit app to test gameloop mode. It doesn't contain any test target, so test artifacts contains only IPA file.</p>"},{"location":"test_artifacts/#generate_2","title":"Generate","text":"<p>Run: <code>flankScripts assemble ios game_loop</code>.</p>"},{"location":"test_artifacts/#source-code_2","title":"Source Code","text":"<p>test_projects/ios/EarlGreyExample</p> <p>\u26a0\ufe0f NOTE: Generating IPA requires Apple distribution certificate therefore for now it's not possible to generate it without correct Apple Developer Account.  <code>game_loop</code> is excluded when building all iOS artifacts: <pre><code>update_test_artifacts ios\n</code></pre></p>"},{"location":"test_artifacts/#flanktestplansexample","title":"FlankTestPlansExample","text":"<p>iOS project with XCTestPlans. Contains <code>AllTests</code> test plan. Generated .xctestrun is using V2 format. More details about test plans: docs/feature/ios_test_plans.md</p>"},{"location":"test_artifacts/#generate_3","title":"Generate","text":"<p>Run: <code>flankScripts assemble ios test_plans</code>.</p>"},{"location":"test_artifacts/#source-code_3","title":"Source Code","text":"<p>test_projects/ios/EarlGreyExample</p>"},{"location":"test_sharding/","title":"Test Sharding","text":""},{"location":"test_sharding/#orchestrator","title":"Orchestrator","text":"<p>Android Test Orchestrator removes shared state and isolates crashes. Orchestrator trades performance for stability. Tests run slower when orchestrator is enabled.</p> <p>Orchestrator ensures each tests runs Each test runs in a new Instrumentation instance to ensure there's no shared state. It's recommended to use <code>clearPackageData</code> as well to remove file system state. </p> <p>When a test crashes, only that tests instrumentation instance crashes which enables other tests in the suite to continue execution. Without orchestrator, a test crash will break the entire test suite.</p> <pre><code>gcloud:\n  use-orchestrator: true\n</code></pre>"},{"location":"test_sharding/#orchestrator-firebase-test-lab","title":"Orchestrator + Firebase Test lab","text":"<p>Orchestrator is enabled by default in Flank and disabled by default in gcloud CLI.</p> <p>AndroidX Test 1.3.0 Beta02 or later is required to run parameterized tests with orchestrator. Both the runner and orchestrator must be updated.</p> <p>Local execution will use the version of Orchestrator defined in your gradle file. Firebase Test Lab currently uses Orchestrator v1.3.0. Firebase must manually upgrade Orchestrator on their devices for customers to use the new version.</p>"},{"location":"test_sharding/#gcloud-sharding","title":"GCloud Sharding","text":"<p>The gcloud CLI supports two types of sharding, uniform sharding and manual sharding via test targets for shard.</p> <p>--num-uniform-shards is translated to \u201c-e numShard\u201d \u201c-e shardIndex\u201d AndroidJUnitRunner arguments. This uses the native <code>adb am instrument</code> sharding feature which randomly shards all tests. When using uniform shards, it's possible to have shards with empty tests.  </p> <p>Firebase will mark shards as failed when execution consists of skipped/empty tests, as this is likely an indication the tests are not configured correctly. This firebase design choice is incompatible with num-uniform-shards as you will randomly get failures when shards are empty. Using num-uniform-shards is therefor not recommended.</p> <p>--test-targets-for-shard allows manually specifying tests to be run.</p> <p>On FTL <code>--test-targets</code> or <code>--test-targets-for-shard</code> are passed as arguments to <code>adb shell am instrument</code>.</p> <p>adb shell am instrument -r -w -e class com.example.test_app.ParameterizedTest#shouldHopefullyPass com.example.test_app.test/androidx.test.runner.AndroidJUnitRunner</p>"},{"location":"test_sharding/#flank","title":"Flank","text":"<p>The Flank supports two types of sharding, automatic sharding and uniform sharding.</p> <p>Automatic sharding is enabled by default and can be disabled by <code>--disable-sharding=true</code>. Under the hood automatic sharding uses same API as gcloud's <code>--test-targets-for-shard</code> but in difference to gcloud it creates shards automatically.  <code>--dump-shards</code> can help with verifying if calculates shards are correct. Automated sharding can work with <code>--test-targets</code> option. </p> <p><code>--num-uniform-shards</code> provides same functionality as gcloud's option. Is not compatible with automatic sharding.</p>"},{"location":"test_sharding/#parameterized-tests","title":"Parameterized tests","text":"<p>Flank v20.06.1 fix some compatibility issues with named parameterized tests, when running with sharding. \\ Table below bases on report from running parameterized tests with different configurations. Flank uses same API as gcloud so everything supported by gcloud should be also supported by flank. </p> orchestrator disabled disabled 1.3.0-rc01 1.3.0-rc01 sharding disabled enabled disabled enabled local @RunWith(Parameterized::class) OK OK OK OK local @RunWith(Parameterized::class) {named} OK OK OK OK local @RunWith(JUnitParamsRunner::class) OK OK OK OK gcloud @RunWith(Parameterized::class) OK OK OK OK gcloud @RunWith(Parameterized::class) {named} OK OK OK OK gcloud @RunWith(JUnitParamsRunner::class) OK OK null null flank v20.06.0 @RunWith(Parameterized::class) OK OK OK OK flank v20.06.0 @RunWith(Parameterized::class) {named} OK missing OK missing flank v20.06.0 @RunWith(JUnitParamsRunner::class) OK missing null missing flank v20.06.1 @RunWith(Parameterized::class) OK OK OK OK flank v20.06.1 @RunWith(Parameterized::class) {named} OK OK OK OK flank v20.06.1 @RunWith(JUnitParamsRunner::class) OK OK null null"},{"location":"test_sharding/#junit5","title":"JUnit5","text":"<p>Android instrumented tests has no official support for JUnit5. There is third-party support</p>"},{"location":"update_gradle/","title":"Gradle","text":""},{"location":"update_gradle/#updating-gradle","title":"Updating Gradle","text":"<p>brew upgrade gradle</p> <p>gradle --version</p> <p>gradle wrapper --distribution-type all</p> <p>Specify the gradle distribution type in <code>build.gradle</code>: <pre><code>wrapper {\n    distributionType = Wrapper.DistributionType.ALL\n}\n</code></pre></p>"},{"location":"using_different_environment_variables_in_different_matrices/","title":"Using different environment variables per test apk","text":""},{"location":"using_different_environment_variables_in_different_matrices/#the-problem","title":"The problem","text":"<p>Environment variables are used to configure test coverage. When you configure this in the global scope (gcloud:environment-variables) all of the matrices have the same test coverage file name. Example:</p> <pre><code>gcloud:\n  app: ./src/test/kotlin/ftl/fixtures/tmp/apk/app-debug.apk\n  test: ./src/test/kotlin/ftl/fixtures/tmp/apk/app-multiple-success-debug-androidTest.apk\n  environment-variables:\n    coverage: true\n    coverageFile: /sdcard/coverage.ec\n    clearPackageData: true\n  directories-to-pull:\n    - /sdcard/\n  use-orchestrator: false\n</code></pre> <p>In the case where you have configured additional test apks, all of the matrices have a coverage file named <code>coverage.ec</code></p>"},{"location":"using_different_environment_variables_in_different_matrices/#solution","title":"Solution","text":"<p>You can override environment variables by configuring it in <code>additional-app-test-apks</code></p> <p>Example:</p> <pre><code>gcloud:\n  app: ./src/test/kotlin/ftl/fixtures/tmp/apk/app-debug.apk\n  test: ./src/test/kotlin/ftl/fixtures/tmp/apk/app-multiple-success-debug-androidTest.apk\n  environment-variables:\n    coverage: true\n    coverageFile: /sdcard/main.ec\n    clearPackageData: true\n  directories-to-pull:\n    - /sdcard/\n  use-orchestrator: false\n\nflank:\n  disable-sharding: false\n  max-test-shards: 2\n  files-to-download:\n    - .*/sdcard/[^/]+\\.ec$\n  additional-app-test-apks:\n    - test: ./src/test/kotlin/ftl/fixtures/tmp/apk/app-multiple-success-debug-androidTest.apk\n      environmentVariables:\n        coverageFile: /sdcard/module_1.ec\n    - test: ./src/test/kotlin/ftl/fixtures/tmp/apk/app-multiple-success-debug-androidTest.apk\n      environmentVariables:\n        coverageFile: /sdcard/module_2.ec\n</code></pre> <p>Now Flank override <code>coverageFile</code> in matrices and you can identify what matrix run what test</p>"},{"location":"windows_and_github_actions/","title":"Working with Windows on GitHub actions","text":""},{"location":"windows_and_github_actions/#differences-between-system-property-userhome-and-environment-variable-homepath","title":"Differences between system property user.home and environment variable HOMEPATH","text":"<ol> <li><code>%HOMEPATH%</code> in a batch scripts returns <code>D:\\Users\\runneradmin\\</code></li> <li>In Java <code>System.getProperty(\"user.home\")</code> returns <code>C:\\Users\\runneradmin\\</code></li> </ol> <p>For Windows recommended is using <code>System.getenv(\"HOMEPATH\")</code> instead of <code>System.getProperty(\"user.home\")</code></p>"},{"location":"windows_wsl_guide/","title":"Building and running Flank on Windows WSL","text":"<p>It is possible to build and run Flank on Windows through WSL. You could configure it using your own Windows machine or you could use GitHub actions to do this.</p>"},{"location":"windows_wsl_guide/#building","title":"Building","text":""},{"location":"windows_wsl_guide/#own-windows-machine","title":"Own Windows machine","text":"<ol> <li>Install WSL on Windows using Microsoft Guide</li> <li>Launch WSL console</li> <li>Install JDK if you do not have any installed    <pre><code>sudo apt-get install openjdk-15-jre\nsudo apt-get install openjdk-15-jdk\nexport JAVA_HOME=/usr/lib/jvm/openjdk-15-jdk\nexport PATH=$PATH:$JAVA_HOME/bin\n</code></pre></li> <li>Install <code>dos2unix</code> using the command <code>sudo apt-get install dos2unix</code></li> <li>Convert files to UNIX in your Flank repository directory    <pre><code>find . -type f -print0 | xargs -0 -n 1 -P 4 dos2unix\n</code></pre></li> <li>Make Gradlew wrapper executable    <pre><code>chmod +x gradlew\n</code></pre></li> <li>Build Flank using command <code>./gradlew clean build</code></li> </ol>"},{"location":"windows_wsl_guide/#github-actions","title":"GitHub actions","text":"<ol> <li>Setup WSL on <code>windows-2019</code> runner     <pre><code>runs-on: windows-2019\n</code></pre></li> <li>Setup default shell to <code>wsl-bash {0}</code> this will allow avoiding typing <code>wsl-bash</code> on start each command     <pre><code>defaults:\n  run:\n    shell: wsl-bash {0}\n</code></pre></li> <li>Use GitHub action for setup WSL <pre><code>- uses: Vampire/setup-wsl@v1\n  with:\n    distribution: Ubuntu-20.04\n    additional-packages:\n      dos2unix\n</code></pre></li> <li>In order to build flank you should install java, add permission to Gradle wrapper file and prepare each file using <code>dos2unix</code> <pre><code>- name: Configure WSL for flank\n  run: |\n      find . -type f -print0 | xargs -0 -n 1 -P 4 dos2unix\n      chmod +x gradlew\n      sudo apt-get -y install openjdk-8-jdk\n</code></pre></li> <li>After this step you could build flank like in every UNIX machine     <pre><code>./gradlew clean build\n</code></pre></li> <li>For reference please check Flank team implementation of WSL workflow</li> </ol>"},{"location":"windows_wsl_guide/#running","title":"Running","text":"<p>After building using the above steps or downloading using the command <code>wget --quiet https://github.com/Flank/flank/releases/download/XXX/flank.jar -O ./flank.jar</code> where <code>XXX</code> is the latest version of flank from Flank releases on GitHub You could run Flank both on your own machine or GitHub actions typing the command: <code>java -jar &lt;PATH TO FLANK&gt; &lt;COMMANDS&gt; &lt;OPTIONS&gt;</code> You could also add Flank's bash helper folder to your <code>$PATH</code> environment variable. This will allow you to call the shell scripts in that helper folder from anywhere.</p>"},{"location":"bugs/1374_invalid_class/","title":"[Parametrized tests] #1374 - java.lang.ClassNotFoundException: Invalid name:","text":""},{"location":"bugs/1374_invalid_class/#bug-description","title":"Bug description","text":"<p>Test code with parametrized code and custom name</p> <pre><code>@RunWith(Parameterized::class)\nclass BrokenTestName2(private val testCase: TestCase) {\n\n    @Test fun test() {\n        val expectedRemainder = if (testCase.odd) 1 else 0\n        for (value in testCase.values) {\n            assertEquals(expectedRemainder, abs(value % 2))\n        }\n    }\n\n    data class TestCase(\n        val values: List&lt;Int&gt;,\n        val odd: Boolean,\n    )\n\n    companion object {\n\n        @[JvmStatic Parameterized.Parameters(name = \"{0}\")]\n        fun parameters(): List&lt;TestCase&gt; = listOf(\n            TestCase(listOf(-4, -2, 0, 2, 4), odd = false),\n            TestCase(listOf(-3, -5, -1, 1, 3, 5), odd = true),\n        )\n    }\n}\n</code></pre> <p>Will produce failures such as: <pre><code>java.lang.ClassNotFoundException: Invalid name:  3\nat java.lang.Class.classForName(Native Method)\nat java.lang.Class.forName(Class.java:324)\nat androidx.test.internal.runner.TestLoader.doCreateRunner(TestLoader.java:72)\nat androidx.test.internal.runner.TestLoader.getRunnersFor(TestLoader.java:105)\nat androidx.test.internal.runner.TestRequestBuilder.build(TestRequestBuilder.java:804)\nat androidx.test.runner.AndroidJUnitRunner.buildRequest(AndroidJUnitRunner.java:575)\nat androidx.test.runner.AndroidJUnitRunner.onStart(AndroidJUnitRunner.java:393)\nat android.app.Instrumentation$InstrumentationThread.run(Instrumentation.java:1879)\n</code></pre></p> <p>and similar failures for other values interspersed with commas, e.g. <code>java.lang.ClassNotFoundException: Invalid name:  -2</code>, etc.</p> <p>Such failures appear like this in the FTL UI:</p> <p></p>"},{"location":"bugs/1374_invalid_class/#test-details","title":"Test details","text":"<p>No matter if sharding is disabled or not, tests will always fail both on GCloud and Flank</p>"},{"location":"bugs/1374_invalid_class/#solution","title":"Solution","text":"<p>Disable test orchestrator with yaml option: <pre><code>gcloud:\n  ...\n  use-orchestrator: false\n  ...\nflank:\n  ...\n</code></pre> or CLI command: <pre><code>--no-use-orchestrator\n</code></pre></p>"},{"location":"bugs/1374_invalid_class/#more-info","title":"More info","text":"<p>Please take a look at documentation about sharding for more info</p>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/","title":"Non-deterministic issue when parsing JUnitReport.xml generated by Flank 20.06.2 #872","text":""},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#description","title":"Description","text":"<p>After updating from Flank 8.0.1 to 20.06.2 and switching to server-side sharding sometimes on our CI (TeamCity) we see following error when parsing <code>JUnitReport.xml</code>: <pre><code>[17:00:00]Ant JUnit report watcher\n[17:00:00][Ant JUnit report watcher] 1 report found for paths:\n[17:00:00][Ant JUnit report watcher] results/**/JUnitReport.xml\n[17:00:00][Ant JUnit report watcher] Parsing errors\n[17:00:00][Parsing errors] Failed to parse 1 report\n[17:00:00][Parsing errors] results/2020-06-25_16-47-33.675000_QnCW/JUnitReport.xml: Content is not allowed in prolog.\n[17:00:00][Parsing errors] jetbrains.buildServer.util.XmlXppAbstractParser$3: Content is not allowed in prolog.\n    at jetbrains.buildServer.util.XmlXppAbstractParser.parse(XmlXppAbstractParser.java:39)\n    at jetbrains.buildServer.util.XmlXppAbstractParser.parse(XmlXppAbstractParser.java:31)\n    at jetbrains.buildServer.xmlReportPlugin.parsers.antJUnit.AntJUnitReportParser.parse(AntJUnitReportParser.java:179)\n    at jetbrains.buildServer.xmlReportPlugin.ParseReportCommand.run(ParseReportCommand.java:62)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n    at java.lang.Thread.run(Thread.java:748)\nCaused by: org.xml.sax.SAXParseException; lineNumber: 1; columnNumber: 1; Content is not allowed in prolog.\n    at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)\n    at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)\n    at jetbrains.buildServer.util.XmlXppAbstractParser.parseWithSAX(XmlXppAbstractParser.java:240)\n    at jetbrains.buildServer.util.XmlXppAbstractParser.parse(XmlXppAbstractParser.java:37)\n    ... 8 more\n</code></pre> The issue is non-deterministic, in most cases the report gets parsed, but this never happened to us when using Flank 8. Did anyone already run into the problem? Any ideas what could be a cause? The XML files look correct for me, I compared two files from failed and successful runs, the difference is only in reported time of running tests, both files do not contain BOM marker (checked using vim).</p> <p>To Reproduce</p> <ol> <li>Run tests using Flank and then try to parse the report using TeamCity's report parsing feature.</li> </ol> <p>Expected behavior</p> <p>No error raised by TeamCity when parsing the <code>JUnitReport.xml</code>.</p> <p>Details (please complete the following information):</p> <p>Flank 20.06.2</p>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#additional-info","title":"Additional info","text":"<p>Asked user for providing raport which fails on TeamCity CI and he replied with failing report fail:</p> <pre><code>&lt;?xml version='1.0' encoding='UTF-8' ?&gt;\n&lt;testsuites&gt;\n  &lt;testsuite name=\"Pixel2-27-en-portrait\" tests=\"2\" failures=\"0\" flakes=\"0\" errors=\"0\" skipped=\"0\" time=\"39.151\" timestamp=\"2020-07-01T16:46:41\" hostname=\"localhost\"&gt;\n    &lt;testcase name=\"loginSuccessBetaEnvTest\" classname=\"com.miquido.play360.login.LoginBetaEnvTest\" time=\"19.133\"/&gt;\n    &lt;testcase name=\"testPaymentsCard\" classname=\"com.miquido.play360.dashboard.PaymentCardBetaEnvTest\" time=\"20.019\"/&gt;\n  &lt;/testsuite&gt;\n&lt;/testsuites&gt;\n</code></pre>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#problem-investigation-techniques","title":"Problem investigation techniques","text":""},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#validate-xml","title":"Validate XML","text":""},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#description_1","title":"Description","text":"<p>Attached XML report was checked using some online tools to validate XML files</p>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#execution","title":"Execution","text":"<p>Following sites were used to validate XML (https://www.xmlvalidation.com/, https://www.w3schools.com/xml/xml_validator.asp, https://www.freeformatter.com/xml-validator-xsd.html, https://codebeautify.org/xmlvalidator, https://www.liquid-technologies.com/online-xml-validator)</p>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#results","title":"Results","text":"<p>All tools confirm that provided XML report is valid</p>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#clear-xml-buffer-unnecessary-characters","title":"Clear XML buffer unnecessary characters","text":""},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#description_2","title":"Description","text":"<p>During research about stack trace provided in the task description, user suggest on stack overflow that some XML files could contain bad whitespace characters which are bytes order marked</p>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#execution_1","title":"Execution","text":"<ol> <li>Change <code>JUnitXML.kt</code> file to trim characters suggested in post</li> </ol> <pre><code>fun JUnitTestResult?.xmlToString(): String {\n    if (this == null) return \"\"\n    val prefix = \"&lt;?xml version='1.0' encoding='UTF-8'?&gt;\"\n\n    return (prefix + System.lineSeparator() + xmlPrettyWriter.writeValueAsString(this)).clearByteOrderMarkersFromBuffer()\n}\n\n// According to occasional problem with parsing byte order markers should be cleared from buffer\n// https://stackoverflow.com/a/3030913\nprivate fun String.clearByteOrderMarkersFromBuffer() = trim().replaceFirst(\"^([\\\\W]+)&lt;\",\"&lt;\")\n</code></pre> <ol> <li>Try following code when reading file and compare it without using option to clear buffer</li> </ol>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#results_1","title":"Results","text":"<p>No characters were deleted, XML has the same length with and without suggested \"fix\"</p>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#checking-hex-code-of-provided-raport","title":"Checking hex code of provided raport","text":""},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#description_3","title":"Description","text":"<p>XML report hex code was checked to make sure that no unnecessary characters are added to the file.</p>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#execution_2","title":"Execution","text":"<ol> <li>The report was parsed to hex representation of chars and then in revert side. Used websites (https://tomeko.net/online_tools/file_to_hex.php, https://tomeko.net/online_tools/hex_to_file.php)</li> <li>The file was checked using online hex viewer </li> </ol>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#results_2","title":"Results","text":"<p>No unnecessary characters found on file.</p>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#compare-reading-report-with-using-kotlin-file-loading","title":"Compare reading report with using Kotlin file loading","text":""},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#description_4","title":"Description","text":"<p>By using <code>java.nio.File(\"JUnitReport.xml\")</code> methods <code>readLines()</code>/ <code>length()</code>/<code>readText()</code> checking is provided file is different than generated similar one (also with clearing byte order markers)</p>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#results_3","title":"Results","text":"<p>No issues found in the report</p>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#checking-git-history","title":"Checking git history","text":""},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#description_5","title":"Description","text":"<p>Checked git history of XML reporting code.</p>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#results_4","title":"Results","text":"<p>No breaking changes were introduced between Flank 8.0.1 and 20.06.2</p>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#ask-user-about-teamcity-configuration","title":"Ask user about TeamCity configuration","text":""},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#description_6","title":"Description","text":"<p>User was asked about agents count and configuration </p>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#results_5","title":"Results","text":"<p>All agents are docker's containers so they are always the same and the problem isn't here. </p> <p>User have 2 types of tests</p> <ol> <li>Using MockWebServer and have ~140 tests executed on multiple shards</li> <li>Using real backend, not many tests executed on single shards - this type of tests sometime falling</li> </ol> <p>When user back to old configuration, he can still reproduce problem</p> <p>Between versions user changed config from: <code>num-uniform-shards: 1</code> to <code>num-test-runs: 1</code></p> <p>But when user back to old configuration, he can still reproduce problem.</p>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#current-situation","title":"Current situation","text":""},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#issue-reported-to-teamcity-httpsyoutrackjetbrainscomissuetw-66753","title":"Issue reported to TeamCity https://youtrack.jetbrains.com/issue/TW-66753","text":"<p>TeamCity team cannot reproduce the problem, they asked about additional logs, but User could deliver them in next week (starting 13-07-2020), until that we must wait.</p>"},{"location":"bugs/872_error_when_parsing_Junit_raport_using_TeamCityCI/#user-is-testing-teamcity-ci-with-flank-8-to-make-sure-that-the-problem-is-related-to-flank","title":"User is testing TeamCity CI with Flank 8 to make sure that the problem is related to Flank","text":""},{"location":"bugs/891-rate-limit-exceeded/","title":"Rate limit exceeded #891","text":"<p>Reported description:</p> <p>After bump from 20.05.2 to 20.06.2 I started to see some issues related to rate limit. Also, there are no significant changes on the shard size or test amount.</p> <p>We are running another 7 flank execution in parallel. Total ~6k tests.</p>"},{"location":"bugs/891-rate-limit-exceeded/#stack-trace","title":"Stack trace","text":"<pre><code>java.io.IOException: Request failed\n  at ftl.http.ExecuteWithRetryKt$executeWithRetry$$inlined$withRetry$1.invokeSuspend(ExecuteWithRetry.kt:36)\n  at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)\n  at kotlinx.coroutines.DispatchedTask.run(Dispatched.kt:241)\n  at kotlinx.coroutines.EventLoopImplBase.processNextEvent(EventLoop.common.kt:270)\n  at kotlinx.coroutines.BlockingCoroutine.joinBlocking(Builders.kt:79)\n  at kotlinx.coroutines.BuildersKt__BuildersKt.runBlocking(Builders.kt:54)\n  at kotlinx.coroutines.BuildersKt.runBlocking(Unknown Source)\n  at kotlinx.coroutines.BuildersKt__BuildersKt.runBlocking$default(Builders.kt:36)\n  at kotlinx.coroutines.BuildersKt.runBlocking$default(Unknown Source)\n  at ftl.http.ExecuteWithRetryKt.executeWithRetry(ExecuteWithRetry.kt:41)\n  at ftl.gc.GcToolResults.getStepResult(GcToolResults.kt:98)\n  at ftl.json.SavedMatrix.finished(SavedMatrix.kt:90)\n  at ftl.json.SavedMatrix.update(SavedMatrix.kt:65)\n  at ftl.json.MatrixMapKt.update(MatrixMap.kt:47)\n  at ftl.run.NewTestRunKt$newTestRun$2$2.invokeSuspend(NewTestRun.kt:24)\n  at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)\n  at kotlinx.coroutines.ResumeModeKt.resumeUninterceptedMode(ResumeMode.kt:45)\n  at kotlinx.coroutines.internal.ScopeCoroutine.afterCompletionInternal(Scopes.kt:32)\n  at kotlinx.coroutines.JobSupport.completeStateFinalization(JobSupport.kt:310)\n  at kotlinx.coroutines.JobSupport.tryFinalizeSimpleState(JobSupport.kt:276)\n  at kotlinx.coroutines.JobSupport.tryMakeCompleting(JobSupport.kt:807)\n  at kotlinx.coroutines.JobSupport.makeCompletingOnce$kotlinx_coroutines_core(JobSupport.kt:787)\n  at kotlinx.coroutines.AbstractCoroutine.resumeWith(AbstractCoroutine.kt:111)\n  at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:46)\n  at kotlinx.coroutines.ResumeModeKt.resumeUninterceptedMode(ResumeMode.kt:45)\n  at kotlinx.coroutines.internal.ScopeCoroutine.afterCompletionInternal(Scopes.kt:32)\n  at kotlinx.coroutines.JobSupport.completeStateFinalization(JobSupport.kt:310)\n  at kotlinx.coroutines.JobSupport.tryFinalizeFinishingState(JobSupport.kt:236)\n  at kotlinx.coroutines.JobSupport.tryMakeCompletingSlowPath(JobSupport.kt:849)\n  at kotlinx.coroutines.JobSupport.tryMakeCompleting(JobSupport.kt:811)\n  at kotlinx.coroutines.JobSupport.makeCompletingOnce$kotlinx_coroutines_core(JobSupport.kt:787)\n  at kotlinx.coroutines.AbstractCoroutine.resumeWith(AbstractCoroutine.kt:111)\n  at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:46)\n  at kotlinx.coroutines.DispatchedTask.run(Dispatched.kt:241)\n  at kotlinx.coroutines.EventLoopImplBase.processNextEvent(EventLoop.common.kt:270)\n  at kotlinx.coroutines.BlockingCoroutine.joinBlocking(Builders.kt:79)\n  at kotlinx.coroutines.BuildersKt__BuildersKt.runBlocking(Builders.kt:54)\n  at kotlinx.coroutines.BuildersKt.runBlocking(Unknown Source)\n  at kotlinx.coroutines.BuildersKt__BuildersKt.runBlocking$default(Builders.kt:36)\n  at kotlinx.coroutines.BuildersKt.runBlocking$default(Unknown Source)\n  at ftl.cli.firebase.test.android.AndroidRunCommand.run(AndroidRunCommand.kt:48)\n  at picocli.CommandLine.executeUserObject(CommandLine.java:1769)\n  at picocli.CommandLine.access$900(CommandLine.java:145)\n  at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2150)\n  at picocli.CommandLine$RunLast.handle(CommandLine.java:2144)\n  at picocli.CommandLine$RunLast.handle(CommandLine.java:2108)\n  at picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:1975)\n  at picocli.CommandLine.execute(CommandLine.java:1904)\n  at ftl.Main$Companion$main$1.invoke(Main.kt:53)\n  at ftl.Main$Companion$main$1.invoke(Main.kt:43)\n  at ftl.util.Utils.withGlobalExceptionHandling(Utils.kt:130)\n  at ftl.Main$Companion.main(Main.kt:49)\n  at ftl.Main.main(Main.kt)\nC used by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 429 Too Many Requests\n{ \n  \"code\" : 429,\n  \"errors\" : [ {\n    \"domain\" : \"global\",\n    \"message\" : \"Quota exceeded for quota group 'default' and limit 'Queries per user per 100 seconds' of service 'toolresults.googleapis.com' for consumer 'project_number:x'.\",\n    \"reason\" : \"rateLimitExceeded\"\n  } ],\n  \"message\" : \"Quota exceeded for quota group 'default' and limit 'Queries per user per 100 seconds' of service 'toolresults.googleapis.com' for consumer 'project_number:x'.\",\n  \"status\" : \"RESOURCE_EXHAUSTED\"\n} \n  at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:150)\n  at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113)\n  at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40)\n  at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:443)\n  at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1092)\n  at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:541)\n  at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:474)\n  at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:591)\n  at ftl.http.ExecuteWithRetryKt$executeWithRetry$$inlined$withRetry$1.invokeSuspend(ExecuteWithRetry.kt:41)\n  ... 52 more   \n</code></pre>"},{"location":"bugs/891-rate-limit-exceeded/#reported-flank-config","title":"Reported flank config","text":"<pre><code>    flank:\n      max-test-shards: 15\n      shard-time: 160\n      num-test-runs: 1\n      smart-flank-gcs-path: gs://x/unit-tests.xml\n      smart-flank-disable-upload: false\n      files-to-download:\n      test-targets-always-run:\n      disable-sharding: false\n      project: x\n      local-result-dir: results\n      full-junit-result: true\n      # Android Flank Yml\n      keep-file-path: false\n      additional-app-test-apks:\n      run-timeout: -1\n      legacy-junit-result: false\n      ignore-failed-tests: false\n      output-style: multi\n\nRunTests\n\n Smart Flank cache hit: 100% (88 / 88)\n  Shard times: 93s, 93s\n\n  Uploadingx-app-debug.apk .\n  Uploading x-androidTest.apk .\n  88 tests / 2 shards\n</code></pre>"},{"location":"bugs/891-rate-limit-exceeded/#to-reproduce","title":"To Reproduce","text":"<p><code>shell script Flank.jar firebase test android run --num-flaky-test-attempts=0 --full-junit-result=true <pre><code>## API usage outline\nReal examples simplified to pseudo code that outlines only API call usage \n#### Gcloud\nCase for disabled sharding\n* [MonitorTestExecutionProgress](https://github.com/Flank/gcloud_cli/blob/137d864acd5928baf25434cf59b0225c4d1f9319/google-cloud-sdk/lib/googlecloudsdk/api_lib/firebase/test/matrix_ops.py#L164)\n</code></pre> while (matrix status is not completed) {     _client.projects_testMatrices.Get(         TestingProjectsTestMatricesGetRequest(projectId, testMatrixId)     )     wait(6s) } <pre><code>* [MonitorTestMatrixProgress](https://github.com/Flank/gcloud_cli/blob/137d864acd5928baf25434cf59b0225c4d1f9319/google-cloud-sdk/lib/googlecloudsdk/api_lib/firebase/test/matrix_ops.py#L248)\nCase for enabled sharding  \n</code></pre> while (matrix status is not completed) {     _client.projects_testMatrices.Get(         TestingProjectsTestMatricesGetRequest(projectId, testMatrixId)     )     wait(6s) } <pre><code>#### Flank v20.06.2\n* [pollMatrices](https://github.com/Flank/flank/blob/6ee6939263923953edf67afa7218cf2c496c2ef2/test_runner/src/main/kotlin/ftl/run/common/PollMatrices.kt#L19)\n</code></pre> forEach(test matrix) {     async while(matrix status is not completed) {         GcTestMatrix.refresh(testMatrixId, projectId)         wait(5s)     } } <pre><code>* [SavedMatrix.finished](https://github.com/Flank/flank/blob/c88cb2786de67c0a114fc31a7b25917a035e145b/test_runner/src/main/kotlin/ftl/json/SavedMatrix.kt#L75)\n</code></pre> forEach(test matrix) {     sync forEach(matrix test execution) {         GcToolResults.listTestCases(toolResultsStep)         GcToolResults.getStepResult(toolResultsStep)     }     sync forEach(matrix test execution) {         GcToolResults.getExecutionResult(testExecution)         GcToolResults.getStepResult(toolResultsStep)     } } <pre><code>#### Flank v20.05.2\n* [pollMatrices](https://github.com/Flank/flank/blob/accca3b941874e9556eea6616b34a9f4319c8746/test_runner/src/main/kotlin/ftl/run/common/PollMatrices.kt#L15)\n</code></pre> // Only the first matrix is getting status updates // the others are blocked until the first is getting completed. // As a result, it reduces the amount of requests to 1 per 5 secs. // That is why this version of the flank is not getting limit exceeded. forEach(test matrix) {     sync while(matrix status is not completed) {         GcTestMatrix.refresh(testMatrixId, projectId)         wait(5s)     } } <pre><code>#### Flank v20.06.2\n* [pollMatrices](https://github.com/Flank/flank/blob/6ee6939263923953edf67afa7218cf2c496c2ef2/test_runner/src/main/kotlin/ftl/run/common/PollMatrices.kt#L19)\n</code></pre> forEach(test matrix) {     async while(matrix status is not completed) {         GcTestMatrix.refresh(testMatrixId, projectId)         wait(5s)     } } <pre><code>* [SavedMatrix.finished](https://github.com/Flank/flank/blob/c88cb2786de67c0a114fc31a7b25917a035e145b/test_runner/src/main/kotlin/ftl/json/SavedMatrix.kt#L75)\n</code></pre> forEach(test matrix) {     sync forEach(matrix test execution) {         GcToolResults.getStepResult(toolResultsStep)     }   } <pre><code>## API calls usage comparison table\nFollowing table should compare API calls complexity.\n\n|         | execution status updates |\n|:-------:|:------------------------:|\n| Gcloud  | 1 * r / 6s + 1           |\n| 20.05.2 | 1 * r / 5s + (E * r)     |\n| 20.06.2 | M * r / 5s + (M * E * 4 * r) |\n</code></pre> r - request s - second M - count of matrixes E - count of test executions in matrix scope <pre><code>## Conclusions\n#### Gcloud\nBecause of single matrix run gives only 1 request per 6 seconds\n\n#### Flank v20.05.2\nGets matrix status updates in synchronize way so only the first matrix is getting status updates,\nthe others are blocked until the first is getting completed, so the amount of requests is reduced to 1 per 5 secs.\nPlus additional number of requests for each execution in one matrix scope.\nThat is why this version of the flank is not getting a limit exceeded.\n\n#### Flank v20.06.2\nIs polling results asynchronously for each matrix. \nAt last, it is doing a request for each test execution for each matrix, \nand this is the place where flank is getting a rate limit exceeded.\nIt is visible on stack trace.\n</code></pre>   at ftl.gc.GcToolResults.getStepResult(GcToolResults.kt:98)   at ftl.json.SavedMatrix.finished(SavedMatrix.kt:90)</code></p>"},{"location":"bugs/914_falsy_positive_outcome_for_flaky_tests/","title":"Outcome incorrectly set by Flank #914","text":""},{"location":"bugs/914_falsy_positive_outcome_for_flaky_tests/#changelog","title":"Changelog","text":"Date Who? Action 31th July 2020 pawelpasterz created 1st October 2020 adamfilipow92 update"},{"location":"bugs/914_falsy_positive_outcome_for_flaky_tests/#description","title":"Description","text":"<p><pre><code>[task 2020-07-23T20:29:15.152Z] \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n[task 2020-07-23T20:29:15.153Z] \u2502 OUTCOME \u2502      MATRIX ID       \u2502               TEST DETAILS               \u2502\n[task 2020-07-23T20:29:15.153Z] \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n[task 2020-07-23T20:29:15.153Z] \u2502  flaky  \u2502 matrix-1vj2pt9wih182 \u2502 1 test cases failed, 106 passed, 2 flaky \u2502\n[task 2020-07-23T20:29:15.153Z] \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> FTL confirmed the matrix outcome is a failure. Flank reported flaky.</p>"},{"location":"bugs/914_falsy_positive_outcome_for_flaky_tests/#steps-to-reproduce","title":"Steps to reproduce","text":"<p>So far no reliable way to reproduce it (with 10/10 rate) found. One can simulate error with the test: <pre><code>SavedMatrixTest#`savedMatrix should have failed outcome when at least one test is failed and the last one is flaky`\n</code></pre></p> <p>Due to the incorrectly implemented logic regarding the status update, there were cases when flaky tests obscure failed results. The following must occur: 1. The matrix needs to have both flaky and failed tests (at least one of each) 2. TestExecutions need to be returned in a specific order:     1. Failed execution must be consumed by flank before flaky one     2. The following flaky execution must be actually failed but the outcome of all re-runs is success 3. Then flank does what is the following:     1. The outcome is set to <code>failure</code> when failed test/shards/executions are processed     <code>kotlin    private fun Outcome?.updateOutcome(        when {            ...            else -&gt; this?.summary  // at this point SavedMatrix.outcome == success, flank changes it to failure            ...    })</code>     2. When flank reaches case where step summary is <code>failure</code> but execution is <code>success</code> it sets <code>SavedMatrix</code> outcome to flaky     <code>kotlin    updateOutcome(flakyOutcome = it.step.outcome?.summary != this?.summary) // flakyOutcome == true</code>     3. Due to incorrect order in <code>when</code> condition <code>failure</code> check is never reached      <code>kotlin    private fun Outcome?.updateOutcome(            flakyOutcome: Boolean        ) {            outcome = when {                flakyOutcome -&gt; flaky                 // flank should escape here with failure status persisted, but since flakyOutcome == true SavedMatrix.outcome is changed to flaky                outcome == failure || outcome == inconclusive -&gt; return                 outcome == flaky -&gt; this?.summary?.takeIf { it == failure || it == inconclusive }                else -&gt; this?.summary            } ?: outcome        }</code></p>"},{"location":"bugs/914_falsy_positive_outcome_for_flaky_tests/#proposed-fix","title":"Proposed fix","text":"<ol> <li>Change order in when condition to always check for <code>failure</code> first     <code>kotlin    private fun Outcome?.updateOutcome(            flakyOutcome: Boolean        ) {            outcome = when {                outcome == failure || outcome == inconclusive -&gt; return // escape when failure/inconclusive outcome is set                flakyOutcome -&gt; flaky                 outcome == flaky -&gt; this?.summary?.takeIf { it == failure || it == inconclusive }                else -&gt; this?.summary            } ?: outcome        }</code></li> <li> <p>The test below reflects potential but rare behavior.</p> <p><code>``kotlin    @Test    fun</code>savedMatrix should have flaky outcome when at least one test is flaky`() {        val expectedOutcome = \"flaky\"        val successStepExecution = createStepExecution(1) // success        // https://github.com/Flank/flank/issues/918        // This test covers edge case where summary for both step and execution is null and outcome of        // saved matrix was not changed and is set to success        val malformed = createStepExecution(stepId = -666, executionId = -666) // flaky</p> <pre><code>   // below order in the list matters!\n   val executions = listOf(\n       successStepExecution,\n       successStepExecution,\n       malformed\n   )\n\n   val testMatrix = testMatrix().apply {\n       testMatrixId = \"123\"\n       state = FINISHED\n       resultStorage = createResultsStorage()\n       testExecutions = executions\n   }\n\n   val savedMatrix = createSavedMatrix(testMatrix)\n\n   assertEquals(expectedOutcome, savedMatrix.outcome)\n</code></pre> <p>}    ```</p> </li> <li> <p>This issue is not deterministic and really difficult to reproduce by manual tests. The community not reporting this issue for some time. </p> </li> </ol>"},{"location":"bugs/986_test_count_and_smart_sharding_%20count_dont_match/","title":"Test count and smart sharding count don't match","text":"<p>Bug reported in this issue</p>"},{"location":"bugs/986_test_count_and_smart_sharding_%20count_dont_match/#the-problem","title":"The problem","text":"<p>Flank does not support parameterized tests sharding. Every class with parameterized is considered as one test during shard calculation.</p> <p>Flank is using DEX parser to decompile apks and gather info about all the tests inside. As for now, Flank is unable to determine how many times a test in a parameterized class is invoked. Due to this fact scans apks for any class with an annotation that contains <code>JUnitParamsRunner</code> or <code>Parameterized</code>:</p> <pre><code>@RunWith(JUnitParamsRunner::class)\n...\n@RunWith(Parameterized::class)\n</code></pre>"},{"location":"bugs/986_test_count_and_smart_sharding_%20count_dont_match/#solution","title":"Solution","text":"<ol> <li>Flank knows how many tests and classes are being sent to Firebase. So we can inform the user of how many classes we have. Example:</li> </ol> <pre><code> Smart Flank cache hit: 0% (0 / 9)\n  Shard times: 240s, 240s, 240s, 360s\n\n  Uploading app-debug.apk .\n  Uploading app-multiple-flaky-debug-androidTest.apk .\n  5 tests + 4 parameterized classes / 4 shards\n</code></pre> <ol> <li>Default test time for classes should be different from the default time for test</li> <li>You can set default test time for class with <code>--default-class-test-time</code> command</li> <li>If you did not set this time, the default value is 240s</li> </ol>"},{"location":"bugs/993_multiple_identical_lines_printing/","title":"Avoid multiple identical lines printing","text":"<p>Related to #993</p> <p>Sometimes Flank prints identical lines multiple times. This bug occurs rarely, there is no clear way to reproduce or force this by code changes.</p> <p>What was checked:</p> <ul> <li>[X] launched flank with a different configuration, different count of matrices</li> <li>[X] on <code>PollMatrices.kt</code> </li> </ul> <pre><code>onEach {\n      printMatrixStatus(it)\n  }\n</code></pre> <p>It always executes on the same thread so it is not a concurrency issue</p> <ul> <li> <p>[X] on <code>ExecutionStatusPrinter.kt</code> -&gt; <code>MultiLinePrinter</code> try to force remove less lines than <code>output.size</code> but in this case, this line does not update status, so the behaviour is different than on screen</p> </li> <li> <p>[X] on <code>ExecutionStatusPrinter.kt</code> -&gt; <code>MultiLinePrinter</code> try to force add to output two same ExecutionStatus but no effect</p> </li> <li> <p>[X] on <code>GcTestMatrix.kt</code> -&gt; <code>refresh()</code> try to add testSpecification with same id but without effect</p> </li> </ul>"},{"location":"bugs/deviceUsageDuration_always_null/","title":"deviceUsageDuration always null","text":""},{"location":"bugs/deviceUsageDuration_always_null/#deviceusageduration-description","title":"deviceUsageDuration description","text":"<p>How much the device resource is used to perform the test.</p> <p>This is the device usage used for billing purpose, which is different from the run_duration, for example, infrastructure failure won't be charged for device usage.</p> <p>PRECONDITION_FAILED will be returned if one attempts to set a device_usage on a step which already has this field set.</p> <ul> <li>In response: present if previously set. - In create request: optional - In update request: optional @return value or {@code null} for none</li> </ul>"},{"location":"bugs/deviceUsageDuration_always_null/#problem-description","title":"Problem description","text":"<p>Problem found on pull request: Flank needs to respect the timeout value as that's a cap for billing purposes. #865</p> <p><code>deviceUsageDuration</code> still is null even if we testing on blaze plan with free quota spent</p>"},{"location":"bugs/deviceUsageDuration_always_null/#next-steps","title":"Next steps","text":"<p>In future we should check problem status and if problem is fixed on testlab we should implement it on Flank</p>"},{"location":"bugs/null_no_tests_found/","title":"The problem","text":"<p>One or more shards failed because there are no test cases inside. This problem encounter a couple times on multi-module tests which use a lot of additional test apks. It was noticed only with the submodule tests.</p>"},{"location":"bugs/null_no_tests_found/#stack-trace","title":"Stack trace","text":"<pre><code>java.lang.ClassNotFoundException: Invalid name: no tests found\nat java.lang.Class.classForName(Native Method)\nat java.lang.Class.forName(Class.java:324)\nat androidx.test.internal.runner.TestLoader.doCreateRunner(TestLoader.java:72)\nat androidx.test.internal.runner.TestLoader.getRunnersFor(TestLoader.java:104)\nat androidx.test.internal.runner.TestRequestBuilder.build(TestRequestBuilder.java:793)\nat androidx.test.runner.AndroidJUnitRunner.buildRequest(AndroidJUnitRunner.java:547)\nat androidx.test.runner.AndroidJUnitRunner.onStart(AndroidJUnitRunner.java:390)\nat com.work.android.test.view.ViewTestRunner.onStart(ViewTestRunner.kt:25)\nat android.app.Instrumentation$InstrumentationThread.run(Instrumentation.java:1879)\n</code></pre>"},{"location":"bugs/null_no_tests_found/#firebase-screens","title":"Firebase screens","text":""},{"location":"bugs/null_no_tests_found/#references","title":"References","text":"<ul> <li>github issue https://github.com/Flank/flank/issues/818</li> <li>reported for Flank v20.05.2</li> </ul>"},{"location":"bugs/null_no_tests_found/#reported-flank-config","title":"Reported flank config","text":"<pre><code>flank:\n  additional-app-test-apks:\n  - test: feature/1/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/2/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/3/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/4/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/5/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/6/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/7/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/8/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/9/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/10/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/11/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/12/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/13/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/14/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/15/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/16/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/17/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/18/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/19/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/20/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/21/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/22/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/23/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/24/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/25/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/26/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  - test: feature/27/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  legacy-junit-result: 'false'\n  local-result-dir: sub-modules-flank-results\n  max-test-shards: 5\n  project: project-id-12345\n  run-timeout: 20m\n  smart-flank-gcs-path: gs://project-id-12345-flank/submodules-timing.xml\ngcloud:\n  app: ./sample-app/build/outputs/apk/debug/sample-app-tester-debug.apk\n  async: false\n  auto-google-login: false\n  device:\n  - model: NexusLowRes\n    version: 23\n  environment-variables:\n    clearPackageData: true\n  performance-metrics: false\n  record-video: false\n  results-bucket: sub-modules-flank-results\n  test: feature/28/build/outputs/apk/androidTest/debug/android-debug-androidTest.apk\n  test-targets:\n  - notAnnotation org.junit.Ignore\n  use-orchestrator: true\n</code></pre>"},{"location":"bugs/null_no_tests_found/#reported-fladle-config","title":"Reported fladle config","text":"<pre><code>fladle {\n    serviceAccountCredentials = file(\"pathToCredentials\")\n    useOrchestrator = true\n    environmentVariables = [\n        \"clearPackageData\"     : \"true\"\n    ]\n    timeoutMin = 30\n    recordVideo = true\n    performanceMetrics = false\n    devices = [\n        [\"model\": \"Pixel2\", \"version\": \"27\", \"orientation\": \"portrait\", \"locale\": \"en\"]\n    ]\n    projectId = \"id\"\n    flankVersion = \"20.05.2\"\n    testShards = 5\n    flakyTestAttempts = 0\n}\n</code></pre>"},{"location":"bugs/null_no_tests_found/#what-we-know-from-report-issue","title":"What we know from report issue","text":"<ol> <li>Firebase shows error <code>null</code> <code>no tests found</code></li> <li>Same error occurs with and without <code>test-targets: - notAnnotation org.junit.Ignore</code></li> <li>With <code>test-targets: - notAnnotation org.junit.Ignore</code> firebase additionally shows <code>One or more shards failed because there are no test cases inside. Please check your sharding configuration.</code></li> <li>Occurs with custom annotation-based filter.</li> <li>It was noticed only with the multi-module tests.</li> <li>If number of <code>shards &gt; 2</code>, there is a high chance one of the shards will have no tests.</li> <li><code>test-targets-always-run</code> is not the case.</li> <li>Duplicated apk names probably are not the case, but we should ensure.</li> </ol>"},{"location":"bugs/null_no_tests_found/#how-to-reproduce-it","title":"How to reproduce it","text":"<ul> <li>Use <code>additional-test-app-apk</code> option and set different apks with same names from different directories. Apks will overlap on bucket because of names collision. This should give similar result to reported.  </li> </ul>"},{"location":"bugs/null_no_tests_found/#proposals","title":"Proposals","text":"<ul> <li>~~Drop ignored tests before shard calculation and use them only for results. https://github.com/Flank/flank/pull/853~~</li> <li>~~Apks uploaded to bucket could overlap if has same names, fixing this could help. https://github.com/Flank/flank/pull/854~~</li> <li>Create multi-module project which will provide many test apks and try to reproduce issue.</li> <li>Ensure that our knowledge about issue in <code>What we know from report issue</code> is correct.</li> <li>Based on: https://stackoverflow.com/questions/39241640/android-instrumented-test-no-tests-found try to make real multi dex app and try trun tests on it</li> <li>Play with @BeforeClass and @Before annotations (exception on @BeforeClass produce null without test cases on test-lab).</li> </ul>"},{"location":"bugs/smart_flank_upload_results_rules/","title":"Smart Flank rules of validation result types","text":"<p>Flank trying to avoid override smart-flank-gcs-path by different JUnit report type. That's means: </p> <ol> <li> <p>If user select in <code>smart-flank-gcs-path</code> command FulJUnitResult.xml and flag <code>--full-junit-result</code> is not set Flank fail with the message</p> <pre><code>smart-flank-gcs-path is set with FullJUnitReport.xml but in this run --full-junit-result is disabled, please set --full-junit-result flag\n</code></pre> </li> <li> <p>If user set in <code>smart-flank-gcs-path</code> command JUnitResult.xml and flag <code>--full-junit-result</code> is set Flank fails with message</p> <pre><code>smart-flank-gcs-path is set with JUnitReport.xml but in this run --full-junit-result enabled, please turn off --full-junit-result flag\n</code></pre> </li> <li> <p>If <code>smart-flank-gcs-path</code> is set to a different name than <code>JUnitReport.xml</code> and <code>FullJUnitReport.xml</code> flank not validating report type</p> </li> <li> <p>Flank not validating report type if flag <code>--smart-flank-disable-upload</code> set</p> </li> </ol>"},{"location":"desktop/flank_desktop/","title":"Flank desktop prototype","text":""},{"location":"desktop/flank_desktop/#prototype-flank-options","title":"Prototype Flank options","text":"<p>The prototype will run a simple Android test on a given apk and test the apk with options to specify some flanks flags, as well as max tests shards.</p> <ul> <li>Flags</li> <li>disable sharding</li> <li>disable results upload</li> <li>fail fast</li> <li>disable usage statistics</li> <li> <p>auto Google login</p> </li> <li> <p>Input</p> </li> <li>Max tests shards</li> <li>apk path</li> <li>test apk path</li> </ul>"},{"location":"desktop/flank_desktop/#prototype-design","title":"Prototype design","text":"<p>The mockup of the design is shown below:</p> <p></p>"},{"location":"desktop/flank_desktop/#design-elements","title":"Design elements","text":"<ul> <li>At the top left side there are some small buttons to toggle state of boolean options</li> <li>Below there is text field to input <code>maxTestsShards</code></li> <li>Below there are two text fields with buttons placed at the right to open file chooser/provide a path to files</li> <li>At the very bottom of left column there is a button to start Flank test run.</li> <li>On the right side there is a big window which is responsible for displaying output</li> </ul>"},{"location":"desktop/flank_desktop/#setup","title":"Setup","text":"<p>Please follow getting started guide to set up new module for a prototype. There is also a gradle plugin for simplifying usage of Jetbrains compose. More info on project page.</p>"},{"location":"desktop/flank_desktop/#additional-resources","title":"Additional resources","text":"<ul> <li>IntelliJ Idea plugin</li> <li>Tutorial</li> <li>Latest build</li> <li>Template to use without gradle</li> </ul>"},{"location":"feature/1532-explore-test-target-for-shards-with-extra-features/","title":"Auto discover rest of tests when using test-target-for-shards option","text":"<p>Currently, when using <code>test-target-for-shards</code> you need to specify all tests manually to split to shards. If you do not do that then only listed tests are executed. It will be good to provide an option to auto-discover other than specified tests to make <code>test-target-for-shards</code> better and easier to use.</p>"},{"location":"feature/1532-explore-test-target-for-shards-with-extra-features/#references","title":"References","text":"<ul> <li>Conversation on Slack</li> <li>1532</li> </ul>"},{"location":"feature/1532-explore-test-target-for-shards-with-extra-features/#motivation","title":"Motivation","text":"<p><code>test-target-for-shards</code> is not so easy to use, this change will improve it when using Flank and give users more flexibility and control over creating shards.</p>"},{"location":"feature/1532-explore-test-target-for-shards-with-extra-features/#goals","title":"Goals","text":"<ol> <li>New option is available on the flank configuration level</li> <li>User could specify which packages/class/tests run on specific shards by using a new option</li> <li>Other tests that are not specified are then automatically added to a different set of shards/shard</li> </ol>"},{"location":"feature/1532-explore-test-target-for-shards-with-extra-features/#design","title":"Design","text":"<ul> <li>Add new option under Flank configuration, possible ideas are: <code>plan-sharding</code>, <code>tests-for-shards</code>, <code>smart-test-targets-for-shards</code>.</li> <li>New option should at least behave the same as <code>test-target-for-shards</code>.</li> <li>The left over tests should then be sorted into other shards or a single shard based upon the configuration provided by the user.</li> <li>Flank should fast fail if <code>disable-sharding</code> is set to <code>true</code>  or <code>max-test-shards</code> is lower than specified test shards   by user + 1.</li> </ul>"},{"location":"feature/1532-explore-test-target-for-shards-with-extra-features/#api","title":"API","text":"<p>It is hard to plan for this change to the API because by the time this is worked upon the codebase may have changed significantly influencing the usage of this request. This option will be applied to many places in code. Please follow up <code>Design</code> section for the implementation plan.</p>"},{"location":"feature/1532-explore-test-target-for-shards-with-extra-features/#results","title":"Results","text":"<p>A new option will be created which will split sharding based on user input or an alternative flag (described in <code>Alternative Considered</code>) which will change behavior of <code>test-target-for-shards</code>.</p>"},{"location":"feature/1532-explore-test-target-for-shards-with-extra-features/#dependencies","title":"Dependencies","text":"<p>There are no dependencies that will have a impact on this task. It is recommended to do this after  Flank's refactor to make it easier.</p>"},{"location":"feature/1532-explore-test-target-for-shards-with-extra-features/#testing","title":"Testing","text":"<ol> <li>Add some tests(not all) as a value to a new option</li> <li>Verify that they are correctly split into shards and there is one more shard with rest of tests(not specified)</li> </ol>"},{"location":"feature/1532-explore-test-target-for-shards-with-extra-features/#alternatives-considered","title":"Alternatives Considered","text":"<p>Add a new flag to Flank configuration, which overrides <code>test-target-for-shards</code> and automatically add the rest of the tests to separate shard/shards(if max tests shards are greater than left count).</p>"},{"location":"feature/1609-add-apk-name-to-result-matrix/","title":"Add apk name or module name to the result matrix","text":"<p>Currently, the result matrix displays matrices ids only. When there are lots of additional test apks it's hard to distinguish which apk has failed. Having the apk file name associated with the results (matrices) will give a better overview and will allow a user to find a failing apk module without the need of jumping between result URLs.</p> <p>Current result table: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 OUTCOME \u2502      MATRIX ID       \u2502      TEST AXIS VALUE       \u2502               TEST DETAILS                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 failure \u2502 matrix-b1fizzmw53qka \u2502 NexusLowRes-29-de-portrait \u2502 82 test cases failed, 206 passed, 1 flaky \u2502\n\u2502 failure \u2502 matrix-wq8upcrn5uoca \u2502 NexusLowRes-29-de-portrait \u2502 5 test cases failed, 4 passed             \u2502\n\u2502 failure \u2502 matrix-2n50loc2ze1h4 \u2502 NexusLowRes-29-de-portrait \u2502 1 test cases failed, 6 passed             \u2502\n\u2502 success \u2502 matrix-3eo91na6dzmd1 \u2502 NexusLowRes-29-de-portrait \u2502 8 test cases passed                       \u2502\n\u2502 failure \u2502 matrix-1ztkep4prcq43 \u2502 NexusLowRes-29-de-portrait \u2502 1 test cases failed                       \u2502\n\u2502 failure \u2502 matrix-w9wpp0jwt4yba \u2502 NexusLowRes-29-de-portrait \u2502 23 test cases failed, 6 passed            \u2502\n\u2502 success \u2502 matrix-30cqwb4sc1rqh \u2502 NexusLowRes-29-de-portrait \u2502 17 test cases passed                      \u2502\n\u2502 success \u2502 matrix-32kzu6e7a1t3h \u2502 NexusLowRes-29-de-portrait \u2502 2 test cases passed                       \u2502\n\u2502 failure \u2502 matrix-3dp8qqblpyav7 \u2502 NexusLowRes-29-de-portrait \u2502 20 test cases failed, 12 passed           \u2502\n\u2502 failure \u2502 matrix-zw52wsouk4zma \u2502 NexusLowRes-29-de-portrait \u2502 1 test cases failed                       \u2502\n\u2502 INVALID \u2502 matrix-36qxkc2szybc6 \u2502                            \u2502 NO_TEST_RUNNER_CLASS                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"feature/1609-add-apk-name-to-result-matrix/#references","title":"References","text":"<ul> <li>Issue #1609</li> </ul>"},{"location":"feature/1609-add-apk-name-to-result-matrix/#motivation","title":"Motivation","text":"<p>Flank gives the possibility to run multiple apks in parallel within a single test run. This feature is extensively used by companies with big projects that include a multitude of additional modules. Unfortunately, processing results in the current form is neither easy nor straightforward. The user needs to associate the matrix with the related apk/modules which can be time-consuming and error-prone. To achieve a better result overview, flank should add the apk name to both the result table and the output JSON.</p>"},{"location":"feature/1609-add-apk-name-to-result-matrix/#goals","title":"Goals","text":"<p>Add an associated apk file name to the result table and output JSON.</p>"},{"location":"feature/1609-add-apk-name-to-result-matrix/#design","title":"Design","text":"<p><code>Flank</code> is not aware of any project, modules, etc so it can't find module names on its own, in a reasonable way, without breaking backward compatibility.</p> <p>On the other hand, finding the apk file name is simple and straightforward. To achieve it we need: 1. add new field <code>app</code> to the <code>SavedMatrix</code> data class 2. update private extension function <code>SavedMatrix#updateProperties</code> to extract apk file name from the <code>newMatrix</code>    * find app used during tests under the <code>TestMatrix</code> -&gt; <code>TestSpecification</code>    * once we have <code>TestSpecification</code>, iterate over all specs (android/ios/instrumentation/etc.) and find non-null    * since we can run only one spec within a matrix, only one (spec) is non-null    * fetch <code>appApk</code> from spec (this is full <code>gs://</code> path) <code>TestSpecification#appApk</code>    * extract file name from <code>gs://</code> path    * logic should be converted to a separate function to preserve readability    * Google API likes to return <code>null</code> - flank should handle it!    * the same for empty file name (who knows what Google API will bring) 3. Update <code>SavedMatrixTableUtil</code> and add new column 4. Update <code>OutputReportLoggers</code> to log apk file name:    * switch <code>it.matrixId</code> to <code>it.app</code> in:    <pre><code> matrices.map {\n   it.matrixId to it.testAxises // it.app\n }.toMap()\n</code></pre>    * above is not resilient to the same name apks    * instead, we can add a filed under matrix id in JSON    <pre><code>\"matrix-1ealdqtvrtn5r\": {\n  \"app\": \"my-super-app.apk\",\n  \"test-axises\": [ \"results here\" ]\n}\n</code></pre></p>"},{"location":"feature/1609-add-apk-name-to-result-matrix/#api","title":"API","text":"<p>No changes.</p>"},{"location":"feature/1609-add-apk-name-to-result-matrix/#results","title":"Results","text":"<p>A new table column <code>APP</code> will be added to the result table. Similar for output JSON. <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 OUTCOME \u2502      MATRIX ID       \u2502        APP       |     TEST AXIS VALUE        \u2502               TEST DETAILS                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 failure \u2502 matrix-b1fizzmw53qka \u2502 my-super-app.apk | NexusLowRes-29-de-portrait \u2502 82 test cases failed, 206 passed, 1 flaky \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"feature/1609-add-apk-name-to-result-matrix/#dependencies","title":"Dependencies","text":"<p>There are no dependencies that will have an impact on this task.</p>"},{"location":"feature/1609-add-apk-name-to-result-matrix/#testing","title":"Testing","text":"<ol> <li>Unit test(s) should be added to verify fetching apk filename logic and its association with result matrix</li> <li>Integration tests should be updated to verify <code>App</code> column</li> </ol>"},{"location":"feature/1609-add-apk-name-to-result-matrix/#alternatives-considered","title":"Alternatives Considered","text":"<p>It would be possible to display a module name instead of an apk file name, it requires either: 1. additional option in yml for a user to provide module:    * new option in <code>IArgs</code>    * only manually 2. use Fladle to pass module information to <code>flank</code>    * can be automatic    * feature available for users who use <code>fladle</code> (not available for 'flank only users)    * requires PR for both, <code>fladle</code> and <code>flank</code>    * strong coupling between tools</p>"},{"location":"feature/1665-custom-sharding/","title":"Custom sharding","text":"<p>With #1665 Flank received the new feature called <code>Custom Sharding</code>. It enables Flank to consume predefined sharding and apply it during a test run. The feature gives flexibility and enables manual optimization. It also allows users to set up different sharding per app-test apk pair (android only).</p>"},{"location":"feature/1665-custom-sharding/#android","title":"Android","text":"<p>Below you can find an example flow with all features explained</p>"},{"location":"feature/1665-custom-sharding/#1-acquire-dump-shard-for-current-configuration","title":"1. Acquire dump shard for current configuration","text":"<p>Suppose you config with options:</p> <p><code>flank.yml</code></p> <pre><code>gcloud:\n  app: ./app-debug.apk\n  robo-script: ./MainActivity_robo_script.json\nflank:\n  max-test-shards: 2\n  additional-app-test-apks:\n    - test: ./debug-1.apk\n    - test: ../build-dir/debug-2.apk\n    - test: gs://path/to/your/bucket/debug-3.apk\n</code></pre> <p><code>flank firebase test android run -c=flank.yml</code> will run on 4 matrices:</p> <ul> <li>1x Robo run (just for example that <code>robo-script</code> will not collide with custom sharding on <code>additional-app-test-apks</code>)</li> <li>3x instrumentation tests with 2 shards max each</li> </ul> <p><code>flank firebase test android run -c=flank.yml --dump-shards</code> produces <code>android_shards.json</code> with sharding:</p> <pre><code>{\n  \"matrix-0\": {\n    \"app\": \"[PATH]/app-debug.apk\",\n    \"test\": \"[PATH]/debug-1.apk\",\n    \"shards\": {\n      \"shard-0\": [\n        \"class com.TestClassA#test1\",\n        \"class com.TestClassA#test2\",\n        \"class com.package2.TestClassB#test4\"\n      ],\n      \"shard-1\": [\n        \"class com.TestClassA#test3\",\n        \"class com.package2.TestClassB#test1\",\n        \"class com.package2.TestClassB#test2\",\n        \"class com.package2.TestClassB#test3\"\n      ]\n    },\n    \"junit-ignored\": [\n      \"class com.TestClassA#ignoredTest\"\n    ]\n  },\n  \"matrix-1\": {\n    \"app\": \"[PATH]/app-debug.apk\",\n    \"test\": \"[PATH]/debug-2.apk\",\n    \"shards\": {\n      \"shard-0\": [\n        \"class com.ParameterizedTest\",\n        \"class com.package3.TestClass3#test5\"\n      ],\n      \"shard-1\": [\n        \"class com.package3.TestClass3#test1\",\n        \"class com.package3.TestClass3#test2\",\n        \"class com.package3.TestClass3#test3\",\n        \"class com.package3.TestClass3#test4\"\n      ]\n    },\n    \"junit-ignored\": [\n      \"class com.package.3.TestClassA#ignoredTest1\",\n      \"class com.package.3.TestClassA#ignoredTest2\"\n    ]\n  },\n  \"matrix-2\": {\n    \"app\": \"[PATH]/app-debug.apk\",\n    \"test\": \"[PATH]/debug-3.apk\",\n    \"shards\": {\n      \"shard-0\": [\n        \"class com.package4.TestClass4#test1\",\n        \"class com.package4.TestClass4#test2\",\n        \"class com.package4.subpackage.TestClass6#test3\"\n      ],\n      \"shard-1\": [\n        \"class com.package4.TestClass4#test3\",\n        \"class com.package4.subpackage.TestClass6#test1\",\n        \"class com.package4.subpackage.TestClass6#test2\"\n      ]\n    },\n    \"junit-ignored\": [\n    ]\n  }\n}\n</code></pre>"},{"location":"feature/1665-custom-sharding/#2-prepare-custom-sharding-json-file","title":"2. Prepare custom sharding JSON file","text":"<p>You can now make changes as you wish, flank will attempt to find corresponding app-test pair names, and then apply custom sharding.</p> <ol> <li>for <code>debug-1.apk</code> let's add another shard and move <code>TestClassB#test4</code> &amp; <code>TestClassB#test3</code> into it:</li> </ol> <pre><code>{\n  \"matrix-0\": {\n    \"app\": \"[PATH]/app-debug.apk\",\n    \"test\": \"[PATH]/debug-1.apk\",\n    \"shards\": {\n      \"shard-0\": [\n        \"class com.TestClassA#test1\",\n        \"class com.TestClassA#test2\"\n      ],\n      \"shard-1\": [\n        \"class com.TestClassA#test3\",\n        \"class com.package2.TestClassB#test1\",\n        \"class com.package2.TestClassB#test2\"\n      ],\n      \"shard-2\": [\n        \"class com.package2.TestClassB#test4\",\n        \"class com.package2.TestClassB#test3\"\n      ]\n    },\n    \"junit-ignored\": [\n      \"class com.TestClassA#ignoredTest\"\n    ]\n  },\n  \"matrix-1\": {...},\n  \"matrix-2\": {...}\n}\n</code></pre> <ol> <li>for <code>debug-2.apk</code> we know that parameterized test takes lots of time so we want to have it in a separate shard:</li> </ol> <pre><code>{\n  \"matrix-0\": {...},\n  \"matrix-1\": {\n    \"app\": \"[PATH]/app-debug.apk\",\n    \"test\": \"[PATH]/debug-2.apk\",\n    \"shards\": {\n      \"shard-0\": [\n        \"class com.ParameterizedTest\"\n      ],\n      \"shard-1\": [\n        \"class com.package3.TestClass3#test1\",\n        \"class com.package3.TestClass3#test2\",\n        \"class com.package3.TestClass3#test3\",\n        \"class com.package3.TestClass3#test4\",\n        \"class com.package3.TestClass3#test5\"\n      ]\n    },\n    \"junit-ignored\": [\n      \"class com.package.3.TestClassA#ignoredTest1\",\n      \"class com.package.3.TestClassA#ignoredTest2\"\n    ]\n  },\n  \"matrix-2\": {...}\n}\n</code></pre> <ol> <li>for <code>debug-3.apk</code> all tests are rather quick, so we don't care about sharding, let's move them into one shard:</li> </ol> <pre><code>{\n  \"matrix-0\": {...},\n  \"matrix-1\": {...},\n  \"matrix-2\": {\n    \"app\": \"[PATH]/app-debug.apk\",\n    \"test\": \"gs://path/to/your/bucket/debug-3.apk\",\n    \"shards\": {\n      \"shard-0\": [\n        \"class com.package4.TestClass4#test1\",\n        \"class com.package4.TestClass4#test2\",\n        \"class com.package4.subpackage.TestClass6#test3\",\n        \"class com.package4.TestClass4#test3\",\n        \"class com.package4.subpackage.TestClass6#test1\",\n        \"class com.package4.subpackage.TestClass6#test2\"\n      ]\n    },\n    \"junit-ignored\": [\n    ]\n  }\n}\n</code></pre> <ol> <li>Let's save newly created JSON as <code>custom_sharding.json</code></li> </ol>"},{"location":"feature/1665-custom-sharding/#3-add-custom-sharding-to-your-configuration","title":"3. Add custom sharding to your configuration","text":"<p>Update <code>flank.yml</code> with <code>custom-sharding-json</code> option:</p> <pre><code>gcloud:\n  app: ./app-debug.apk\n  robo-script: ./MainActivity_robo_script.json\nflank:\n  max-test-shards: 2\n  additional-app-test-apks:\n    - test: ./debug-1.apk\n    - test: ../build-dir/debug-2.apk\n    - test: gs://path/to/your/bucket/debug-3.apk\n  custom-sharding-json: ./custom_sharding.json\n</code></pre> <p>You can verify if shards are correctly applied by running the following command <code>flank firebase test android run -c=flank.yml --dump-shards</code>. This command will parse your shards configuration JSON into internal structures used for executing test and will print them back to the JSON file. The diff between the file specified in <code>custom-sharding-json</code> and the output file produced by <code>--dump-shards</code> should show that no changes were applied to custom shard configuration.</p>"},{"location":"feature/1665-custom-sharding/#4-start-test-run","title":"4. Start Test Run","text":"<p>You can now start a flank test run. With the updated config there will still be 4 matrices:</p> <ul> <li>1x Robo test</li> <li>3x instrumentation tests:<ul> <li><code>debug-1.apk</code> with 3 shards</li> <li><code>debug-2.apk</code> with 2 shards</li> <li><code>debug-3.apk</code> with 1 shard</li> </ul> </li> </ul>"},{"location":"feature/1665-custom-sharding/#ios","title":"iOS","text":"<p>iOS custom sharding works exactly the same as Android (dump shards, modify, add a path to JSON file, etc) with some small exceptions:</p> <ul> <li>there is no <code>additional-app-test-apks</code> feature for iOS</li> <li>every shard in iOS is a separate matrix (FTL limitations)</li> <li>dump shard JSON is different for xctestrun with test plans, therefore there is different custom sharding JSON   structure for both versions.</li> </ul>"},{"location":"feature/1665-custom-sharding/#custom-sharding-json-for-xctestrun-without-test-plans-example","title":"Custom sharding JSON for xctestrun without Test Plans (example)","text":"<pre><code>[\n  {\n    \"ExampleSwiftTests\": [\n      \"ExampleSwiftTestsClass/test1\",\n      \"ExampleSwiftTestsClass/test2\",\n      \"ExampleSwiftTestsClass/test3\",\n      \"ExampleSwiftTestsClass/test4\",\n      \"ExampleSwiftTestsClass/test5\"\n    ]\n  },\n  {\n    \"ExampleSwiftTests\": [\n      \"ExampleSwiftTestsClass/test6\",\n      \"ExampleSwiftTestsClass/test7\",\n      \"ExampleSwiftTestsClass/test8\",\n      \"ExampleSwiftTestsClass/test9\"\n    ]\n  },\n  {\n    \"ExampleSwiftTests\": [\n      \"ExampleSwiftTestsClass/test10\",\n      \"ExampleSwiftTestsClass/test11\",\n      \"ExampleSwiftTestsClass/test12\",\n      \"ExampleSwiftTestsClass/test13\"\n    ]\n  },\n  {\n    \"ExampleSwiftTests\": [\n      \"ExampleSwiftTestsClass/test14\",\n      \"ExampleSwiftTestsClass/test15\",\n      \"ExampleSwiftTestsClass/test16\",\n      \"ExampleSwiftTestsClass/test17\"\n    ]\n  }\n]\n</code></pre>"},{"location":"feature/1665-custom-sharding/#custom-sharding-json-for-xctestrun-with-test-plans-example","title":"Custom sharding JSON for xctestrun with Test Plans (example)","text":"<pre><code>{\n  \"en\": [\n    {\n      \"SecondUITests\": [\n        \"SecondUITestsClass/test2_PLLocale\",\n        \"SecondUITestsClass/test2_3\",\n        \"SecondUITestsClass/test2_ENLocale\"\n      ],\n      \"UITests\": [\n        \"UITestsClass/test1_1\",\n        \"UITestsClass/test1_2\",\n        \"UITestsClass/test1_3\"\n      ]\n    },\n    {\n      \"UITests\": [\n        \"UITestsClass/test1_ENLocale\",\n        \"UITestsClass/test1_PLLocale\"\n      ]\n    },\n    {\n      \"SecondUITests\": [\n        \"SecondUITestsClass/test2_1\",\n        \"SecondUITestsClass/test2_2\"\n      ]\n    }\n  ],\n  \"pl\": [\n    {\n      \"UITests\": [\n        \"UITestsClass/test1_1\",\n        \"UITestsClass/test1_2\",\n        \"UITestsClass/test1_3\",\n        \"UITestsClass/test1_ENLocale\",\n        \"UITestsClass/test1_PLLocale\"\n      ]\n    },\n    {\n      \"SecondUITests\": [\n        \"SecondUITestsClass/test2_1\",\n        \"SecondUITestsClass/test2_2\",\n        \"SecondUITestsClass/test2_PLLocale\",\n        \"SecondUITestsClass/test2_3\",\n        \"SecondUITestsClass/test2_ENLocale\"\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"feature/1665-custom-sharding/#note","title":"NOTE:","text":"<ul> <li>flank DOES NOT validate the provided custom sharding JSON -- it's your responsibility to provide a proper configuration</li> <li>flank will apply sharding by searching for test pairs by app apk and test apk paths</li> <li>custom sharding supports <code>gs://</code> paths</li> <li>custom sharding JSON is a source of truth -- no smart sharding is applied (or sharding related configurations)</li> <li>matrices ids and shard ids are not important, the only requirement is -- they should be unique</li> <li>you can provide custom sharding JSON created entirely from scratch</li> <li> <p>custom sharding is very similar to <code>test-targets-for-shard</code>, which means you can use the same test targets when   preparing custom sharding. Below example will create 3 shards, one for each of the packages (<code>bar</code>, <code>foo</code>, <code>parameterized</code>):</p> <pre><code>{\n  \"matrix-0\": {\n    \"app\": \"./any-app.apk\",\n    \"test\": \"./any-debug.apk\",\n    \"shards\": {\n      \"shard-0\": [\n        \"package com.bar\"\n      ],\n      \"shard-1\": [\n        \"package com.parametrized\"\n      ],\n      \"shard-2\": [\n        \"package com.similar\"\n      ]\n    },\n    \"junit-ignored\": [\n    ]\n  }\n}\n</code></pre> </li> </ul>"},{"location":"feature/1665-custom-sharding/#problems-something-missing","title":"Problems? Something missing?","text":"<p>If you believe there is a problem with the custom sharding, or you would like to have some additional feature -- let us know and create an issue in flank's backlog. Any feedback is more than welcome!</p>"},{"location":"feature/1692_test_case_based_retries/","title":"Test case based retries","text":""},{"location":"feature/1692_test_case_based_retries/#description","title":"Description","text":"<p>Test case-based retires is a feature request which automatically retries failed tests.</p>"},{"location":"feature/1692_test_case_based_retries/#things-worth-mention","title":"Things worth mention","text":"<ul> <li>[\"One thing that would be worth to keep in mind, since FTL does not support such logic it would require from flank creating new matrix (matrices) for failed tests. It's not something extremely difficult but there is another overhead. FTL will set up new device(s) and that takes some time. I think it's not a blocker but let's don't forget about it.\"(https://github.com/Flank/flank/issues/778#issuecomment-696027295)</li> <li>please also make sure that the total test count tally is not impacted by the retry. If we have 100 tests that execute, and 2 are flaky and get re-ran twice, we should still report 100 tests. I saw this issue in FTL where they actually incremented the total test count, which threw off our jenkins test analyzer.</li> </ul>"},{"location":"feature/1692_test_case_based_retries/#solution","title":"Solution","text":"<p>Failed test case retries could be done using an automatic solution that starts failing tests just after the previous test run finished. Also, there should be a possibility to manually run only failed tests based on the report from a previous run. Test case based retries will not be compatible with the FTL option <code>num-flaky-test-attempts</code>.</p>"},{"location":"feature/1692_test_case_based_retries/#automatic","title":"Automatic","text":""},{"location":"feature/1692_test_case_based_retries/#run","title":"Run","text":"<ul> <li>Flank config will contain a Boolean option to retry failed tests. When using this option flank will automatically create a new matrix with failed tests which will be run afterwards.</li> </ul>"},{"location":"feature/1692_test_case_based_retries/#implementation","title":"Implementation","text":"<ul> <li>A new option is required to be added to enable the auto-retry. When the option is present Flank will check if there are any failed tests after the test run and retry it by creating a new matrix. After running the matrix test report needs to be updated with retried test results.</li> </ul>"},{"location":"feature/1692_test_case_based_retries/#result","title":"Result","text":"<ul> <li>As a result, retried failed test run results will replace the first test run.</li> </ul>"},{"location":"feature/1692_test_case_based_retries/#possible-problems","title":"Possible problems","text":"<ul> <li>The output should clearly show information that failed tests were re-executed.</li> </ul>"},{"location":"feature/1692_test_case_based_retries/#manual","title":"Manual","text":""},{"location":"feature/1692_test_case_based_retries/#run_1","title":"Run","text":"<ul> <li>Flank will have a new command to run only failed tests. The report file should have this argument appended.</li> </ul>"},{"location":"feature/1692_test_case_based_retries/#implementation_1","title":"Implementation","text":"<ul> <li>To run manual retry failed test case-based retries a new flank command needs to be added. As an additional Flank argument, the previous report file needs to be provided</li> </ul>"},{"location":"feature/1692_test_case_based_retries/#result_1","title":"Result","text":"<ul> <li>As a result, we will get the new test run with a separate report.</li> </ul>"},{"location":"feature/ios_test_plans/","title":"Flow","text":"<p>Flow starts by parsing .xctestrun file.  Search for:  <code>__xctestrun_metadata__</code> key.</p> <pre><code>&lt;key&gt;__xctestrun_metadata__&lt;/key&gt;\n    &lt;dict&gt;\n        &lt;key&gt;FormatVersion&lt;/key&gt;\n        &lt;integer&gt;1&lt;/integer&gt;\n    &lt;/dict&gt;\n</code></pre> <ul> <li>FormatVersion: <code>1</code> - old version of .xctestrun</li> <li>FormatVersion: <code>2</code> - the newest version with test plans</li> <li>If format is different than 1 or 2 throw an error.</li> </ul>"},{"location":"feature/ios_test_plans/#formatversion-1","title":"FormatVersion: 1","text":"<p>Any other key than metadata should have corresponding TestTarget dictionary. In example below <code>EarlGreyExampleSwiftTests</code> has a TestTarget dictionary.</p> <pre><code>&lt;plist version=\"1.0\"&gt;\n&lt;dict&gt;\n    &lt;key&gt;EarlGreyExampleSwiftTests&lt;/key&gt;\n    &lt;dict&gt; &lt;!-- TestTarget --&gt;\n        &lt;key&gt;BlueprintName&lt;/key&gt;\n        &lt;string&gt;EarlGreyExampleSwiftTests&lt;/string&gt;\n        ... \n    &lt;/dict&gt;\n    &lt;key&gt;__xctestrun_metadata__&lt;/key&gt;\n    &lt;dict&gt;\n        &lt;key&gt;FormatVersion&lt;/key&gt;\n        &lt;integer&gt;1&lt;/integer&gt;\n    &lt;/dict&gt;\n&lt;/dict&gt;\n&lt;/plist&gt;\n</code></pre>"},{"location":"feature/ios_test_plans/#formatversion-2","title":"FormatVersion: 2","text":"<p>In this version, XML contains two keys: <code>TestConfigurations</code> and <code>TestPlan</code> in addition to <code>__xctestrun_metadata__</code>. </p> <p><code>TestPlan</code> is just a dictionary containing basic informations about current TestPlan. We can ignore it. So it's excluded from example xml below.</p> <p><code>TestConfigurations</code> is an array of different test configurations. Test configuration contains name property and array of TestTargets. </p> <pre><code>&lt;plist version=\"1.0\"&gt;\n&lt;dict&gt;\n    &lt;key&gt;Name&lt;/key&gt; \n    &lt;string&gt;pl&lt;/string&gt; &lt;!-- Name property --&gt;\n    &lt;key&gt;TestTargets&lt;/key&gt;\n    &lt;array&gt; &lt;!-- TestConfigurations --&gt;\n        &lt;dict&gt;\n            &lt;key&gt;BlueprintName&lt;/key&gt;\n            &lt;string&gt;UITests&lt;/string&gt;\n            &lt;!-- Test target and Test configuration properties go here --&gt;\n        &lt;/dict&gt;\n        &lt;dict&gt;\n            &lt;key&gt;BlueprintName&lt;/key&gt;\n            &lt;string&gt;SecondUITests&lt;/string&gt;\n            &lt;!-- Test target and Test configuration properties go here --&gt;\n        &lt;/dict&gt;\n    &lt;/array&gt;\n&lt;/dict&gt;\n&lt;/plist&gt;\n</code></pre> <p>Each configuration may contain different Environment Variables, languages, regions or any other properties. Those properties are stored under TestTarget. </p> <p>Currently FTL doesn't support specifying TestConfiguration for test execution.</p> <p>If there is more than one configuration FTL will probably choose one arbitrarily.</p> <p>For now Flank will allow specifying which test configuration should run with <code>only-test-configuration</code> argument.</p>"},{"location":"feature/ios_test_plans/#running-test-plan-locally","title":"Running test plan locally","text":""},{"location":"feature/ios_test_plans/#build-xcode-project","title":"Build Xcode project","text":"<p>To build example project run command below.</p> <pre><code>xcodebuild build-for-testing \\\n-allowProvisioningUpdates \\\n-project \"FlankMultiTestTargetsExample.xcodeproj\" \\\n-scheme \"AllTests\" \\ #Scheme should have test plans enabled\n-derivedDataPath \"build_testplan_device\" \\\n-sdk iphoneos | xcpretty\n</code></pre> <p>This command will generate directory: Debug-iphoneos containing binaries and .xctestrun file for each TestPlan. </p> <p>In this example scheme <code>AllTests</code> has have only one test plan: AllTests with two test configurations: <code>pl</code> and <code>en</code>. </p> <p>Test Plan contains two Test Targets: <code>UITests</code> and <code>SecondUITests</code> Outputted .xctestrun should looks like this:</p> <pre><code>&lt;plist version=\"1.0\"&gt;\n&lt;dict&gt;\n    &lt;key&gt;TestConfigurations&lt;/key&gt;\n    &lt;array&gt;\n        &lt;dict&gt;\n            &lt;key&gt;Name&lt;/key&gt;\n            &lt;string&gt;en&lt;/string&gt;\n            &lt;key&gt;TestTargets&lt;/key&gt; &lt;!-- Test Targets for `en` test configuration --&gt;\n            &lt;array&gt;\n                &lt;dict&gt;\n                    &lt;key&gt;BlueprintName&lt;/key&gt;\n                    &lt;string&gt;UITests&lt;/string&gt;\n                    &lt;key&gt;TestLanguage&lt;/key&gt;\n                    &lt;string&gt;en&lt;/string&gt;\n                    &lt;key&gt;TestRegion&lt;/key&gt;\n                    &lt;string&gt;GB&lt;/string&gt; &lt;!-- Language and region --&gt;\n                    &lt;!-- ... Other properties --&gt;\n                &lt;/dict&gt;\n                &lt;dict&gt;\n                    &lt;key&gt;BlueprintName&lt;/key&gt;\n                    &lt;string&gt;SecondUITests&lt;/string&gt;\n                    &lt;key&gt;TestLanguage&lt;/key&gt;\n                    &lt;string&gt;en&lt;/string&gt;\n                    &lt;key&gt;TestRegion&lt;/key&gt;\n                    &lt;string&gt;GB&lt;/string&gt; &lt;!-- Language and region --&gt;\n                    &lt;!-- ... Other properties --&gt;\n                &lt;/dict&gt;\n            &lt;/array&gt;\n        &lt;/dict&gt;\n        &lt;dict&gt;\n            &lt;key&gt;Name&lt;/key&gt;\n            &lt;string&gt;pl&lt;/string&gt;\n            &lt;key&gt;TestTargets&lt;/key&gt; &lt;!-- Test Targets for `pl` test configuration --&gt;\n            &lt;array&gt;\n                &lt;dict&gt;\n                    &lt;key&gt;BlueprintName&lt;/key&gt;\n                    &lt;string&gt;UITests&lt;/string&gt;\n                    &lt;key&gt;TestLanguage&lt;/key&gt;\n                    &lt;string&gt;pl&lt;/string&gt;\n                    &lt;key&gt;TestRegion&lt;/key&gt;\n                    &lt;string&gt;PL&lt;/string&gt; &lt;!-- Language and region --&gt;\n                    &lt;!-- ... Other properties --&gt;\n                &lt;/dict&gt;\n                &lt;dict&gt;\n                    &lt;key&gt;BlueprintName&lt;/key&gt;\n                    &lt;string&gt;SecondUITests&lt;/string&gt;\n                    &lt;key&gt;TestLanguage&lt;/key&gt;\n                    &lt;string&gt;pl&lt;/string&gt;\n                    &lt;key&gt;TestRegion&lt;/key&gt;\n                    &lt;string&gt;PL&lt;/string&gt; &lt;!-- Language and region --&gt;\n                    &lt;!-- ... Other properties --&gt;\n                &lt;/dict&gt;\n            &lt;/array&gt;\n        &lt;/dict&gt;\n    &lt;/array&gt;\n    &lt;key&gt;TestPlan&lt;/key&gt;\n    &lt;dict&gt;\n        &lt;key&gt;IsDefault&lt;/key&gt;\n        &lt;true/&gt;\n        &lt;key&gt;Name&lt;/key&gt;\n        &lt;string&gt;AllTests&lt;/string&gt;\n    &lt;/dict&gt;\n    &lt;key&gt;__xctestrun_metadata__&lt;/key&gt;\n    &lt;dict&gt;\n        &lt;key&gt;FormatVersion&lt;/key&gt;\n        &lt;integer&gt;2&lt;/integer&gt;\n    &lt;/dict&gt;\n&lt;/dict&gt;\n&lt;/plist&gt;\n</code></pre>"},{"location":"feature/ios_test_plans/#running-tests-on-a-local-device","title":"Running tests on a local device","text":"<p>After generating binaries and .xctestrun file we can run tests using command.</p> <pre><code>xcodebuild test-without-building \\\n-xctestrun \"build_testplan_device/Build/Products/testrun.xctestrun\" \\\n-destination \"platform=iOS,id=00008030-000209DC1A50802E\" \\\n-only-test-configuration pl | xcpretty\n</code></pre> <p>Option: <code>-only-test-configuration pl</code> allows to specify which test configuration should Xcode run.</p>"},{"location":"feature/summary_output/","title":"Formatted summary output","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 OUTCOME \u2502      MATRIX ID       \u2502     TEST AXIS VALUE      \u2502              TEST DETAILS               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 success \u2502 matrix-35czp85w4h3a7 \u2502 greatqlte-26-en-portrait \u2502 20 test cases passed                    \u2502\n\u2502 failure \u2502 matrix-35czp85w4h3a7 \u2502 Nexus6P-26-en-portrait   \u2502 1 test cases failed, 16 passed, 3 flaky \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"feature/summary_output/#user-scenario","title":"User scenario","text":"<p>As a user I want to see finely formatted summary result at the end of execution output.</p>"},{"location":"feature/summary_output/#motivation","title":"Motivation","text":"<p>Gcloud prints summary output in the table. It looks nice and is readable. Why we wouldn't have same in flank?</p>"},{"location":"feature/summary_output/#possible-outputs","title":"Possible outputs","text":"<p>Numbers represent the <code>OUTCOME</code> column, and bullet points represent the <code>TEST DETAILS</code> column.</p> <ol> <li> <p>success | flaky</p> <ul> <li><code>${1} test cases passed | ${2} skipped | ${3} flakes | (Native crash) | ---</code></li> </ul> </li> <li> <p>failure</p> <ul> <li><code>${1} test cases failed | ${2} errors | ${3} passed | ${4} skipped | ${4} flakes | (Native crash)</code></li> <li><code>Application crashed | (Native crash)</code></li> <li><code>Test timed out | (Native crash)</code></li> <li><code>App failed to install | (Native crash)</code></li> <li><code>Unknown failure | (Native crash)</code></li> </ul> </li> <li> <p>inconclusive</p> <ul> <li><code>Infrastructure failure</code></li> <li><code>Test run aborted by user</code></li> <li><code>Unknown reason</code></li> </ul> </li> <li> <p>skipped</p> <ul> <li><code>Incompatible device/OS combination</code></li> <li><code>App does not support the device architecture</code></li> <li><code>App does not support the OS version</code></li> <li><code>Unknown reason</code></li> </ul> </li> </ol>"},{"location":"feature/summary_output/#implementation-details","title":"Implementation details","text":""},{"location":"feature/summary_output/#outcome-calculation-v2-919","title":"Outcome calculation v2 #919","text":"<p>Because of rate limit issue, the new implementation of test details calculation is  based on gcloud's CreateMatrixOutcomeSummaryUsingEnvironments. which was already described in <code>Outcome calculation v1</code> section.</p> <ul> <li>The activity diagram for gcloud</li> </ul> <p></p> <ul> <li>The activity diagram for flank</li> </ul> <p></p> <p>Both diagrams are showing slightly different aspects of flow but the main difference between <code>gcloud</code> and <code>flank</code> is that the <code>flank</code> is calculating <code>billable minutes</code> in addition. The <code>billable</code> minutes are able to calculate from list of <code>steps</code>,  so while <code>gcloud</code> is fetching <code>steps</code> only when <code>environments</code> are corrupted, the flank always required at least <code>steps</code>.</p>"},{"location":"feature/summary_output/#drawbacks","title":"Drawbacks","text":"<ul> <li>Calculating outcome details basing on <code>steps</code> may not return info about flaky tests. But it is possible to reuse data that is collecting for <code>JUnitReport</code> as alternative way for generating outcome details. It should be delivered in dedicated pull request.</li> <li>Flank is not displaying info about the environment in outcome table this problem is described in #983 issue.</li> </ul>"},{"location":"feature/summary_output/#outcome-calculation-v1","title":"Outcome calculation v1","text":"<p>It should be mentioned there are some crucial differences how flank and gcloud calculates outcome value.</p> <p>Gcloud is using following API calls 1. <code>self._client.projects_histories_executions_environments.List(request)</code> 2. <code>self._client.projects_histories_executions_steps.List(request)</code></p> <p>The first one is default, but if returns any <code>environment</code> without <code>environmentResult.outcome</code>, the second one will be used to obtain <code>steps</code>.  Both <code>environments</code> and <code>steps</code> can provide <code>outcome</code>. The difference between them is the <code>steps</code> returns <code>success</code> event if tests are <code>flaky</code>. Currently, we don't know why <code>self._client.projects_histories_executions_environments.List(request)</code> may return empty <code>environmentResult.outcome</code>.</p> <p>In difference to gcloud flank uses 3 api call to obtain necessary data 1. <code>TestMatrix</code> - <code>GcTesting.get.projects().testMatrices().get(projectId, testMatrixId)</code> 2. <code>Step</code> - <code>toolsResults.projects().histories().executions().steps().get(projectId, historyId, executionId, stepId)</code> 3. <code>ListTestCasesResponse</code> - <code>toolsResults.projects().histories().executions().steps().testCases().get(projectId, historyId, executionId, stepId)</code></p> <p><code>TestMatrix</code> from first call provides <code>ToolResultsStep</code> through <code>TestExecution</code> which is used to obtain arguments for next two calls.  </p> <p>This is part of flank legacy. Those api calls provides data for <code>JUnitResult</code>.  As <code>JUnitResult</code> contains all data required to generate <code>table</code> output, we can reuse it. In result, we are forced to calculate <code>flaky</code> outcomes on flank site because of <code>step</code>. Probably it is place for little improvement in the future.</p>"},{"location":"feature/summary_output/#test-details-calculation","title":"Test details calculation","text":"<p>When flank and gcloud implementations can be slightly different because of programming languages, the logic behind is the mainly same.</p>"},{"location":"flank-github-action/flank_github_acton_sdd/","title":"Flank GitHub action","text":"<p>Add GitHub action which allows running Flank</p>"},{"location":"flank-github-action/flank_github_acton_sdd/#references","title":"References","text":"<ul> <li> <p>GitHub actions documentation</p> </li> <li> <p>Creating a Docker container action</p> </li> <li> <p>Creating a JavaScript action</p> </li> <li> <p>Creating a composite run steps action</p> </li> <li> <p>GitHub actions marketplace</p> </li> </ul>"},{"location":"flank-github-action/flank_github_acton_sdd/#motivation","title":"Motivation","text":"<p>Bitrise and Circle CI have steps in their CIs to run Flank. As GitHub is a widely used code repository and GitHub actions become more and more popular there should be also GitHub action that allows running Flank. </p> <p>After creating GitHub action, Flank could reach more users.</p>"},{"location":"flank-github-action/flank_github_acton_sdd/#goals","title":"Goals","text":"<ul> <li>Flank actions should be as easy as possible to run</li> <li>Flank action should be maintainable together with Flank runner (always be up to date with options)</li> <li>Flank action should be available on the public repository</li> </ul>"},{"location":"flank-github-action/flank_github_acton_sdd/#design","title":"Design","text":"<p>There should be a possibility to specify all flank options using GitHub action variables as input, as well as passing the configuration itself.</p> <p>User must provide at least:</p> <ul> <li>Flank version (default latest)</li> <li>platform to run (iOS or Android)</li> <li>Flank service account file to authenticate</li> <li>Flank options or flank configuration file path</li> </ul>"},{"location":"flank-github-action/flank_github_acton_sdd/#api","title":"API","text":"<p>Flank GitHub action will be developed using composite run steps action which just packs other actions and runs it as a single action.</p>"},{"location":"flank-github-action/flank_github_acton_sdd/#design-proposal","title":"Design proposal","text":"<pre><code>name: 'Flank'\ndescription: 'Run Flank from GitHub actions!'\ninputs:\n    version: \n        description: 'Version of flank to run'\n        required: true\n        default: &lt;latest&gt;\n    platform: \n        description: 'Platform to run iOS or Android'\n        required: true\n  flank_option1:\n    description: 'Description of option 1'\n    required: false # validation will done when running\n    ...\n  flank_optionN:\n    description: 'Description of option N'\n    required: false # validation will done when running\n  flank_configuration_file:\n    description: 'Path to configuration file'\n    required: false # validation will done when running\n  flank_service_account: \n      description: 'Path to service account file to authenticate'\n    required: true\noutputs:\n  output_report:\n    description: \"Output report\"\n    value: ${{ steps.report.outputs.random-id }}\nruns:\n  using: \"composite\"\n  steps:\n    - id: download flank\n      run: &lt;download flank&gt;\n      shell: bash\n    - id: validate configuration\n      run: &lt;check if configuration file or any options are specified&gt;\n      shell: bash\n    - id: run flank\n      run: &lt;check if configuration file or any options are specified&gt;\n      shell: bash\n    - id: report\n      run: &lt;show run report to user&gt;\n      shell: bash\n</code></pre>"},{"location":"flank-github-action/flank_github_acton_sdd/#usage","title":"Usage","text":""},{"location":"flank-github-action/flank_github_acton_sdd/#with-config-file","title":"With config file","text":"<pre><code>on: [push]\n\njobs:\n  hello_world_job:\n    runs-on: ubuntu-latest\n    name: A job to say hello\n    steps:\n    - uses: actions/checkout@v2\n    - id: flank\n      uses: actions/flank@v1\n      with:\n        version: '21.01.0'\n        platform: 'android'\n        flank_service_account: './service_account.json'\n        flank_configuration_file: './flank.yml'\n    - run: cat ${{ steps.flank.outputs.output_report }}\n      shell: bash\n</code></pre>"},{"location":"flank-github-action/flank_github_acton_sdd/#with-options","title":"With options","text":"<pre><code>on: [push]\n\njobs:\n  hello_world_job:\n    runs-on: ubuntu-latest\n    name: A job to say hello\n    steps:\n    - uses: actions/checkout@v2\n    - id: flank\n      uses: actions/flank@v1\n      with:\n        version: '21.01.0'\n        platform: 'android'\n        flank_service_account: './service_account.json'\n                app: \"../test_projects/android/apks/app-debug.apk\"\n              test: \"../test_projects/android/apks/app-debug-androidTest.apk\"\n              results-dir: test_dir\n                legacy-junit-result: true\n    - run: cat ${{ steps.flank.outputs.output_report }}\n      shell: bash\n</code></pre>"},{"location":"flank-github-action/flank_github_acton_sdd/#results","title":"Results","text":"<p>After finishing Flank GitHub actions should be published to GitHub actions marketplace. </p> <p>There should be also an announcement on Flank channel on Slack.</p> <p>The thing to consider is also using it for our internal verification together with integration tests</p>"},{"location":"flank-github-action/flank_github_acton_sdd/#dependencies","title":"Dependencies","text":"<p>GitHub action needs to have <code>action.yml</code> file in the root of the repository, however, Flank repository has the file for posting Slack message after release. However it is only used by Flank team, so it will be best to move it as a side repository and keep the main Flank action in Flank's mono repository</p>"},{"location":"flank-github-action/flank_github_acton_sdd/#testing","title":"Testing","text":"<p>A new testing repository will be set up to test action as described in GitHub actions documentation</p>"},{"location":"flank-github-action/flank_github_acton_sdd/#alternatives-considered","title":"Alternatives Considered","text":"<p>The investigation was done to choose the best way to develop custom GitHub action.</p> <p>Docker container action is not the best choice, because users are forced to run Flank action on Ubuntu workflow.</p> <p>The second alternative considered was using JavaScript as action language. However, this is another language to maintain in our project and it will not be the best option to choose for such an important thing</p>"},{"location":"flank-github-action/store_documentation/","title":"Store documentation","text":""},{"location":"flank-github-action/store_documentation/#action","title":"Action","text":"<p>This GitHub action allows for running Flank as a GitHub workflow.</p> <p>Documentation for Flank is at flank.github.io/flank</p>"},{"location":"flank-github-action/store_documentation/#usage","title":"Usage","text":""},{"location":"flank-github-action/store_documentation/#inputs","title":"Inputs","text":"Input name Description Required Default <code>version</code> Flank version to run. Minimal supported version is <code>v21.03.1</code>. Leaving it blank will fallback to latest version. <code>false</code> latest available <code>service_account</code> Service account to authenticate with. Could be path to file, link to file or file content itself. More information about creating a service account could be found at documentation <code>true</code> <code>platform</code> Platform to run. Could be <code>ios</code> or <code>android</code> <code>true</code> <code>flank_configuration_file</code> Flank configuration file. More information on how it should look like is in documentation <code>true</code>"},{"location":"flank-github-action/store_documentation/#outputs","title":"Outputs","text":"Output name Description <code>gcloud_results_directory</code> Link to Gcloud store where results are stored. <code>local_results_directory</code> Path to local results directory. All output files from this run are stored inside. You could use it as output artifacts."},{"location":"flank-github-action/store_documentation/#adding-to-workflows","title":"Adding to workflows","text":"<pre><code>- name: &lt;your name&gt;\n  id: &lt;id of action&gt;\n  uses: Flank/flank@master\n  with:\n    version: &lt;Flank version to run, minimum supported is v21.03.1, default latest&gt;\n    service_account: &lt;file content, file link or path to file with service account&gt; \n    platform: [android|ios]\n    flank_configuration_file: &lt;Path to configuration file&gt;\n</code></pre>"},{"location":"flank-github-action/store_documentation/#example-workflows","title":"Example workflows","text":""},{"location":"flank-github-action/store_documentation/#service-account-file-content-from-secrets","title":"Service account file content from secrets","text":"<pre><code>- name: flank run\n  id: flank_run\n  uses: Flank/flank@master\n  with:\n    # Flank version to run\n    version: v21.03.1\n    # Service account file content from secrets\n    service_account: ${{ secrets.SERVICE_ACCOUNT }} \n    # Run Android tests\n    platform: android\n    # Path to configuration file from local repo\n    flank_configuration_file: './testing/android/flank-simple-success.yml'\n\n- name: output\n  run: |\n    # Use local directory output\n    echo \"Local directory: ${{ steps.flank_run.outputs.local_results_directory }}\"\n    # Use Gcloud storage output \n    echo \"Gcloud: ${{ steps.flank_run.outputs.gcloud_results_directory }}\"\n</code></pre>"},{"location":"flank-github-action/store_documentation/#service-account-file-from-repository","title":"Service account file from repository","text":"<pre><code>- name: flank run\n  id: flank_run\n  uses: Flank/flank@master\n  with:\n    # Service account file from repository\n    service_account: './service_account.json'\n    # Run Android tests\n    platform: android\n    # Path to configuration file from local repo\n    flank_configuration_file: './testing/android/flank-simple-success.yml'\n\n- name: output\n  run: |\n    # Use local directory output\n    echo \"Local directory: ${{ steps.flank_run.outputs.local_results_directory }}\"\n    # Use Gcloud storage output \n    echo \"Gcloud: ${{ steps.flank_run.outputs.gcloud_results_directory }}\"\n</code></pre>"},{"location":"flank-github-action/store_documentation/#create-service-account-during-workflow","title":"Create service account during workflow","text":"<pre><code>- name: Create service account\n  run: echo '${{ secrets.SERVICE_ACCOUNT }}' &gt; service_account_created.json\n\n- name: flank run\n  id: flank_run\n  uses: Flank/flank@master\n  with:\n    # Service account created in previous step\n    service_account: './service_account_created.json'\n    # Run Android tests\n    platform: android\n    # Path to configuration file from local repo\n    flank_configuration_file: './testing/android/flank-simple-success.yml'\n\n- name: output\n  run: |\n    # Use local directory output\n    echo \"Local directory: ${{ steps.flank_run.outputs.local_results_directory }}\"\n    # Use Gcloud storage output \n    echo \"Gcloud: ${{ steps.flank_run.outputs.gcloud_results_directory }}\"\n</code></pre>"},{"location":"flank-github-action/store_documentation/#runner-os-support","title":"Runner OS support","text":"<p>All 3 runner operating systems are supported.</p>"},{"location":"flank-output-investigation/flank_current_output/","title":"Flank output","text":""},{"location":"flank-output-investigation/flank_current_output/#android","title":"Android","text":""},{"location":"flank-output-investigation/flank_current_output/#version-section","title":"Version section","text":"<pre><code>version: local_snapshot\nrevision: d5e7c76ab206373c6cdf0c1a25e2575f323e5929\nsession id: 7a7ceda1-658e-461f-bd37-04f2b2a90a37\n</code></pre>"},{"location":"flank-output-investigation/flank_current_output/#args-section","title":"Args section","text":"<pre><code>AndroidArgs\n    gcloud:\n      results-bucket: test-lab-v9cn46bb990nx-kz69ymd4nm9aq\n      results-dir: 2021-03-01_13-01-56.722225_lYrQ\n      record-video: false\n      timeout: 15m\n      async: false\n      client-details:\n      network-profile: null\n      results-history-name: null\n      # Android gcloud\n      app: /Users/adamfilipowicz/Repos/flank/test_runner/src/test/kotlin/ftl/fixtures/tmp/apk/app-debug.apk\n      test: /Users/adamfilipowicz/Repos/flank/test_runner/src/test/kotlin/ftl/fixtures/tmp/apk/app-single-success-debug-androidTest.apk\n      additional-apks:\n      auto-google-login: false\n      use-orchestrator: true\n      directories-to-pull:\n      grant-permissions: all\n      type: null\n      other-files:\n      scenario-numbers:\n      scenario-labels:\n      obb-files:\n      obb-names:\n      performance-metrics: false\n      num-uniform-shards: null\n      test-runner-class: null\n      test-targets:\n      robo-directives:\n      robo-script: null\n      device:\n        - model: NexusLowRes\n          version: 28\n          locale: en\n          orientation: portrait\n      num-flaky-test-attempts: 0\n      test-targets-for-shard:\n      fail-fast: false\n\n    flank:\n      max-test-shards: 1\n      shard-time: -1\n      num-test-runs: 1\n      smart-flank-gcs-path: \n      smart-flank-disable-upload: false\n      default-test-time: 120.0\n      use-average-test-time-for-new-tests: false\n      files-to-download:\n      test-targets-always-run:\n      disable-sharding: true\n      project: flank-open-source\n      local-result-dir: results\n      full-junit-result: false\n      # Android Flank Yml\n      keep-file-path: false\n      additional-app-test-apks:\n      run-timeout: -1\n      legacy-junit-result: false\n      ignore-failed-tests: false\n      output-style: single\n      disable-results-upload: false\n      default-class-test-time: 240.0\n      disable-usage-statistics: false\n      output-report: none\n</code></pre>"},{"location":"flank-output-investigation/flank_current_output/#run-tests-section","title":"Run tests section","text":"<pre><code>RunTests\n  Saved 1 shards to /Users/adamfilipowicz/Repos/flank/results/2021-03-01_13-01-56.722225_lYrQ/android_shards.json\n  Uploading [android_shards.json] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ/...\n  Uploading [app-debug.apk] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ/...\n  Uploading [app-single-success-debug-androidTest.apk] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ/...\n\n  1 test / 1 shard\n\n  Uploading [session_id.txt] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ/...\n  1 matrix ids created in 0m 5s\n  Raw results will be stored in your GCS bucket at [https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ]\n</code></pre>"},{"location":"flank-output-investigation/flank_current_output/#matrices-weblink-section","title":"Matrices webLink section","text":"<pre><code>  matrix-1kozhsv2imkru https://console.firebase.google.com/project/flank-open-source/testlab/histories/bh.da0c237aaa33732/matrices/8233077922466140188/executions/bs.d3f60304f671ce86\n</code></pre>"},{"location":"flank-output-investigation/flank_current_output/#test-status","title":"Test status","text":"<pre><code>  3m 11s Test executions status: FINISHED:1\n  3m 11s matrix-1kozhsv2imkru FINISHED\n</code></pre>"},{"location":"flank-output-investigation/flank_current_output/#cost-report-section","title":"Cost report section","text":"<pre><code>CostReport\n  Virtual devices\n    $0.02 for 1m\n\n  Uploading [CostReport.txt] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ/...\n</code></pre>"},{"location":"flank-output-investigation/flank_current_output/#results-section","title":"Results section","text":"<pre><code>MatrixResultsReport\n  1 / 1 (100.00%)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 OUTCOME \u2502      MATRIX ID       \u2502      TEST AXIS VALUE       \u2502          TEST DETAILS          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 success \u2502 matrix-1kozhsv2imkru \u2502 NexusLowRes-28-en-portrait \u2502 1 test cases passed, 1 skipped \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n  Uploading [MatrixResultsReport.txt] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ/...\n  Uploading [JUnitReport.xml] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ/...\n  Uploading [matrix_ids.json] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ/...\n\nFetchArtifacts\n    Updating matrix file\n\nMatrices webLink\n  matrix-1kozhsv2imkru https://console.firebase.google.com/project/flank-open-source/testlab/histories/bh.da0c237aaa33732/matrices/8233077922466140188/executions/bs.d3f60304f671ce86\n</code></pre>"},{"location":"flank-output-investigation/flank_current_output/#ios","title":"Ios","text":""},{"location":"flank-output-investigation/flank_current_output/#version-section_1","title":"Version section","text":"<pre><code>version: local_snapshot\nrevision: d5e7c76ab206373c6cdf0c1a25e2575f323e5929\nsession id: 7a7ceda1-658e-461f-bd37-04f2b2a90a37\n</code></pre>"},{"location":"flank-output-investigation/flank_current_output/#args-section_1","title":"Args section","text":"<pre><code>IosArgs\n    gcloud:\n      results-bucket: test-lab-v9cn46bb990nx-kz69ymd4nm9aq\n      results-dir: test_dir\n      record-video: false\n      timeout: 15m\n      async: false\n      client-details:\n      network-profile: null\n      results-history-name: null\n      # iOS gcloud\n      test: /Users/adamfilipowicz/Repos/flank/test_runner/src/test/kotlin/ftl/fixtures/tmp/ios/EarlGreyExample/EarlGreyExample.zip\n      xctestrun-file: /Users/adamfilipowicz/Repos/flank/test_runner/src/test/kotlin/ftl/fixtures/tmp/ios/EarlGreyExample/EarlGreyExampleSwiftTests.xctestrun\n      xcode-version: null\n      device:\n        - model: iphone8\n          version: 13.6\n          locale: en\n          orientation: portrait\n      num-flaky-test-attempts: 0\n      directories-to-pull:\n      other-files:\n      additional-ipas:\n      scenario-numbers:\n      type: xctest\n      app: \n      test-special-entitlements: false\n      fail-fast: false\n\n    flank:\n      max-test-shards: 1\n      shard-time: -1\n      num-test-runs: 1\n      smart-flank-gcs-path: \n      smart-flank-disable-upload: false\n      default-test-time: 120.0\n      use-average-test-time-for-new-tests: false\n      test-targets-always-run:\n      files-to-download:\n      keep-file-path: false\n      full-junit-result: false\n      # iOS flank\n      test-targets:\n      disable-sharding: false\n      project: flank-open-source\n      local-result-dir: results\n      run-timeout: -1\n      ignore-failed-tests: false\n      output-style: single\n      disable-results-upload: false\n      default-class-test-time: 240.0\n      disable-usage-statistics: false\n      only-test-configuration: \n      skip-test-configuration: \n      output-report: none\nWARNING: Google cloud storage result directory should be unique, otherwise results from multiple test matrices will be overwritten or intermingled\n</code></pre>"},{"location":"flank-output-investigation/flank_current_output/#run-tests-section_1","title":"Run tests section","text":"<pre><code>RunTests\nFound xctest: /Users/adamfilipowicz/Repos/flank/test_runner/src/test/kotlin/ftl/fixtures/tmp/ios/EarlGreyExample/Debug-iphoneos/EarlGreyExampleSwift.app/PlugIns/EarlGreyExampleSwiftTests.xctest\nisMacOS = true (mac os x)\nnm -U \"/Users/adamfilipowicz/Repos/flank/test_runner/src/test/kotlin/ftl/fixtures/tmp/ios/EarlGreyExample/Debug-iphoneos/EarlGreyExampleSwift.app/PlugIns/EarlGreyExampleSwiftTests.xctest/EarlGreyExampleSwiftTests\"\nnm -gU \"/Users/adamfilipowicz/Repos/flank/test_runner/src/test/kotlin/ftl/fixtures/tmp/ios/EarlGreyExample/Debug-iphoneos/EarlGreyExampleSwift.app/PlugIns/EarlGreyExampleSwiftTests.xctest/EarlGreyExampleSwiftTests\" | xargs -s 262144 xcrun swift-demangle\n\n Smart Flank cache hit: 0% (0 / 17)\n  Shard times: 2040s\n\n  Saved 1 shards to /Users/adamfilipowicz/Repos/flank/results/test_dir/ios_shards.json\n  Uploading [ios_shards.json] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/test_dir/...\n\n  17 tests / 1 shard\n\n  Uploading [EarlGreyExample.zip] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/test_dir/.....\n  Uploading [EarlGreyExampleSwiftTests_shard_0.xctestrun] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/test_dir/shard_0/...\n  Uploading [session_id.txt] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/test_dir/...\n  1 matrix ids created in 0m 29s\n  Raw results will be stored in your GCS bucket at [https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/test_dir]\n</code></pre>"},{"location":"flank-output-investigation/flank_current_output/#matrices-weblink-section_1","title":"Matrices webLink section","text":"<pre><code>Matrices webLink\n  matrix-3d331uzs97mlt https://console.firebase.google.com/project/flank-open-source/testlab/histories/bh.a3b607c9bb6d0088/matrices/5523514684002242128/executions/bs.70a259d113387c0c\n</code></pre>"},{"location":"flank-output-investigation/flank_current_output/#test-status_1","title":"Test status","text":"<pre><code>  3m 11s Test executions status: FINISHED:1\n  3m 11s matrix-1kozhsv2imkru FINISHED\n</code></pre>"},{"location":"flank-output-investigation/flank_current_output/#cost-report-section_1","title":"Cost report section","text":"<pre><code>CostReport\n  Physical devices\n    $0.08 for 1m\n\n  Uploading [CostReport.txt] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/test_dir/...\n</code></pre>"},{"location":"flank-output-investigation/flank_current_output/#results-section_1","title":"Results section","text":"<pre><code>MatrixResultsReport\n  1 / 1 (100.00%)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 OUTCOME \u2502      MATRIX ID       \u2502     TEST AXIS VALUE      \u2502     TEST DETAILS     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 success \u2502 matrix-3d331uzs97mlt \u2502 iphone8-13.6-en-portrait \u2502 17 test cases passed \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n  Uploading [MatrixResultsReport.txt] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/test_dir/...\n  Uploading [JUnitReport.xml] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/test_dir/...\n  Uploading [matrix_ids.json] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/test_dir/...\n\nFetchArtifacts\n    Updating matrix file\n\nMatrices webLink\n  matrix-3d331uzs97mlt https://console.firebase.google.com/project/flank-open-source/testlab/histories/bh.a3b607c9bb6d0088/matrices/5523514684002242128/executions/bs.70a259d113387c0c\n</code></pre>"},{"location":"flank-output-investigation/flank_output_proposition/","title":"Flank output proposition","text":""},{"location":"flank-output-investigation/flank_output_proposition/#android","title":"Android","text":""},{"location":"flank-output-investigation/flank_output_proposition/#version-section","title":"Version section","text":"<pre><code>version: local_snapshot\nrevision: d5e7c76ab206373c6cdf0c1a25e2575f323e5929\nsession id: 7a7ceda1-658e-461f-bd37-04f2b2a90a37\n</code></pre>"},{"location":"flank-output-investigation/flank_output_proposition/#args-section","title":"Args section","text":"<pre><code>&lt;Diff of arguments&gt;\n</code></pre>"},{"location":"flank-output-investigation/flank_output_proposition/#dump-shards","title":"Dump shards","text":"<pre><code>[Dump shards]\nSaved 1 shards to /Users/adamfilipowicz/Repos/flank/results/2021-03-01_13-01-56.722225_lYrQ/android_shards.json\nUploading [android_shards.json] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ/...\n</code></pre>"},{"location":"flank-output-investigation/flank_output_proposition/#uploading-files","title":"Uploading files","text":"<pre><code>[Uploading files]\n\nUploading [app-debug.apk] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ/...\nUploading [app-single-success-debug-androidTest.apk] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ/...\nUploading [session_id.txt] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ/...\n</code></pre>"},{"location":"flank-output-investigation/flank_output_proposition/#matrix-info","title":"Matrix info","text":"<pre><code>[Matrix info]\nFound 1 test / 1 shard\n\n1 matrix ids created in 0m 5s\n\nmatrix-1kozhsv2imkru https://console.firebase.google.com/project/flank-open-source/testlab/histories/bh.da0c237aaa33732/matrices/8233077922466140188/executions/bs.d3f60304f671ce86\n</code></pre>"},{"location":"flank-output-investigation/flank_output_proposition/#storage-information","title":"Storage information","text":"<pre><code>Raw results will be stored in your GCS bucket at [https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ]\n</code></pre>"},{"location":"flank-output-investigation/flank_output_proposition/#test-status","title":"Test status","text":"<pre><code>[Execution statuses]\n3m 11s Test executions status: FINISHED:1\n3m 11s matrix-1kozhsv2imkru FINISHED\n</code></pre>"},{"location":"flank-output-investigation/flank_output_proposition/#cost-report-section","title":"Cost report section","text":"<pre><code>[CostReport]\nVirtual devices\n$0.02 for 1m\n\nUploading [CostReport.txt] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ/...\n</code></pre>"},{"location":"flank-output-investigation/flank_output_proposition/#results-section","title":"Results section","text":"<pre><code>[MatrixResultsReport]\n1 / 1 (100.00%)\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 OUTCOME \u2502      MATRIX ID       \u2502      TEST AXIS VALUE       \u2502          TEST DETAILS          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 success \u2502 matrix-1kozhsv2imkru \u2502 NexusLowRes-28-en-portrait \u2502 1 test cases passed, 1 skipped \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nUploading [MatrixResultsReport.txt] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ/...\nUploading [JUnitReport.xml] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ/...\nUploading [matrix_ids.json] to https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-03-01_13-01-56.722225_lYrQ/...\n\nmatrix-1kozhsv2imkru https://console.firebase.google.com/project/flank-open-source/testlab/histories/bh.da0c237aaa33732/matrices/8233077922466140188/executions/bs.d3f60304f671ce86\n</code></pre>"},{"location":"flank-output-investigation/gcloud_current_output/","title":"Gcloud output","text":""},{"location":"flank-output-investigation/gcloud_current_output/#android","title":"Android","text":""},{"location":"flank-output-investigation/gcloud_current_output/#welcome-section","title":"Welcome section","text":"<pre><code>Have questions, feedback, or issues? Get support by visiting:\n  https://firebase.google.com/support/\n</code></pre>"},{"location":"flank-output-investigation/gcloud_current_output/#upload-info","title":"Upload info","text":"<pre><code>Uploading [../test_projects/android/apks/app-debug.apk] to Firebase Test Lab...\nUploading [../test_projects/android/apks/app-debug-androidTest.apk] to Firebase Test Lab...\n</code></pre>"},{"location":"flank-output-investigation/gcloud_current_output/#storage-information","title":"Storage information","text":"<pre><code>Raw results will be stored in your GCS bucket at [https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-02-28_19:08:02.351035_LadZ/]\n</code></pre>"},{"location":"flank-output-investigation/gcloud_current_output/#info-before-running-test","title":"Info before running test","text":"<pre><code>Test [matrix-1uohkjt5rsr28] has been created in the Google Cloud.\nFirebase Test Lab will execute your instrumentation test on 1 device(s).\nCreating individual test executions...done.   \n</code></pre>"},{"location":"flank-output-investigation/gcloud_current_output/#test-status","title":"Test status","text":"<pre><code>Test results will be streamed to [https://console.firebase.google.com/project/flank-open-source/testlab/histories/bh.bf178d418be9d33e/matrices/4823249401837879607].\n19:08:18 Test is Pending\n19:08:46 Starting attempt 1.\n19:08:46 Started logcat recording.\n19:08:46 Test is Running\n19:08:53 Started crash monitoring.\n19:08:53 Preparing device.\n19:09:00 Logging in to Google account on device.\n19:09:06 Installing apps.\n19:09:06 Retrieving Pre-Test Package Stats information from the device.\n19:09:06 Retrieving Performance Environment information from the device.\n19:09:06 Started crash detection.\n19:09:06 Started Out of memory detection\n19:09:06 Started performance monitoring.\n19:09:06 Started video recording.\n19:09:06 Starting instrumentation test.\n19:09:06 Completed instrumentation test.\n19:09:13 Stopped performance monitoring.\n19:09:13 Retrieving Post-test Package Stats information from the device.\n19:09:13 Logging out of Google account on device.\n19:09:20 Stopped crash monitoring.\n19:09:20 Stopped logcat recording.\n19:09:40 Done. Test time = 1 (secs)\n19:09:40 Starting results processing. Attempt: 1\n19:09:47 Completed results processing. Time taken = 4 (secs)\n19:09:47 Test is Finished\n</code></pre>"},{"location":"flank-output-investigation/gcloud_current_output/#completion-info","title":"Completion info","text":"<pre><code>Instrumentation testing complete.\n</code></pre>"},{"location":"flank-output-investigation/gcloud_current_output/#results","title":"Results","text":"<pre><code>More details are available at [https://console.firebase.google.com/project/flank-open-source/testlab/histories/bh.bf178d418be9d33e/matrices/4823249401837879607].\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 OUTCOME \u2502    TEST_AXIS_VALUE     \u2502     TEST_DETAILS    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Passed  \u2502 walleye-27-en-portrait \u2502 1 test cases passed \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"flank-output-investigation/gcloud_current_output/#survey-at-the-end","title":"Survey at the end","text":"<pre><code>To take a quick anonymous survey, run:\n  $ gcloud survey\n</code></pre>"},{"location":"flank-output-investigation/gcloud_current_output/#ios","title":"iOS","text":""},{"location":"flank-output-investigation/gcloud_current_output/#welcome-section_1","title":"Welcome section","text":"<pre><code>Have questions, feedback, or issues? Get support by emailing:\n  ftl-ios-feedback@google.com\n</code></pre>"},{"location":"flank-output-investigation/gcloud_current_output/#upload-info_1","title":"Upload info","text":"<pre><code>Uploading [./src/test/kotlin/ftl/fixtures/tmp/ios/EarlGreyExample/EarlGreyExample.zip] to Firebase Test Lab...\nUploading [./src/test/kotlin/ftl/fixtures/tmp/ios/EarlGreyExample/EarlGreyExampleSwiftTests.xctestrun] to Firebase Test Lab...\nRaw results will be stored in your GCS bucket at [https://console.developers.google.com/storage/browser/test-lab-v9cn46bb990nx-kz69ymd4nm9aq/2021-02-28_19:15:20.392870_nuvf/]\n</code></pre>"},{"location":"flank-output-investigation/gcloud_current_output/#storage-information_1","title":"Storage information","text":"<pre><code>Test [matrix-2k6ldtp789lvy] has been created in the Google Cloud.\nFirebase Test Lab will execute your xctest test on 1 device(s).\nCreating individual test executions...done. \n</code></pre>"},{"location":"flank-output-investigation/gcloud_current_output/#info-before-running-test_1","title":"Info before running test","text":"<pre><code>Test [matrix-2k6ldtp789lvy] has been created in the Google Cloud.\nFirebase Test Lab will execute your xctest test on 1 device(s).\nCreating individual test executions...done.   \n</code></pre>"},{"location":"flank-output-investigation/gcloud_current_output/#test-status_1","title":"Test status","text":"<pre><code>Test results will be streamed to [https://console.firebase.google.com/project/flank-open-source/testlab/histories/bh.a3b607c9bb6d0088/matrices/7622498233210161623].\n19:15:49 Test is Pending\n19:16:44 Starting attempt 1.\n19:16:44 Checking Internet connection...\n19:16:44 Test is Running\n19:18:22 Internet connection stable!\n19:18:41 Started device logs task\n19:20:20 Stopped device logs task\n19:20:39 Done. Test time = 62 (secs)\n19:20:39 Starting results processing. Attempt: 1\n19:20:45 Completed results processing. Time taken = 5 (secs)\n19:20:45 Test is Finished\n</code></pre>"},{"location":"flank-output-investigation/gcloud_current_output/#completion-info_1","title":"Completion info","text":"<pre><code>Xctest testing complete.\n</code></pre>"},{"location":"flank-output-investigation/gcloud_current_output/#results_1","title":"Results","text":"<pre><code>More details are available at [https://console.firebase.google.com/project/flank-open-source/testlab/histories/bh.a3b607c9bb6d0088/matrices/7622498233210161623].\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 OUTCOME \u2502     TEST_AXIS_VALUE      \u2502     TEST_DETAILS     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Passed  \u2502 iphone8-11.2-en-portrait \u2502 17 test cases passed \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"flank-scripts/","title":"flank-scripts","text":"<p>This repository contains helper scripts for developing flank. For now, it contains just release related scripts.</p>"},{"location":"flank-scripts/#build-and-usage","title":"Build and usage","text":""},{"location":"flank-scripts/#build","title":"Build","text":"<p>To build flank-scripts:   - Run script <code>buildFlankScripts.sh</code> in <code>flank-scripts/bash/</code> directory   - Run command <code>./gradlew clean flank-scripts:assemble flank-scripts:shadowJar</code> and manual copy file from <code>/flank-scripts/build/libs/flank-scripts.jar</code> to <code>flank-scripts/bash/</code>   - You could always run/build it from IntelliJ IDEA</p>"},{"location":"flank-scripts/#usage","title":"Usage","text":"<p>Run the script with arguments <code>flankScripts &lt;command group&gt; [&lt;subgroup&gt;] &lt;command name&gt; [&lt;arguments&gt;]</code></p> <p>If you need help with available commands or arguments you could always use the option <code>--help</code></p>"},{"location":"flank-scripts/#available-commands-and-options","title":"Available commands and options","text":""},{"location":"flank-scripts/#command-list","title":"Command List","text":"<ul> <li><code>assemble</code> - Group of commands to assemble application</li> <li><code>android</code> - Subgroup of commands for Android test application assembly<ul> <li><code>app</code> - Assemble Android test application</li> </ul> </li> <li><code>ios</code> - Subgroup of commands for iOS test applications assembly<ul> <li><code>earl_grey</code> - Assemble iOS earl grey application</li> <li><code>example</code> - Assemble iOS example application</li> <li><code>flank_example</code> - Assemble iOS flank example application</li> <li><code>ftl</code> - Assemble iOS ftl example application</li> <li><code>game_loop</code> - Assemble iOS game loop application</li> <li><code>test_plans</code> - Assemble iOS test plans application</li> <li><code>all</code> - Assemble all iOS applications</li> </ul> </li> <li><code>flank</code> - Build Flank</li> <li><code>go_artifacts</code> - Generate go artifacts</li> </ul> <ul> <li><code>dependencies</code>   - Group of commands related to dependencies tasks</li> <li><code>install_xcpretty</code> - Install xcpretty formatter</li> <li><code>setup_ios_env</code> - Setup iOS environment</li> <li><code>universal_framework_files</code> - Create Universal Framework files</li> <li><code>update_binaries</code> - Update binaries used by Flank</li> <li><code>update</code> - Update repository 3rd party dependencies</li> </ul> <ul> <li><code>firebase</code> - Group of commands for managing firebase integrations</li> <li><code>check_for_sdk_updates</code> - Check for new SDK features and create update tasks for it<ul> <li><code>generate_client</code> - Generate Java Client based on api schema</li> <li><code>update_api</code> - Update api schema</li> </ul> </li> </ul> <ul> <li><code>github</code> - Group of command for managing GitHub integration</li> <li><code>copy_issue_properties</code> - Copy properties(assignees, story points, labels) from issue to pull request</li> <li><code>delete_old_tag</code> - Delete old tag on GitHub</li> <li><code>delete_release</code> - Delete old release on github</li> <li><code>make_release</code> - Make new GitHub release</li> </ul> <ul> <li><code>integration_tests</code> - Group of commands for handling integration tests (1)</li> <li><code>process_results</code> - Process results of integration tests</li> </ul> <ul> <li><code>linter</code> - Group of commands used for applying correct coding style</li> <li><code>apply_to_git_hooks</code> - Apply Linter pre-commit hook</li> <li><code>apply_to_ide</code> - Apply Linter to IDE</li> </ul> <ul> <li><code>release</code> - Group of commands for creating Flank release</li> <li><code>delete_snapshot</code> - Delete snapshot package from artifacts repository</li> <li><code>generate_release_notes</code> - Generate release notes</li> <li><code>next_tag</code> - Get tag for next release</li> <li><code>sync_with_maven_central</code> - Sync artifact's repository with Maven central</li> </ul> <ul> <li><code>test_artifacts</code> - Group of commands for artifacts management</li> <li><code>download</code> - Download test artifacts zip asset to test_artifacts directory.</li> <li><code>link</code> - Create symbolic link to under test_runner/src/test/kotlin/ftl/fixtures/tmp to     test_artifacts/{branchName}.</li> <li><code>prepare</code>- Creates a fresh copy of test artifacts for the current working branch, basing on an existing one.</li> <li><code>remove_remote</code> - Remove remote copy of test artifacts.</li> <li><code>resolve</code> - Automatically prepare local artifacts if needed.</li> <li><code>unzip</code> - Unpack test artifacts zip archive.</li> <li><code>upload</code> - Upload test artifacts zip as github release asset.</li> <li><code>zip</code> - Create zip archive from test artifacts directory.</li> </ul> <p>(1) - please note that there is only one command, but it may change in the future.</p>"},{"location":"flank-scripts/#arguments","title":"Arguments","text":"<p>To show applicable arguments for command use <code>--help</code> or <code>-h</code> options: <code>flankScripts &lt;command group&gt; [&lt;subgroup&gt;] &lt;command name&gt; --help</code> or <code>flankScripts &lt;command group&gt; [&lt;subgroup&gt;] &lt;command name&gt; -h</code></p>"},{"location":"flank-scripts/#testing","title":"Testing","text":"<p>To test your script with different settings use the <code>flank-debug.properties</code> file. Uncomment and replace with desired values. Properties are skipped by git and should not be attached to a commit. Note, the <code>test</code> task ignores your own properties and will use the default.</p>"},{"location":"flank-scripts/#list-of-possible-configs","title":"List of possible configs","text":"Key Description Default value <code>repo.flank</code> Flank test runner repo. Essential property for github client. <code>Flank/flank</code> <code>repo.gcloud_cli</code> Flank's fork of gcloud sdk repo. <code>Flank/gcloud_cli</code> <code>repo.test-artifacts</code> Flank's source of artifacts (apks, binaries, etc) used for testing <code>Flank/test_artifacts</code> <code>integration.workflow-filename</code> GH Action integration tests workflow file. Used to fetch list of commits since it's last run. <code>full_suite_integration_tests.yml</code> <code>integration.issue-poster</code> Name of account that creates IT issue <code>github-actions[bot]</code> <code>sdk-check.workflow-filename</code> GH Action dependencies update workflow file. Used to fetch list of commits since it's last run. <code>update_dependencies_and_client.yml</code> <code>sdk-check.issue-poster</code> Name of account that creates dependencies issues/epics <code>github-actions[bot]</code>"},{"location":"flank-scripts/#directory-structure","title":"Directory structure","text":"<pre><code>.\n\u251c\u2500\u2500 cli\n\u2502   \u251c\u2500\u2500 Main.kt\n\u2502   \u251c\u2500\u2500 assemble\n\u2502   \u2502   \u251c\u2500\u2500 AssembleCommand.kt\n\u2502   \u2502   \u251c\u2500\u2500 FlankCommand.kt\n\u2502   \u2502   \u251c\u2500\u2500 GoCommand.kt\n\u2502   \u2502   \u251c\u2500\u2500 android\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 AndroidCommand.kt\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 AppCommand.kt\n\u2502   \u2502   \u2514\u2500\u2500 ios\n\u2502   \u2502       \u251c\u2500\u2500 EarlGreyCommand.kt\n\u2502   \u2502       \u251c\u2500\u2500 ExampleCommand.kt\n\u2502   \u2502       \u251c\u2500\u2500 FlankExampleCommand.kt\n\u2502   \u2502       \u251c\u2500\u2500 FtlCommand.kt\n\u2502   \u2502       \u251c\u2500\u2500 GameLoopExampleCommand.kt\n\u2502   \u2502       \u251c\u2500\u2500 IosCommand.kt\n\u2502   \u2502       \u251c\u2500\u2500 RunFtlLocalCommand.kt\n\u2502   \u2502       \u2514\u2500\u2500 TestPlansExample.kt\n\u2502   \u251c\u2500\u2500 dependencies\n\u2502   \u2502   \u251c\u2500\u2500 DependenciesCommand.kt\n\u2502   \u2502   \u251c\u2500\u2500 InstallXcPrettyCommand.kt\n\u2502   \u2502   \u251c\u2500\u2500 SetupIosEnvCommand.kt\n\u2502   \u2502   \u251c\u2500\u2500 UniversalFrameworkCommand.kt\n\u2502   \u2502   \u251c\u2500\u2500 UpdateBinariesCommand.kt\n\u2502   \u2502   \u2514\u2500\u2500 UpdateCommand.kt\n\u2502   \u251c\u2500\u2500 firebase\n\u2502   \u2502   \u251c\u2500\u2500 CheckForSdkUpdatesCommand.kt\n\u2502   \u2502   \u251c\u2500\u2500 FirebaseCommand.kt\n\u2502   \u2502   \u251c\u2500\u2500 GenerateClientCommand.kt\n\u2502   \u2502   \u2514\u2500\u2500 UpdateApiCommand.kt\n\u2502   \u251c\u2500\u2500 github\n\u2502   \u2502   \u251c\u2500\u2500 CopyIssuePropertiesCommand.kt\n\u2502   \u2502   \u251c\u2500\u2500 DeleteOldTagCommand.kt\n\u2502   \u2502   \u251c\u2500\u2500 DeleteReleaseCommand.kt\n\u2502   \u2502   \u251c\u2500\u2500 DownloadFlankCommand.kt\n\u2502   \u2502   \u251c\u2500\u2500 GitHubCommand.kt\n\u2502   \u2502   \u2514\u2500\u2500 MakeReleaseCommand.kt\n\u2502   \u251c\u2500\u2500 integrationtests\n\u2502   \u2502   \u251c\u2500\u2500 IntegrationTestsCommand.kt\n\u2502   \u2502   \u2514\u2500\u2500 ProcessResultCommand.kt\n\u2502   \u251c\u2500\u2500 linter\n\u2502   \u2502   \u251c\u2500\u2500 ApplyToGitHooksCommand.kt\n\u2502   \u2502   \u251c\u2500\u2500 ApplyToIdeCommand.kt\n\u2502   \u2502   \u2514\u2500\u2500 LinterCommand.kt\n\u2502   \u251c\u2500\u2500 release\n\u2502   \u2502   \u251c\u2500\u2500 GenerateReleaseNotesCommand.kt\n\u2502   \u2502   \u251c\u2500\u2500 NextTagCommand.kt\n\u2502   \u2502   \u2514\u2500\u2500 ReleaseCommand.kt\n\u2502   \u2514\u2500\u2500 testartifacts\n\u2502       \u251c\u2500\u2500 DownloadCommand.kt\n\u2502       \u251c\u2500\u2500 LinkCommand.kt\n\u2502       \u251c\u2500\u2500 PrepareCommand.kt\n\u2502       \u251c\u2500\u2500 RemoveRemoteCommand.kt\n\u2502       \u251c\u2500\u2500 ResolveCommand.kt\n\u2502       \u251c\u2500\u2500 TestArtifactsCommand.kt\n\u2502       \u251c\u2500\u2500 UnzipCommand.kt\n\u2502       \u251c\u2500\u2500 UploadCommand.kt\n\u2502       \u2514\u2500\u2500 ZipCommand.kt\n\u251c\u2500\u2500 data\n\u2502   \u2514\u2500\u2500 github\n\u2502       \u251c\u2500\u2500 GitHubErrorResponse.kt\n\u2502       \u251c\u2500\u2500 GithubApi.kt\n\u2502       \u251c\u2500\u2500 commons\n\u2502       \u2502   \u2514\u2500\u2500 LastWorkflowRunDate.kt\n\u2502       \u2514\u2500\u2500 objects\n\u2502           \u251c\u2500\u2500 GitHubCommit.kt\n\u2502           \u251c\u2500\u2500 GitHubCreateIssue.kt\n\u2502           \u251c\u2500\u2500 GitHubCreateIssueComment.kt\n\u2502           \u251c\u2500\u2500 GitHubRelease.kt\n\u2502           \u251c\u2500\u2500 GitHubSetAssigneesRequest.kt\n\u2502           \u251c\u2500\u2500 GitHubSetLabelsRequest.kt\n\u2502           \u251c\u2500\u2500 GitHubUpdateIssue.kt\n\u2502           \u251c\u2500\u2500 GitHubWorkflowRun.kt\n\u2502           \u2514\u2500\u2500 GithubPullRequest.kt\n\u251c\u2500\u2500 ops\n\u2502   \u251c\u2500\u2500 assemble\n\u2502   \u2502   \u251c\u2500\u2500 BuildFlank.kt\n\u2502   \u2502   \u251c\u2500\u2500 BuildGo.kt\n\u2502   \u2502   \u251c\u2500\u2500 android\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 BuildBaseAndroidApk.kt\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 BuildBaseAndroidTests.kt\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 BuildCucumberSampleApk.kt\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 BuildDuplicatedNamesApks.kt\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 BuildMultiModulesApks.kt\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 Common.kt\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 RunAndroidOps.kt\n\u2502   \u2502   \u2514\u2500\u2500 ios\n\u2502   \u2502       \u251c\u2500\u2500 BuildEarlGreyExample.kt\n\u2502   \u2502       \u251c\u2500\u2500 BuildExample.kt\n\u2502   \u2502       \u251c\u2500\u2500 BuildFlankExampleCommand.kt\n\u2502   \u2502       \u251c\u2500\u2500 BuildFtl.kt\n\u2502   \u2502       \u251c\u2500\u2500 BuildGameLoopExampleCommand.kt\n\u2502   \u2502       \u251c\u2500\u2500 BuildIosIPA.kt\n\u2502   \u2502       \u251c\u2500\u2500 BuildIosTestArtifacts.kt\n\u2502   \u2502       \u251c\u2500\u2500 BuildTestPlansExample.kt\n\u2502   \u2502       \u251c\u2500\u2500 IosBuildCommand.kt\n\u2502   \u2502       \u251c\u2500\u2500 RunFtlLocal.kt\n\u2502   \u2502       \u2514\u2500\u2500 UniversalFramework.kt\n\u2502   \u251c\u2500\u2500 common\n\u2502   \u2502   \u251c\u2500\u2500 DownloadSoftware.kt\n\u2502   \u2502   \u251c\u2500\u2500 EarlGreyExampleConsts.kt\n\u2502   \u2502   \u251c\u2500\u2500 GenerateChangeLog.kt\n\u2502   \u2502   \u2514\u2500\u2500 ReleaseNotesWithType.kt\n\u2502   \u251c\u2500\u2500 dependencies\n\u2502   \u2502   \u251c\u2500\u2500 InstallXcPretty.kt\n\u2502   \u2502   \u251c\u2500\u2500 SetupIosEnv.kt\n\u2502   \u2502   \u251c\u2500\u2500 UpdateAllDependencies.kt\n\u2502   \u2502   \u2514\u2500\u2500 common\n\u2502   \u2502       \u251c\u2500\u2500 DependenciesResultCheck.kt\n\u2502   \u2502       \u251c\u2500\u2500 DependencyExtensions.kt\n\u2502   \u2502       \u251c\u2500\u2500 DependencyUpdate.kt\n\u2502   \u2502       \u251c\u2500\u2500 FindOutdatedDependencies.kt\n\u2502   \u2502       \u251c\u2500\u2500 GradleDependency.kt\n\u2502   \u2502       \u251c\u2500\u2500 UpdateDependencies.kt\n\u2502   \u2502       \u251c\u2500\u2500 UpdateGradle.kt\n\u2502   \u2502       \u251c\u2500\u2500 UpdatePlugins.kt\n\u2502   \u2502       \u2514\u2500\u2500 UpdateVersionsInFile.kt\n\u2502   \u251c\u2500\u2500 firebase\n\u2502   \u2502   \u251c\u2500\u2500 CheckForSDKUpdate.kt\n\u2502   \u2502   \u251c\u2500\u2500 CommitList.kt\n\u2502   \u2502   \u251c\u2500\u2500 GenerateJavaClient.kt\n\u2502   \u2502   \u251c\u2500\u2500 SDKUpdateContext.kt\n\u2502   \u2502   \u251c\u2500\u2500 UpdateApiJson.kt\n\u2502   \u2502   \u2514\u2500\u2500 common\n\u2502   \u2502       \u2514\u2500\u2500 Extensions.kt\n\u2502   \u251c\u2500\u2500 github\n\u2502   \u2502   \u251c\u2500\u2500 CopyGitHubProperties.kt\n\u2502   \u2502   \u251c\u2500\u2500 DeleteOldRelease.kt\n\u2502   \u2502   \u251c\u2500\u2500 DeleteOldTag.kt\n\u2502   \u2502   \u251c\u2500\u2500 DownloadFlank.kt\n\u2502   \u2502   \u2514\u2500\u2500 ReleaseFlank.kt\n\u2502   \u251c\u2500\u2500 integrationtests\n\u2502   \u2502   \u251c\u2500\u2500 ProcessIntegrationTestsResult.kt\n\u2502   \u2502   \u2514\u2500\u2500 common\n\u2502   \u2502       \u251c\u2500\u2500 ITResult.kt\n\u2502   \u2502       \u251c\u2500\u2500 IntegrationResultContext.kt\n\u2502   \u2502       \u2514\u2500\u2500 PrepareMessage.kt\n\u2502   \u251c\u2500\u2500 linter\n\u2502   \u2502   \u251c\u2500\u2500 ApplyKtlintToIdea.kt\n\u2502   \u2502   \u2514\u2500\u2500 LinkGitHooks.kt\n\u2502   \u251c\u2500\u2500 release\n\u2502   \u2502   \u251c\u2500\u2500 CreateReleaseNotes.kt\n\u2502   \u2502   \u2514\u2500\u2500 NextReleaseTag.kt\n\u2502   \u251c\u2500\u2500 testartifacts\n\u2502   \u2502   \u251c\u2500\u2500 ArtifactsArchive.kt\n\u2502   \u2502   \u251c\u2500\u2500 Context.kt\n\u2502   \u2502   \u251c\u2500\u2500 DownloadFixtures.kt\n\u2502   \u2502   \u251c\u2500\u2500 Helpers.kt\n\u2502   \u2502   \u251c\u2500\u2500 LinkArtifacts.kt\n\u2502   \u2502   \u251c\u2500\u2500 PrepareTestArtifacts.kt\n\u2502   \u2502   \u251c\u2500\u2500 RemoveRemoteCopy.kt\n\u2502   \u2502   \u251c\u2500\u2500 ResolveArtifacts.kt\n\u2502   \u2502   \u251c\u2500\u2500 UploadFixtures.kt\n\u2502   \u2502   \u2514\u2500\u2500 ZipArtifacts.kt\n\u2502   \u2514\u2500\u2500 updatebinaries\n\u2502       \u251c\u2500\u2500 UpdateAtomic.kt\n\u2502       \u251c\u2500\u2500 UpdateBinaries.kt\n\u2502       \u251c\u2500\u2500 UpdateLlvm.kt\n\u2502       \u2514\u2500\u2500 UpdateSwift.kt\n\u2514\u2500\u2500 utils\n    \u251c\u2500\u2500 Env.kt\n    \u251c\u2500\u2500 FastFailForWindows.kt\n    \u251c\u2500\u2500 Git.kt\n    \u251c\u2500\u2500 GradleCommand.kt\n    \u251c\u2500\u2500 MarkdownFormatter.kt\n    \u251c\u2500\u2500 Path.kt\n    \u251c\u2500\u2500 Serialization.kt\n    \u251c\u2500\u2500 ShellExecute.kt\n    \u251c\u2500\u2500 Version.kt\n    \u2514\u2500\u2500 exceptions\n        \u251c\u2500\u2500 FlankScriptsExceptionMappers.kt\n        \u2514\u2500\u2500 FlankScriptsExceptions.kt\n</code></pre>"},{"location":"flank-scripts/command_overview/","title":"Flank-scripts command overview","text":""},{"location":"flank-scripts/command_overview/#command-list","title":"Command List","text":"<ul> <li><code>assemble</code> - Group of commands to assemble application</li> <li><code>android</code> - Subgroup of commands for Android test application assembly<ul> <li><code>app</code> - Assemble Android test application</li> </ul> </li> <li><code>ios</code> - Subgroup of commands for iOS test applications assembly<ul> <li><code>earl_grey</code> - Assemble iOS earl grey application</li> <li><code>example</code> - Assemble iOS example application</li> <li><code>flank_example</code> - Assemble iOS flank example application</li> <li><code>ftl</code> - Assemble iOS ftl example application</li> <li><code>game_loop</code> - Assemble iOS game loop application</li> <li><code>test_plans</code> - Assemble iOS test plans application</li> <li><code>all</code> - Assemble all iOS applications</li> </ul> </li> <li><code>flank</code> - Build Flank</li> <li><code>go_artifacts</code> - Generate go artifacts</li> </ul> <ul> <li><code>dependencies</code>   - Group of commands related to dependencies tasks</li> <li><code>install_xcpretty</code> - Install xcpretty formatter</li> <li><code>setup_ios_env</code> - Setup iOS environment</li> <li><code>universal_framework_files</code> - Create Universal Framework files</li> <li><code>update_binaries</code> - Update binaries used by Flank</li> <li><code>update</code> - Update repository 3rd party dependencies</li> </ul> <ul> <li><code>firebase</code> - Group of commands for managing firebase integrations</li> <li><code>check_for_sdk_updates</code> - Check for new SDK features and create update tasks for it</li> <li><code>generate_client</code> - Generate Java Client based on api schema</li> <li><code>update_api</code> - Update api schema</li> <li><code>save_service_account</code> - Save given service account to flank credentials location</li> </ul> <ul> <li><code>github</code> - Group of command for managing GitHub integration<ul> <li><code>copy_issue_properties</code> - Copy properties(assignees, story points, labels) from issue to pull request</li> <li><code>delete_old_tag</code> - Delete old tag on GitHub</li> <li><code>delete_release</code> - Delete old release on github</li> <li><code>make_release</code> - Make new GitHub release</li> <li><code>download_flank</code> - Downloads flank.jar with selected version.</li> </ul> </li> </ul> <ul> <li><code>integration_tests</code> - Group of commands for handling integration tests (1)<ul> <li><code>process_results</code> - Process results of integration tests</li> </ul> </li> </ul> <ul> <li><code>linter</code> - Group of commands used for applying correct coding style<ul> <li><code>apply_to_git_hooks</code> - Apply Linter pre-commit hook</li> <li><code>apply_to_ide</code> - Apply Linter to IDE</li> </ul> </li> </ul> <ul> <li><code>release</code> - Group of commands for creating Flank release<ul> <li><code>delete_snapshot</code> - Delete snapshot package from artifacts repository</li> <li><code>generate_release_notes</code> - Generate release notes</li> <li><code>next_tag</code> - Get tag for next release</li> <li><code>sync_with_maven_central</code> - Sync artifact's repository with Maven central</li> </ul> </li> </ul> <ul> <li><code>test_artifacts</code> - Group of commands for artifacts management<ul> <li><code>download</code> - Download test artifacts zip asset to test_artifacts directory.</li> <li><code>link</code> - Create symbolic link to under test_runner/src/test/kotlin/ftl/fixtures/tmp to   test_artifacts/{branchName}.</li> <li><code>prepare</code>- Creates a fresh copy of test artifacts for the current working branch, basing on an existing one.</li> <li><code>remove_remote</code> - Remove remote copy of test artifacts.</li> <li><code>resolve</code> - Automatically prepare local artifacts if needed.</li> <li><code>unzip</code> - Unpack test artifacts zip archive.</li> <li><code>upload</code> - Upload test artifacts zip as github release asset.</li> <li><code>zip</code> - Create zip archive from test artifacts directory.</li> </ul> </li> </ul> <p>(1) - please note that there is only one command, but it may change in the future.</p>"},{"location":"flank-scripts/command_overview/#usage","title":"Usage","text":"<p><code>flankScripts &lt;command group&gt; [&lt;subgroup&gt;] &lt;command name&gt; [&lt;arguments&gt;]</code></p>"},{"location":"flank-scripts/ops_structure/","title":"Ops structure","text":""},{"location":"flank-scripts/ops_structure/#flank-scripts-ops-package-structure","title":"Flank-scripts ops package structure","text":"<p>Flank-scripts <code>ops</code> packages mostly match <code>cli</code> structure, however, for widely used function there is a separate package called <code>common</code>. For better code organization <code>updatebinaries</code> has a separate package inside <code>dependencies</code>.</p>"},{"location":"gcloud/google_api_usecases/","title":"Google api use cases","text":""},{"location":"gcloud/google_api_usecases/#list-of-places-where-google-api-calls-are-used","title":"List of places where google api calls are used","text":""},{"location":"gcloud/google_api_usecases/#comgoogleapiclienthttp","title":"com.google.api.client.http","text":"<ol> <li>GoogleApiLogger.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlandroid","title":"ftl.android","text":"<ol> <li>AndroidCatalog.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlargs","title":"ftl.args","text":"<ol> <li>ArgsHelper.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlconfig","title":"ftl.config","text":"<ol> <li>Credentials.kt</li> <li>FtlConstants.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlenvironment","title":"ftl.environment","text":"<ol> <li>ListIPBlocks.kt</li> <li>ListLocales.kt</li> <li>LocalesDescription.kt</li> <li>NetworkProfileDescription.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlenvironmentandroid","title":"ftl.environment.android","text":"<ol> <li>AndroidModelDescription.kt</li> <li>AndroidSoftwareVersionDescription.kt</li> <li>ListAndroidDevices.kt</li> <li>ListAndroidSoftwareVersions.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlenvironmentcommon","title":"ftl.environment.common","text":"<ol> <li>ListNetworkConfiguration.kt</li> <li>ListOrientations.kt</li> <li>ListProvidedSoftware.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlenvironmentios","title":"ftl.environment.ios","text":"<ol> <li>IosModelDescription.kt</li> <li>IosSoftwareVersionDescription.kt</li> <li>ListIOsDevices.kt</li> <li>ListIOsSoftwareVersions.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlgc","title":"ftl.gc","text":"<ol> <li>GcAndroidDevice.kt</li> <li>GcAndroidTestMatrix.kt</li> <li>GcIosMatrix.kt</li> <li>GcIosTestMatrix.kt</li> <li>GcStorage.kt</li> <li>GcTesting.kt</li> <li>GcTestMatrix.kt</li> <li>GcToolResults.kt</li> <li>UserAuth.kt</li> <li>Utils.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlgcandroid","title":"ftl.gc.android","text":"<ol> <li>CreateAndroidInstrumentationTest.kt</li> <li>CreateAndroidLoopTest.kt</li> <li>CreateAndroidRobotTest.kt</li> <li>SetupAndroidTest.kt</li> <li>SetupEnvironmentVariables.kt</li> <li>Utils.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlgcios","title":"ftl.gc.ios","text":"<ol> <li>SetupIosTest.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlhttp","title":"ftl.http","text":"<ol> <li>ExecuteWithRetry.kt</li> <li>HttpTimeoutIncrease.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlios","title":"ftl.ios","text":"<ol> <li>IosCatalog.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftljson","title":"ftl.json","text":"<ol> <li>MatrixMap.kt</li> <li>OutcomeDetailsFormatter.kt</li> <li>SavedMatrix.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftllog","title":"ftl.log","text":"<ol> <li>Loggers.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlmock","title":"ftl.mock","text":"<ol> <li>MockServer.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlreports","title":"ftl.reports","text":"<ol> <li>HtmlErrorReport.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlreportsapi","title":"ftl.reports.api","text":"<ol> <li>CreateJUnitTestCase.kt</li> <li>CreateJUnitTestResult.kt</li> <li>CreateTestExecutionData.kt</li> <li>CreateTestSuiteOverviewData.kt</li> <li>PerformanceMetrics.kt</li> <li>PrepareForJUnitResult.kt</li> <li>ProcessFromApi.kt</li> <li>Utils.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlreportsapidata","title":"ftl.reports.api.data","text":"<ol> <li>TestExecutionData.kt</li> <li>TestSuiteOverviewData.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlreportsoutcome","title":"ftl.reports.outcome","text":"<ol> <li>BillableMinutes.kt</li> <li>CreateMatrixOutcomeSummary.kt</li> <li>CreateTestSuiteOverviewData.kt</li> <li>TestOutcome.kt</li> <li>TestOutcomeContext.kt</li> <li>Util.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlreportsutil","title":"ftl.reports.util","text":"<ol> <li>ReportManager.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlrun","title":"ftl.run","text":"<ol> <li>RefreshLastRun.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlruncommon","title":"ftl.run.common","text":"<ol> <li>FetchArtifacts.kt</li> <li>PollMatrices.kt</li> <li>PrettyPrint.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlrunmodel","title":"ftl.run.model","text":"<ol> <li>AndroidTestShards.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlrunplatform","title":"ftl.run.platform","text":"<ol> <li>RunAndroidTests.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlrunplatformcommon","title":"ftl.run.platform.common","text":"<ol> <li>AfterRunTests.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlrunstatus","title":"ftl.run.status","text":"<ol> <li>ExecutionStatusListPrinter.kt</li> <li>TestMatrixStatusPrinter.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#ftlutil","title":"ftl.util","text":"<ol> <li>MatrixState.kt</li> <li>ObfuscationGson.kt</li> <li>TestMatrixExtension.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#gcloud-api-calls-in-flank","title":"Gcloud Api Calls in Flank","text":"<ol> <li> <p>GcToolResults.kt</p> <ul> <li>createToolResultsHistory</li> <li>getExecutionResult</li> <li>getStepResult</li> <li>getPerformanceMetric</li> <li>listTestCases</li> <li>getDefaultBucket</li> <li>listAllEnvironments</li> <li>listAllSteps</li> </ul> </li> <li> <p>TestOutcomeContext.kt</p> <ul> <li>fetchTestOutcomeContext</li> </ul> </li> <li> <p>GcIosTestMatrix.kt</p> <ul> <li>build</li> </ul> </li> <li> <p>GcAndroidTestMatrix.kt</p> <ul> <li>build</li> </ul> </li> <li> <p>GcStorage.kt</p> <ul> <li>uploadWithProgress</li> <li>download</li> <li>exist</li> </ul> </li> <li> <p>Common environment information's</p> <ul> <li>ListIPBlocks.kt</li> <li>ListLocales.kt</li> <li>LocalesDescription.kt</li> <li>NetworkConfigurationCatalog.kt</li> <li>NetworkProfileDescription.kt</li> <li>ProvidedSoftwareCatalog.kt</li> <li>TestEnvironmentInfo.kt</li> </ul> </li> <li> <p>AndroidModelDescription.kt</p> </li> <li>AndroidSoftwareVersionDescription.kt</li> <li>ListAndroidDevices.kt</li> <li> <p>ListAndroidSoftwareVersions.kt</p> </li> <li> <p>IosModelDescription.kt</p> </li> <li>IosSoftwareVersionDescription.kt</li> <li>ListIOsDevices.kt</li> <li>ListIOsSoftwareVersions.kt</li> </ol>"},{"location":"gcloud/google_api_usecases/#android-run-use-case","title":"Android Run use case","text":"<ol> <li> <p>AndroidRunCommand.kt</p> <ul> <li>L: 76 <code>validate()</code></li> </ul> </li> <li> <p>ValidateAndroidArgs.kt</p> <ul> <li>L: 18 <code>AndroidArgs.validate()</code></li> <li>L: 20 <code>AndroidArgs.assertDevicesSupported()</code><ul> <li>L: 97 <code>AndroidCatalog.supportedDeviceConfig()</code></li> <li>L: 104 <code>AndroidCatalog.androidModelIds()</code></li> <li>L: 109 <code>AndroidCatalog.androidVersionIds()</code></li> <li>L: 112 <code>device.getSupportedVersionId()</code></li> </ul> </li> <li>L: 32 <code>IArgs.checkResultsDirUnique()</code></li> <li>ValidateCommonArgs.kt<ul> <li>L: 75 <code>GcStorage.exist(resultsBucket, resultsDir)</code></li> </ul> </li> </ul> </li> <li> <p>AndroidRunCommand.kt</p> <ul> <li>L: 79 <code>newTestRun()</code></li> </ul> </li> <li> <p>NewTestRun.kt</p> <ul> <li>L: 27 <code>runTests()</code></li> <li>L: 46 <code>runAndroidTests()</code></li> </ul> </li> <li> <p>RunAndroidTests.kt</p> <ul> <li>L: 46 <code>uploadOtherFiles()</code></li> <li> <p>UploadOtherFiles.kt</p> <ul> <li>L: 14 <code>GcStorage.upload()</code></li> </ul> </li> <li> <p>L: 47 <code>uploadAdditionalApks()</code></p> </li> <li> <p>UploadApks.kt</p> <ul> <li>L: 50 <code>uploadAdditionalApks()</code></li> <li>L: 56 <code>uploadToGcloudIfNeeded()</code></li> <li>FileReference.kt<ul> <li>L: 37 <code>FileReference.uploadIfNeeded()</code></li> <li>L: 42 <code>GcStorage.upload()</code></li> </ul> </li> </ul> </li> <li> <p>L: 48 <code>uploadObbFiles()</code></p> </li> <li> <p>UploadOtherFiles.kt</p> <ul> <li>L: 18 <code>uploadObbFiles()</code></li> <li>L: 20  <code>GcStorage.upload()</code></li> </ul> </li> <li> <p>L: 49 <code>createAndroidTestContexts()</code></p> </li> <li> <p>CreateAndroidTestContext.kt</p> <ul> <li>L: 30 <code>setupShards()</code></li> <li>L: 41 <code>testContext.downloadApks()</code></li> <li>L: 50 <code>app = app.downloadIfNeeded()</code></li> <li>L: 51 <code>test = test.downloadIfNeeded()</code></li> <li>FileReference.kt<ul> <li>L: 29 <code>GcStorage.download()</code></li> <li>GcStorage.kt<ul> <li>L: 179 <code>download()</code></li> </ul> </li> </ul> </li> </ul> </li> <li> <p>L: 51 <code>upload()</code></p> </li> <li> <p>UploadApks.kt</p> <ul> <li>L: 23 <code>context.upload()</code></li> <li>L: 26 <code>AndroidTestContext.upload()</code></li> <li>L: 27 <code>is InstrumentationTestContext -&gt; upload()</code></li> <li>L: 33 <code>InstrumentationTestContext.upload()</code></li> <li>L: 34 <code>app.uploadIfNeeded()</code></li> <li>L: 35 <code>test.uploadIfNeeded()</code></li> <li>FileReference.kt<ul> <li>L: 37 <code>FileReference.uploadIfNeeded()</code></li> <li>L: 42 <code>GcStorage.upload</code></li> <li>GcStorage.kt<ul> <li>L: 60 <code>upload()</code></li> </ul> </li> </ul> </li> </ul> </li> <li> <p>L: 28 <code>is RoboTestContext -&gt; upload()</code></p> </li> <li>L: 38 <code>RoboTestContext.upload()</code></li> <li>L: 39 <code>app.uploadIfNeeded()</code></li> <li>L: 40 <code>roboScript.uploadIfNeeded()</code></li> <li> <p>FileReference.kt</p> <ul> <li>L: 37 <code>FileReference.uploadIfNeeded()</code></li> <li>L: 42 <code>GcStorage.upload</code></li> <li>GcStorage.kt<ul> <li>L: 60 <code>upload()</code></li> </ul> </li> </ul> </li> <li> <p>L: 29 <code>is SanityRoboTestContext -&gt; upload()</code></p> </li> <li>L: 47 <code>SanityRoboTestContext.upload()</code></li> <li>L: 48 <code>app.uploadIfNeeded()</code></li> <li> <p>FileReference.kt</p> <ul> <li>L: 37 <code>FileReference.uploadIfNeeded()</code></li> <li>L: 42 <code>GcStorage.upload</code></li> <li>GcStorage.kt<ul> <li>L: 60 <code>upload()</code></li> </ul> </li> </ul> </li> <li> <p>L: 30 <code>is GameLoopContext -&gt; upload()</code></p> </li> <li>L: 43 <code>GameLoopContext.upload()</code></li> <li>L: 44 <code>app.uploadIfNeeded()</code></li> <li> <p>FileReference.kt</p> <ul> <li>L: 37 <code>FileReference.uploadIfNeeded()</code></li> <li>L: 42 <code>GcStorage.upload</code></li> <li>GcStorage.kt<ul> <li>L: 60 <code>upload()</code></li> </ul> </li> </ul> </li> <li> <p>L: 59 <code>GcAndroidTestMatrix.build()</code></p> </li> <li>GcAndroidTestMatrix.kt<ul> <li>L: 30 <code>build()</code></li> <li>L: 89 <code>GcTesting.get.projects().testMatrices().create()</code></li> </ul> </li> </ul> </li> <li> <p>NewTestRun.kt</p> <ul> <li>L: 35 <code>ReportManager.generate()</code></li> <li> <p>ReportManager.kt</p> <ul> <li>L: 97 <code>parseTestSuite()</code></li> <li>L: 103 <code>it.run()</code></li> <li>MatrixResultsReport.kt<ul> <li>L: 80 <code>GcStorage.uploadReportResult()</code></li> <li>GcStorage.kt<ul> <li>L: 115 <code>upload()</code></li> </ul> </li> </ul> </li> <li>CostReport.kt<ul> <li>L: 43 <code>GcStorage.uploadReportResult()</code></li> <li>GcStorage.kt<ul> <li>L: 115 <code>upload()</code></li> </ul> </li> </ul> </li> <li>L: 108 <code>it.run()</code></li> <li>HtmlErrorReport.kt<ul> <li>L: 35 <code>GcStorage.uploadReportResult()</code></li> <li>GcStorage.kt<ul> <li>L: 115 <code>upload()</code></li> </ul> </li> </ul> </li> <li>L: 87 <code>refreshMatricesAndGetExecutions()</code></li> <li> <p>ProcessFromApi.kt</p> <ul> <li>L: 13 <code>refreshMatricesAndGetExecutions()</code></li> <li>L: 18 <code>refreshTestMatrices()</code></li> <li>L: 24 <code>cTestMatrix.refresh()</code></li> </ul> </li> <li> <p>L: 121 <code>refreshMatricesAndGetExecutions()</code></p> </li> <li> <p>ProcessFromApi.kt</p> <ul> <li>L: 13 <code>refreshMatricesAndGetExecutions()</code></li> <li>L: 18 <code>refreshTestMatrices()</code></li> <li>L: 24 <code>cTestMatrix.refresh()</code></li> </ul> </li> <li> <p>L: 123 <code>createAndUploadPerformanceMetricsForAndroid()</code></p> </li> <li>L: 148 <code>getAndUploadPerformanceMetrics()</code></li> <li> <p>PerformanceMetrics.kt</p> <ul> <li>L: 16 <code>getAndUploadPerformanceMetrics()</code></li> <li>L: 27 <code>getPerformanceMetric()</code></li> <li>L: 45 <code>GcToolResults.getPerformanceMetric()</code></li> <li>L: 25 <code>performanceMetrics.upload()</code></li> <li>L: 47 <code>GcStorage.uploadPerformanceMetrics()</code></li> </ul> </li> <li> <p>L: 124 <code>GcStorage.uploadMatricesId()</code></p> </li> <li>GcStorage.kt<ul> <li>L: 96 <code>uploadMatricesId()</code></li> <li>L: 60 <code>upload()</code></li> </ul> </li> </ul> </li> </ul> </li> </ol>"},{"location":"gcloud/google_api_usecases/#ios-run-use-case","title":"iOS Run use case","text":"<ol> <li> <p>IosRunCommand.kt</p> <ul> <li>L: 76 <code>validate()</code></li> </ul> </li> <li> <p>ValidateIosArgs.kt</p> <ul> <li>L: 14 <code>IosArgs.validate()</code></li> <li>L: 16 <code>assertXcodeSupported()</code></li> <li>L: 79 <code>IosCatalog.supportedXcode()</code></li> <li> <p>IosCatalog.kt</p> <ul> <li>L: 44 <code>xcodeVersions()</code></li> <li>L: 47 <code>iosDeviceCatalog()</code></li> <li>L: 63: <code>GcTesting...iosDeviceCatalog()</code></li> </ul> </li> <li> <p>L: 17 <code>assertDevicesSupported(()</code></p> </li> <li>L: 84 <code>IosCatalog.supportedDevice()</code></li> <li>IosCatalog.kt<ul> <li>L: 53 <code>iosDeviceCatalog()</code></li> <li>L: 63 <code>GcTesting...iosDeviceCatalog()</code></li> </ul> </li> <li>L: 21 <code>checkResultsDirUnique()</code></li> <li>ValidateCommonArgs.kt<ul> <li>L: 75 <code>GcStorage.exist()</code></li> </ul> </li> </ul> </li> <li> <p>IosRunCommand.kt</p> <ul> <li>L: 78 <code>newTestRun()</code></li> </ul> </li> <li> <p>NewTestRun.kt</p> <ul> <li>L: 27 <code>runTests()</code></li> <li>L: 47 <code>runIosTests()</code></li> </ul> </li> <li> <p>RunIosTests.kt</p> <ul> <li>L: 41 <code>uploadOtherFiles()</code></li> <li>UploadOtherFiles.kt<ul> <li>L: 14 <code>GcStorage.upload()</code></li> </ul> </li> <li>L: 42 <code>uploadAdditionalIpas()</code></li> <li>UploadApks.kt<ul> <li>L: 54 <code>uploadToGcloudIfNeeded()</code></li> <li>L: 61 <code>uploadIfNeeded()</code></li> <li>FileReference.kt<ul> <li>L: 42 <code>GcStorage.upload()</code></li> </ul> </li> </ul> </li> <li>L: 49 <code>createIosTestContexts()</code></li> <li>CreateIosTestContext.kt<ul> <li>L: 9 <code>createXcTestContexts()</code></li> <li>CreateXcTestContext.kt<ul> <li>L: 17 <code>uploadIfNeeded()</code></li> <li>FileReference.kt<ul> <li>L: 32 <code>uploadIfNeeded()</code></li> <li>L: 42: <code>GcStorage.upload()</code></li> </ul> </li> <li>L: 28 <code>GcStorage.uploadXCTestFile()</code></li> <li>GcStorage.kt<ul> <li>L: 124 <code>upload()</code></li> </ul> </li> <li>L: 10 <code>createGameloopTestContexts()</code></li> <li>CreateGameloopTestContext.kt<ul> <li>L: 15 <code>uploadIfNeeded()</code></li> <li>FileReference.kt<ul> <li>L: 32 <code>uploadIfNeeded()</code></li> <li>L: 42 <code>GcStorage.upload()</code></li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li>L: 50 <code>GcIosTestMatrix.build()</code></li> <li>GcIosTestMatrix.kt<ul> <li>L: 66 <code>GcTesting...create()</code></li> </ul> </li> </ul> </li> <li> <p>NewTestRun.kt</p> <ul> <li>L: 35 <code>ReportManager.generate()</code></li> <li> <p>ReportManager.kt</p> <ul> <li>L: 103 <code>it.run()</code></li> <li>MatrixResultsReport.kt<ul> <li>L: 80 <code>GcStorage.uploadReportResult()</code></li> <li>GcStorage.kt<ul> <li>L: 115 <code>upload()</code></li> </ul> </li> </ul> </li> <li>CostReport.kt<ul> <li>L: 43 <code>GcStorage.uploadReportResult()</code></li> <li>GcStorage.kt<ul> <li>L: 115 <code>upload()</code></li> </ul> </li> </ul> </li> <li>L: 108 <code>it.run()</code></li> <li>HtmlErrorReport.kt<ul> <li>L: 35 <code>GcStorage.uploadReportResult()</code></li> <li>GcStorage.kt<ul> <li>L: 115 <code>upload()</code></li> </ul> </li> </ul> </li> <li>L: 121 <code>refreshMatricesAndGetExecutions()</code></li> <li> <p>ProcessFromApi.kt</p> <ul> <li>L: 13 <code>refreshMatricesAndGetExecutions()</code></li> <li>L: 18 <code>refreshTestMatrices()</code></li> <li>L: 24 <code>cTestMatrix.refresh()</code></li> </ul> </li> <li> <p>L: 123 <code>createAndUploadPerformanceMetricsForAndroid()</code></p> </li> <li>L: 148 <code>getAndUploadPerformanceMetrics()</code></li> <li> <p>PerformanceMetrics.kt</p> <ul> <li>L: 16 <code>getAndUploadPerformanceMetrics()</code></li> <li>L: 27 <code>getPerformanceMetric()</code></li> <li>L: 45 <code>GcToolResults.getPerformanceMetric()</code></li> <li>L: 25 <code>performanceMetrics.upload()</code></li> <li>L: 47 <code>GcStorage.uploadPerformanceMetrics()</code></li> </ul> </li> <li> <p>L: 124 <code>GcStorage.uploadMatricesId()</code></p> </li> <li>GcStorage.kt<ul> <li>L: 96 <code>uploadMatricesId()</code></li> <li>L: 60 <code>upload()</code></li> </ul> </li> </ul> </li> </ul> </li> </ol>"},{"location":"onboarding/1_environment_setup/","title":"Environment setup","text":"<p>This document may be incomplete now or in the future, so if you faced any problems ask the team for help.</p>"},{"location":"onboarding/1_environment_setup/#mac","title":"Mac","text":"<ol> <li>Install a brew, it's not mandatory but may be convenient for installing other software.</li> <li>Currently, the zsh is the default shell on a mac. If you prefer bash use <code>chsh -s /bin/bash</code>.</li> </ol>"},{"location":"onboarding/1_environment_setup/#env-config","title":"Env config","text":"<p>Bunch of useful exports. You can paste them to your <code>.bashrc</code> <pre><code>FLANK_REPO=\"type path to your local flank repository\"\nexport PATH=$PATH:$HOME/$FLANK_REPO/flank/test_runner/bash\nexport PATH=$PATH:$HOME/$FLANK_REPO/flank/test_projects/android/bash\nexport PATH=$PATH:$HOME/Library/Android/sdk/platform-tools\nexport PATH=$PATH:$HOME/Library/Python/2.7/bin\n#export PATH=$PATH:$HOME/\"path to your local gcloud repository\"/gcloud_cli/google-cloud-sdk/bin\nexport FLANK_PROJECT_ID=ftl-flank-open-source\nexport GOOGLE_CLOUD_PROJECT=ftl-flank-open-source\nexport GITHUB_TOKEN=\"type your github token here\"\n</code></pre></p>"},{"location":"onboarding/1_environment_setup/#common","title":"Common","text":"<ol> <li>Ask for access to internal slack channels</li> <li>Ask for an invitation to firebase slack</li> <li>Ask for access to GitHub repo</li> <li>Ask for access to test bucket on a google cloud platform</li> <li>Install Oracle JDK 8<ul> <li>Unfortunately there is no official way to download installer without a login account.</li> <li>Unfortunately unofficial instruction from wavezhang sometimes isn't working.</li> </ul> </li> <li>Use JetBrains Toolbox to install IDE.<ol> <li>Install JetBrains Toolbox<ul> <li>download from website</li> <li>or <code>brew cask install jetbrains-toolbox</code></li> </ul> </li> <li>Install IntelliJ idea (community may be enough)</li> <li>Install the Android studio.</li> </ol> </li> <li>Setup local flank repository<ol> <li>Clone the repo <code>git clone --recursive https://github.com/Flank/flank.git</code></li> <li>Init submodule <code>git submodule update --init --recursive updates the submodules</code></li> </ol> </li> <li>Build flank running ./update_flank.sh</li> <li>Auth google account<ol> <li>Run <code>flank auth login</code> [./flank].</li> <li>Click on the link and authenticate the account in a browser.</li> <li>Flank will save the credential to ~/.flank.</li> </ol> </li> <li>Install gcloud. Be aware gcloud requires a python environment.<ol> <li>You can clone https://github.com/Flank/gcloud_cli</li> <li>Or follow official instruction https://cloud.google.com/sdk/docs/quickstarts</li> <li>Don't forget about exports for Python and gcloud</li> </ol> </li> <li>Configure pre-commit hook for ktlint code autoformatting<ol> <li>Make sure you can execute <code>flank-scripts</code> from the command line if not navigate to in the command line to <code>./flank-scripts/bash</code></li> <li>Run <code>flankScripts linter apply_to_git_hooks</code></li> </ol> </li> <li>Apply Ktlint style to Idea project.<ol> <li>Make sure you can execute <code>flank-scripts</code> from the command line if not navigate to in the command line to <code>./flank-scripts/bash</code></li> <li>Run <code>flankScripts linter apply_to_ide</code></li> </ol> </li> </ol>"},{"location":"onboarding/2_contribution/","title":"Contribution process","text":"<p>This document describes contribution details for full-time contributors.</p>"},{"location":"onboarding/2_contribution/#daily-community-monitoring","title":"Daily community monitoring","text":"<ul> <li>Check if there are any new critical issues in reported issues.</li> <li>Check if there are any new issues on the flank slack channel. This is good practice to check out those points once a day by someone from the team.</li> </ul>"},{"location":"onboarding/2_contribution/#looking-for-a-new-task","title":"Looking for a new task","text":"<ol> <li>Perform daily monitoring if needed.</li> <li>Ask the team if someone needs help. We prefer teamwork over solo-work, our goal is quality so verification is important.</li> </ol>"},{"location":"onboarding/2_contribution/#estimating-tasks","title":"Estimating tasks","text":"<p>In the flank, we are using 3 points scale for estimates tasks complexity (snake, tiger, dragon). For more details see estimation.md</p>"},{"location":"onboarding/2_contribution/#working-on-a-new-task","title":"Working on a new task","text":"<p>Perform estimation if needed. If the task looks complex it's good practice asking a team for help. Typically, estimates should be already done on a weekly review, but issues reported after review may have a lack of estimation. According to task complexity choose the best strategy.</p>"},{"location":"onboarding/2_contribution/#snakes","title":"Snakes","text":"<p>Snake is easy and don't need any explanations. So if the task requires some implementation, everything that you need is a new branch, pull request with proper description and some tests. After you finished don't forget to mention someone from the team for help.</p>"},{"location":"onboarding/2_contribution/#tigers","title":"Tigers","text":"<p>If you are starting work on a tiger, always consider sharing some work with someone from the team, for more details see <code>Buddy system</code> section. Typically, every tiger brings some common things to do like: * Pull request with proper description which typically may contain the following information:     * description     * user story     * definition of done     * how to reproduce * Documentation. for more details see the <code>Documentation</code> section. * Unit tests * Dedicated YAML config with required assets for manual or integration testing</p>"},{"location":"onboarding/2_contribution/#dragons","title":"Dragons","text":"<p>Dragon requires research, so you should always start from writing some documentations draft. This draft should contain any important pieces of information about the task and should be synchronized with the status of knowledge according to any progression. The dragon task may be started by one developer but shouldn't be handle alone too long. The task could be a dragon as long as it's unknown and mysterious when there is a plan on how to deal with it, it's automatically become one or many tigers. So the main goal when deal with a dragon is to prepare documentation on how to solve the problem.</p>"},{"location":"onboarding/2_contribution/#documentation","title":"Documentation","text":"<p>Be aware, some tasks sometimes couldn't be resolved for many reasons, so it's really important to have documentation always up to date. Having documentation up to date gives the ability to drop work at any moment and back to in the future without loss of any information.</p>"},{"location":"onboarding/2_contribution/#buddy-system","title":"Buddy system","text":"<p>See buddy_system.md to read about team work in a flank.</p>"},{"location":"onboarding/2_contribution/#ktlint-styling-and-pre-commit-hooks","title":"Ktlint styling and pre-commit hooks","text":"<p>To ensure that the correct styling for Flank is upheld ensure that environment setup is read, and the correct <code>flankScripts</code> commands have been run so that Ktlint is applied to the idea project, and the pre-commit hook is working correctly.</p>"},{"location":"onboarding/3_estimation/","title":"Estimating Eng Work: Snakes, Tigers, Dragons","text":""},{"location":"onboarding/3_estimation/#introduction","title":"Introduction","text":"<p>This document describes a model for estimating the amount of work an engineering task requires.  It is not about estimating how long that work will take \u2014 that is a different discussion for a different time.  It is not about how to arrive at these estimates \u2014 that is also a different discussion for a different time. The primary aim of estimating size is to increase the velocity of those doing the work, i.e. engineering team.  These estimates might give some amount of signal to other stakeholders, e.g. product management or eng leadership, but that is not the goal.  Those stakeholders must be informed by different means. Because these estimates serve the needs of the team,  they need to be arrived at by the engineers who are going to be doing the work.  Any observer who wishes to adjust the team-arrived estimates needs to sign up for executing those tasks.</p>"},{"location":"onboarding/3_estimation/#snakes","title":"Snakes","text":"<p>A \u201csnake\u201d is a small task that can be executed without interrupting or requiring attention from any other member of the team.  Small wordsmithing updates to a design doc, or a runbook are good examples of a snake.  Creating a new diff to fix a bug that one noticed while working on something unrelated \u2014 not a snake \u2014 because a diff review will require attention from another team member.  Drive-by fixes inside a diff that\u2019s already going out for review can sometimes be a snake, depending on the complexity of the fix. The bottom line is, tasks that are sized as a \u201csnake\u201d do not need to be talked about, they just need to be done.  As a corollary, there is no task that is 2 snakes or 7 snakes. It\u2019s either a snake or one of the creatures below. The idea of a \u201csnake\u201d comes from US Army Ranger training.  They\u2019re told that if, when moving through an area, they see a snake that presents a danger, they should just kill the snake.  They should not yell \u201ccheck this out, SNAKE!\u201d  Jim Barksdale,  who created two industries,  making our jobs today possible, also used the analogy.  \u201cDo not have a meeting about a snake. Do not form a committee to discuss a snake. Do not send out a survey about a snake. Just kill it.\u201d</p>"},{"location":"onboarding/3_estimation/#tigers","title":"Tigers","text":"<p>One \u201ctiger\u201d is an amount of work that is well understood by the team.  It is a real creature with shared characteristics, so, once you have dispatched one, you have an idea of what it\u2019s like to dispatch another one.  The team has to agree on what constitutes one tiger and comparing tigers across teams is a counterproductive exercise. E.g. 1 Tiger is: fixing an NPE (or language-equivalent), writing a unit test to ensure that the fix actually fixed something,  reviewing that, landing the diff, following through to ensure it makes it to production. Tasks can be 1, 2, 3, 5, 8, or 13 tigers \u2014 nothing in between.  If a task is estimated to be bigger than 13 tigers, it needs to be broken up.</p>"},{"location":"onboarding/3_estimation/#dragons","title":"Dragons","text":"<p>A dragon is a mythical creature; each one is unlike any other encountered before.  Not enough is known at estimation time to meaningfully discuss the task and assign a number of tigers.  When a team identifies a dragon, the next step is to create a task that generates information required to turn that dragon into tiger-sized tasks  (often that de-dragonning task is best done as a time-boxed exercise, but that\u2019s a different discussion for a different time).</p> <p>posted on internal slack channel by @bootstraponline</p>"},{"location":"onboarding/4_buddy_system/","title":"Buddy system","text":""},{"location":"onboarding/4_buddy_system/#buddy-system","title":"Buddy System","text":"<p>Every task should have at least two people. Two people working on the task ensures the task gets to Done quickly.  There's no single point of failure. Cross training is another valuable aspect of the buddy system.  Code reviews will be faster as the buddy doesn't have to context switch to review the code.  Having a buddy working on a task provides emotional support and  psychological safety as there's two people responsible for completing the work.</p> <p>Work on one task at a time.</p> <p>Stop starting, start finishing. WIP limits encourage us to finish work that\u2019s already in process before introducing more work into the system.  The more work teams try to juggle at once, the harder it is for them to take work to the finish line.</p> <p>https://www.planview.com/resources/articles/wip-limits/</p> <p>Buddies are empowered to determine how to best collaborate on each task. Ideas: - One writes code, the other reviews. - One writes the business logic, the other writes tests - Pair programming. One writes code, the other observes and guides. Roles can be switched anytime.   - Visual Studio Code Live Share - One designs the APIs, the other implements</p> <p>We believe that people thrive on being trusted, on freedom, and on being able to make a difference. So we foster freedom and empowerment wherever we can.</p> <p>https://jobs.netflix.com/culture</p> <p>source https://github.com/platform-platform/monorepo/blob/master/docs/11_collaboration.md</p>"},{"location":"onboarding/5_code_review/","title":"Code review","text":""},{"location":"onboarding/5_code_review/#code-review","title":"Code review","text":"<p>Do your best and do not forget about some good practices,  formalized and described below. </p>"},{"location":"onboarding/5_code_review/#be-aware","title":"Be aware","text":"<ul> <li>Good code review requires a good understood of a problem.</li> <li>Code review is an important part of the development process and delivery. </li> </ul>"},{"location":"onboarding/5_code_review/#do-code-review-by-steps","title":"Do code review by steps","text":"<ol> <li>Read the issue related to the pull request.</li> <li>Read the description of the pull request.</li> <li>Make sure the description is clear for you. </li> <li>Make sure the description is sufficient for you.</li> <li>Read the committed changes </li> <li>Make sure you are ok with implementation.</li> <li>Make sure the result of what changed is clear for you.</li> <li>Make sure the pull request really solves the related issue in the desired way.</li> <li>Make sure the testing scenario is clear for you.</li> <li>Do the tests step by step and collect the output.</li> <li>Make sure the result of tests is equal to expected</li> <li>Attach report about test results under pull request.</li> </ol>"},{"location":"onboarding/5_code_review/#notify-about-fail","title":"Notify about fail","text":"<p>If any step above will fail for you, try to reproduce it for sure and notify about a faced problem using pull request comment. Additionally, you may attach any of: - GitHub <code>commitable</code> suggestion if possible, and you already know it. - Description of what is unclear for you. - Description of what should be changed or what is missing. - Any additional information important for final quality.</p>"},{"location":"onboarding/5_code_review/#some-tips","title":"Some tips","text":"<ul> <li>Make sure you clearly understand what you are reviewing.</li> <li>Don't be afraid of paying attention to details if feel they are important.</li> <li>It's always a good idea to open IDE, try to identify the root, and trace the implementation if the pull request is not trivial.</li> <li>Ask if you are not sure, suggest if you are sure.</li> </ul>"},{"location":"refactor/diagram/","title":"Flank Activity Diagram","text":""},{"location":"refactor/diagram/#description","title":"Description","text":"<p>The diagram shows abstract view of all possible flank activities.</p> <ul> <li>The <code>#LightGreen</code> color relates to CLI commands.</li> <li>The <code>#LightBlue</code> color relates to domain scope.</li> <li>The default yellow color reserved for top-level functions that are not atomic and can be converted to <code>frame</code>.</li> <li>Frame can represent a package or rather the top-level function composed of other functions.</li> <li>The <code>#snow</code> color relates to low-level functions</li> <li>Low-level functions should be atomic ( can import only non-domain utils and third-party libraries? - consider ).</li> <li>Low-level functions cannot be converted to frame</li> </ul> <p>The complete activity diagram will contain only low-level activities represented by <code>#snow</code> color. All top-level functions represented by yellow activities contains hidden complexity and should be converted to frames.  </p>"},{"location":"refactor/diagram/#layers","title":"Layers","text":"<pre><code>presentation (CLI) -&gt; domain -&gt; utils -&gt; data\n</code></pre>"},{"location":"refactor/important_cli_commands/","title":"Important cli commands","text":"<p>The list of Flank CLI commands that calls domain use cases</p> <ul> <li><code>auth/LoginCommand.kt</code></li> <li><code>firebase/CancelCommand.kt</code></li> <li><code>firebase/RefreshCommand.kt</code></li> <li><code>firebase/test/android/configuration/AndroidLocalesDescribeCommand.kt</code></li> <li><code>firebase/test/android/configuration/AndroidLocalesListCommand.kt</code></li> <li><code>firebase/test/android/models/AndroidModelDescribeCommand.kt</code></li> <li><code>firebase/test/android/models/AndroidModelsListCommand.kt</code></li> <li><code>firebase/test/android/orientations/AndroidOrientationsListCommand.kt</code></li> <li><code>firebase/test/android/versions/AndroidVersionsDescribeCommand.kt</code></li> <li><code>firebase/test/android/versions/AndroidVersionsListCommand.kt</code></li> <li><code>firebase/test/android/AndroidDoctorCommand.kt</code></li> <li><code>firebase/test/android/AndroidRunCommand.kt</code></li> <li><code>firebase/test/android/AndroidTestEnvironmentCommand.kt</code></li> <li><code>firebase/test/ios/configuration/IosLocalesDescribeCommand.kt</code></li> <li><code>firebase/test/ios/configuration/IosLocalesListCommand.kt</code></li> <li><code>firebase/test/ios/models/IosModelDescribeCommand.kt</code></li> <li><code>firebase/test/ios/models/IosModelsListCommand.kt</code></li> <li><code>firebase/test/ios/orientations/IosOrientationsListCommand.kt</code></li> <li><code>firebase/test/ios/versions/IosVersionsDescribeCommand.kt</code></li> <li><code>firebase/test/ios/versions/IosVersionsListCommand.kt</code></li> <li><code>firebase/test/ios/IosDoctorCommand.kt</code></li> <li><code>firebase/test/ios/IosRunCommand.kt</code></li> <li><code>firebase/test/ios/IosTestEnvironmentCommand.kt</code></li> <li><code>firebase/test/ipblocks/IPBlocksListCommand.kt</code></li> <li><code>firebase/test/networkprofiles/NetworkProfilesDescribeCommand.kt</code></li> <li><code>firebase/test/networkprofiles/NetworkProfilesListCommand.kt</code></li> <li><code>firebase/test/providedsoftware/ProvidedSoftwareListCommand.kt</code></li> </ul>"},{"location":"refactor/investigation/","title":"Flank investigation","text":"<p>This document contains investigation of flank architecture, layers and package structure.</p>"},{"location":"refactor/investigation/#motivation","title":"Motivation","text":"<p>Currently, the flank code is not well documented, and the only source of true is the implementation. The code base has grown over the last year, now it's almost impossible to keep in mind whole project. So to make further work more doable and convenient, it's necessary to identify hidden constraints in code, expose them in documentation and do refactor. This document is and entity point for further improvements.</p>"},{"location":"refactor/investigation/#layers","title":"Layers","text":""},{"location":"refactor/investigation/#presentation","title":"Presentation","text":""},{"location":"refactor/investigation/#issues","title":"Issues","text":"<ol> <li><code>ftl.Main</code> command shouldn't be bound with <code>main</code> function through companion object due to single responsibility principle.</li> <li>Some commands that can run domain code are doing too much.</li> <li>Some of composing commands seem to be in wrong package.</li> </ol>"},{"location":"refactor/investigation/#cli-commands","title":"CLI commands","text":"<p>Flank commands tree.</p> <pre><code>ftl/cli/\n\u251c\u2500\u2500 AuthCommand.kt /\n\u251c\u2500\u2500 FirebaseCommand.kt /\n\u251c\u2500\u2500 auth\n\u2502   \u2514\u2500\u2500 LoginCommand.kt ? !\n\u2514\u2500\u2500 firebase\n    \u251c\u2500\u2500 CancelCommand.kt ? !\n    \u251c\u2500\u2500 RefreshCommand.kt ? !\n    \u251c\u2500\u2500 TestCommand.kt /\n    \u2514\u2500\u2500 test\n        \u251c\u2500\u2500 AndroidCommand.kt /\n        \u251c\u2500\u2500 CommandUtil.kt\n        \u251c\u2500\u2500 CommonRunCommand.kt\n        \u251c\u2500\u2500 IPBlocksCommand.kt /\n        \u251c\u2500\u2500 IosCommand.kt /\n        \u251c\u2500\u2500 NetworkProfilesCommand.kt /\n        \u251c\u2500\u2500 ProvidedSoftwareCommand.kt /\n        \u251c\u2500\u2500 android\n        \u2502   \u251c\u2500\u2500 AndroidDoctorCommand.kt ? !\n        \u2502   \u251c\u2500\u2500 AndroidRunCommand.kt ? !\n        \u2502   \u251c\u2500\u2500 AndroidTestEnvironmentCommand.kt ? !\n        \u2502   \u251c\u2500\u2500 configuration\n        \u2502   \u2502   \u251c\u2500\u2500 AndroidLocalesCommand.kt / ^\n        \u2502   \u2502   \u251c\u2500\u2500 AndroidLocalesDescribeCommand.kt ? !\n        \u2502   \u2502   \u2514\u2500\u2500 AndroidLocalesListCommand.kt ? !\n        \u2502   \u251c\u2500\u2500 models\n        \u2502   \u2502   \u251c\u2500\u2500 AndroidModelDescribeCommand.kt ? !\n        \u2502   \u2502   \u251c\u2500\u2500 AndroidModelsCommand.kt / ^\n        \u2502   \u2502   \u2514\u2500\u2500 AndroidModelsListCommand.kt ? !\n        \u2502   \u251c\u2500\u2500 orientations\n        \u2502   \u2502   \u251c\u2500\u2500 AndroidOrientationsCommand.kt / ^\n        \u2502   \u2502   \u2514\u2500\u2500 AndroidOrientationsListCommand.kt ? !\n        \u2502   \u2514\u2500\u2500 versions\n        \u2502       \u251c\u2500\u2500 AndroidVersionsCommand.kt / ^\n        \u2502       \u251c\u2500\u2500 AndroidVersionsDescribeCommand.kt ? !\n        \u2502       \u2514\u2500\u2500 AndroidVersionsListCommand.kt ? !\n        \u251c\u2500\u2500 ios\n        \u2502   \u251c\u2500\u2500 IosDoctorCommand.kt ? !\n        \u2502   \u251c\u2500\u2500 IosRunCommand.kt ? !\n        \u2502   \u251c\u2500\u2500 IosTestEnvironmentCommand.kt ? !\n        \u2502   \u251c\u2500\u2500 configuration\n        \u2502   \u2502   \u251c\u2500\u2500 IosLocalesCommand.kt / ^\n        \u2502   \u2502   \u251c\u2500\u2500 IosLocalesDescribeCommand.kt ? !\n        \u2502   \u2502   \u2514\u2500\u2500 IosLocalesListCommand.kt ? !\n        \u2502   \u251c\u2500\u2500 models\n        \u2502   \u2502   \u251c\u2500\u2500 IosModelDescribeCommand.kt ? !\n        \u2502   \u2502   \u251c\u2500\u2500 IosModelsCommand.kt / ^\n        \u2502   \u2502   \u2514\u2500\u2500 IosModelsListCommand.kt ? !\n        \u2502   \u251c\u2500\u2500 orientations\n        \u2502   \u2502   \u251c\u2500\u2500 IosOrientationsCommand.kt / ^\n        \u2502   \u2502   \u2514\u2500\u2500 IosOrientationsListCommand.kt ? !\n        \u2502   \u2514\u2500\u2500 versions\n        \u2502       \u251c\u2500\u2500 IosVersionsCommand.kt / ^\n        \u2502       \u251c\u2500\u2500 IosVersionsDescribeCommand.kt ? !\n        \u2502       \u2514\u2500\u2500 IosVersionsListCommand.kt ? !\n        \u251c\u2500\u2500 ipblocks\n        \u2502   \u2514\u2500\u2500 IPBlocksListCommand.kt ?\n        \u251c\u2500\u2500 networkprofiles\n        \u2502   \u251c\u2500\u2500 NetworkProfilesDescribeCommand.kt ?\n        \u2502   \u2514\u2500\u2500 NetworkProfilesListCommand.kt ?\n        \u2514\u2500\u2500 providedsoftware\n            \u2514\u2500\u2500 ProvidedSoftwareListCommand.kt ?\n</code></pre> <p>command that:</p> <ul> <li><code>?</code> is running domain code</li> <li><code>/</code> routes to subcommands</li> <li><code>!</code> is doing too much in run function</li> <li><code>^</code> should be moved up in package hierarchy</li> </ul>"},{"location":"refactor/investigation/#domain","title":"Domain","text":""},{"location":"refactor/investigation/#issues_1","title":"Issues","text":"<ol> <li>The core domain api is not easy to identify.</li> <li>The domain layer of flank is not clearly separated of CLI and external APIs.</li> <li>Domain logic is huge and complicated but there is lack of diagram for visualize it.</li> </ol>"},{"location":"refactor/investigation/#data-adapters","title":"Data &amp; Adapters","text":""},{"location":"refactor/investigation/#issues_2","title":"Issues","text":"<ul> <li>External APIs are not hidden behind interfaces</li> <li>External API wrappers / adapters are not clearly separated from other layers.</li> </ul>"},{"location":"refactor/investigation/#external-api-libs","title":"External API libs","text":"<ul> <li><code>com.google.testing:firebase_apis:test_api</code></li> <li><code>com.google.api-client:google-api-client</code></li> <li><code>com.google.auth:google-auth-library-oauth2-http</code></li> <li><code>com.google.cloud:google-cloud-nio</code></li> <li><code>com.google.cloud:google-cloud-storage</code></li> <li><code>com.google.apis:google-api-services-toolresults</code></li> </ul>"},{"location":"refactor/investigation/#list-of-external-api-usages-in-files","title":"List of external API usages in files","text":"<p>Based on google_api_usecases</p> <ol> <li>com.google.api.client.http<ul> <li>GoogleApiLogger.kt</li> </ul> </li> <li>ftl.android<ul> <li>AndroidCatalog.kt</li> </ul> </li> <li>ftl.args<ul> <li>ArgsHelper.kt</li> </ul> </li> <li>ftl.config<ul> <li>Credentials.kt</li> <li>FtlConstants.kt</li> </ul> </li> <li>ftl.environment<ul> <li>ListIPBlocks.kt $</li> <li>ListLocales.kt $</li> <li>LocalesDescription.kt $</li> <li>NetworkProfileDescription.kt $</li> </ul> </li> <li>ftl.environment.android<ul> <li>AndroidModelDescription.kt $</li> <li>AndroidSoftwareVersionDescription.kt $</li> <li>ListAndroidDevices.kt $</li> <li>ListAndroidSoftwareVersions.kt $</li> </ul> </li> <li>ftl.environment.common<ul> <li>ListNetworkConfiguration.kt $</li> <li>ListOrientations.kt $</li> <li>ListProvidedSoftware.kt $</li> </ul> </li> <li>ftl.environment.ios<ul> <li>IosModelDescription.kt $</li> <li>IosSoftwareVersionDescription.kt $</li> <li>ListIOsDevices.kt $</li> <li>ListIOsSoftwareVersions.kt $</li> </ul> </li> <li>ftl.gc<ul> <li>GcAndroidDevice.kt $</li> <li>GcAndroidTestMatrix.kt</li> <li>GcIosMatrix.kt $</li> <li>GcIosTestMatrix.kt</li> <li>GcStorage.kt</li> <li>GcTesting.kt $</li> <li>GcTestMatrix.kt</li> <li>GcToolResults.kt</li> <li>UserAuth.kt</li> <li>ftl/gc/Utils.kt $</li> </ul> </li> <li>ftl.gc.android<ul> <li>CreateAndroidInstrumentationTest.kt $</li> <li>CreateAndroidLoopTest.kt $</li> <li>CreateAndroidRobotTest.kt $</li> <li>SetupAndroidTest.kt $</li> <li>SetupEnvironmentVariables.kt $</li> <li>ftl/gc/android/Utils.kt $</li> </ul> </li> <li>ftl.gc.ios<ul> <li>SetupIosTest.kt $</li> </ul> </li> <li>ftl.http<ul> <li>ExecuteWithRetry.kt</li> <li>HttpTimeoutIncrease.kt</li> </ul> </li> <li>ftl.ios<ul> <li>IosCatalog.kt $</li> </ul> </li> <li>ftl.json<ul> <li>MatrixMap.kt $</li> <li>OutcomeDetailsFormatter.kt $</li> <li>SavedMatrix.kt $</li> </ul> </li> <li>ftl.log<ul> <li>Loggers.kt</li> </ul> </li> <li>ftl.mock<ul> <li>MockServer.kt</li> </ul> </li> <li>ftl.reports<ul> <li>HtmlErrorReport.kt</li> </ul> </li> <li>ftl.reports.api<ul> <li>CreateJUnitTestCase.kt $</li> <li>CreateJUnitTestResult.kt $</li> <li>CreateTestExecutionData.kt</li> <li>CreateTestSuiteOverviewData.kt $</li> <li>PerformanceMetrics.kt</li> <li>PrepareForJUnitResult.kt</li> <li>ProcessFromApi.kt $</li> <li>ftl/reports/api/Utils.kt</li> </ul> </li> <li>ftl.reports.api.data<ul> <li>TestExecutionData.kt $</li> <li>TestSuiteOverviewData.kt $</li> </ul> </li> <li>ftl.reports.outcome<ul> <li>BillableMinutes.kt $</li> <li>CreateMatrixOutcomeSummary.kt $</li> <li>CreateTestSuiteOverviewData.kt $</li> <li>TestOutcome.kt $</li> <li>TestOutcomeContext.kt $</li> <li>ftl/reports/outcome/Util.kt $</li> </ul> </li> <li>ftl.reports.util<ul> <li>ReportManager.kt $</li> </ul> </li> <li>ftl.run<ul> <li>RefreshLastRun.kt $</li> </ul> </li> <li>ftl.run.common<ul> <li>FetchArtifacts.kt</li> <li>PollMatrices.kt</li> </ul> </li> <li>ftl.run.platform<ul> <li>RunAndroidTests.kt $</li> </ul> </li> <li>ftl.run.platform.common<ul> <li>AfterRunTests.kt $</li> </ul> </li> <li>ftl.run.status<ul> <li>ExecutionStatusListPrinter.kt $</li> <li>TestMatrixStatusPrinter.kt $</li> </ul> </li> <li>ftl.util<ul> <li>MatrixState.kt $</li> <li>TestMatrixExtension.kt $</li> </ul> </li> </ol> <p>where</p> <ul> <li><code>$</code> - only operates on API structures, not call methods directly</li> </ul>"},{"location":"refactor/investigation/#google-api-use-cases","title":"Google API use cases","text":"<p>From the CLI command point of view. The most nested points refer API calls.</p> <ul> <li> <p><code>auth/LoginCommand.kt</code></p> <ul> <li>Authorizing google account using OAuth2 for getting credentials.</li> </ul> </li> <li> <p><code>firebase/CancelCommand.kt</code></p> <ul> <li>Sending cancel request using projectId and testMatrixId</li> </ul> </li> <li> <p><code>firebase/RefreshCommand.kt</code> ?</p> <ul> <li>Getting current test matrices' status for updating matrix file if needed</li> <li>Polling the matrices' status for live logging until all matrices are not finished.</li> <li>Downloading test artifacts from bucket</li> </ul> </li> <li> <p><code>firebase/test/providedsoftware/ProvidedSoftwareListCommand.kt</code></p> <ul> <li>Getting softwareCatalog from testEnvironmentCatalog</li> </ul> </li> <li> <p><code>firebase/test/ipblocks/IPBlocksListCommand.kt</code></p> <ul> <li>Getting orchestratorVersion from testEnvironmentCatalog</li> </ul> </li> <li> <p><code>firebase/test/networkprofiles/NetworkProfilesDescribeCommand.kt</code></p> <ul> <li>Getting configurations from testEnvironmentCatalog through networkConfigurationCatalog</li> </ul> </li> <li> <p><code>firebase/test/networkprofiles/NetworkProfilesListCommand.kt</code></p> <ul> <li>Getting configurations from testEnvironmentCatalog through networkConfigurationCatalog</li> </ul> </li> <li> <p><code>firebase/test/android/configuration/AndroidLocalesDescribeCommand.kt</code></p> <ul> <li>Getting android device catalog for obtain locales</li> </ul> </li> <li> <p><code>firebase/test/android/configuration/AndroidLocalesListCommand.kt</code></p> <ul> <li>Getting android device catalog for obtain locales</li> </ul> </li> <li> <p><code>firebase/test/android/models/AndroidModelDescribeCommand.kt</code></p> <ul> <li>Getting android device catalog for obtain models</li> </ul> </li> <li> <p><code>firebase/test/android/models/AndroidModelsListCommand.kt</code></p> <ul> <li>Getting android device catalog for obtain models</li> </ul> </li> <li> <p><code>firebase/test/android/orientations/AndroidOrientationsListCommand.kt</code></p> <ul> <li>Getting android device catalog for obtain orientations</li> </ul> </li> <li> <p><code>firebase/test/android/versions/AndroidVersionsDescribeCommand.kt</code></p> <ul> <li>Getting android device catalog for obtain versions</li> </ul> </li> <li> <p><code>firebase/test/android/versions/AndroidVersionsListCommand.kt</code></p> <ul> <li>Getting android device catalog for obtain versions</li> </ul> </li> <li> <p><code>firebase/test/android/AndroidTestEnvironmentCommand.kt</code></p> <ul> <li><code>AndroidModelsListCommand</code></li> <li><code>AndroidVersionsListCommand</code></li> <li><code>AndroidLocalesListCommand</code></li> <li><code>ProvidedSoftwareListCommand</code></li> <li><code>NetworkProfilesListCommand</code></li> <li><code>AndroidOrientationsListCommand</code></li> <li><code>IPBlocksListCommand</code></li> </ul> </li> <li> <p><code>firebase/test/ios/configuration/IosLocalesDescribeCommand.kt</code></p> <ul> <li>Getting ios device catalog for obtain locales</li> </ul> </li> <li> <p><code>firebase/test/ios/configuration/IosLocalesListCommand.kt</code></p> <ul> <li>Getting ios device catalog for obtain locales</li> </ul> </li> <li> <p><code>firebase/test/ios/models/IosModelDescribeCommand.kt</code></p> <ul> <li>Getting ios device catalog for obtain models</li> </ul> </li> <li> <p><code>firebase/test/ios/models/IosModelsListCommand.kt</code></p> <ul> <li>Getting ios device catalog for obtain models</li> </ul> </li> <li> <p><code>firebase/test/ios/orientations/IosOrientationsListCommand.kt</code></p> <ul> <li>Getting ios device catalog for obtain orientations</li> </ul> </li> <li> <p><code>firebase/test/ios/versions/IosVersionsDescribeCommand.kt</code></p> <ul> <li>Getting ios device catalog for obtain versions</li> </ul> </li> <li> <p><code>firebase/test/ios/versions/IosVersionsListCommand.kt</code></p> <ul> <li>Getting ios device catalog for obtain versions</li> </ul> </li> <li> <p><code>firebase/test/ios/IosTestEnvironmentCommand.kt</code></p> <ul> <li><code>IosModelsListCommand</code></li> <li><code>IosVersionsListCommand</code></li> <li><code>IosLocalesListCommand</code></li> <li><code>ProvidedSoftwareListCommand</code></li> <li><code>NetworkProfilesListCommand</code></li> <li><code>IosOrientationsListCommand</code></li> <li><code>IPBlocksListCommand</code></li> </ul> </li> <li> <p><code>firebase/test/android/AndroidRunCommand.kt</code></p> <ul> <li>Validation<ul> <li>Checking if bucket exist (common args validation)</li> <li>Getting android device catalog for check supported devices</li> </ul> </li> <li>Running android tests<ul> <li>Preparing data</li> <li>Uploading files</li> <li>Creating android test contexts<ul> <li>downloading apks if needed</li> </ul> </li> <li>Dumping shards<ul> <li>Uploading dumped shards if needed</li> </ul> </li> <li>Uploading<ul> <li>Uploading apks if needed &amp; depending on test context</li> </ul> </li> <li>Building and running android test matrix</li> <li>After run test<ul> <li>Uploading session ID</li> <li>Printing matrices web links<ul> <li>getOrUpdateWebLink<ul> <li>Getting test matrices</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li>Pooling matrices<ul> <li>Getting test matrices</li> </ul> </li> <li>Generating report<ul> <li>Parsing test suite<ul> <li>Getting test matrices</li> <li>Creating JUnit test result</li> </ul> </li> <li>Uploading each report<ul> <li>Cost report</li> <li>Matrix results report</li> <li>Html error report</li> <li>JUnit report</li> </ul> </li> <li>Getting test matrices for test executions</li> <li>Processing junit results<ul> <li>processing full junit result<ul> <li>Creating JUnit test result</li> </ul> </li> </ul> </li> <li>Create and upload performance metrics</li> <li>Upload matrices ids</li> </ul> </li> <li>Fetching artifacts</li> <li>Printing matrices web links<ul> <li>get or update web for each matrix<ul> <li>Getting test matrices</li> </ul> </li> </ul> </li> </ul> </li> <li> <p><code>firebase/test/ios/IosRunCommand.kt</code></p> <ul> <li>validation<ul> <li>Checking if bucket exist (common args validation)</li> <li>Getting ios device catalog for check supported devices</li> </ul> </li> <li>Running ios tests<ul> <li>Preparing data</li> <li>Uploading files</li> <li>Dump shards if needed<ul> <li>Uploading dumped shards if needed</li> </ul> </li> <li>Creating ios test contexts<ul> <li>Creating xctest context<ul> <li>Uploading xctest files</li> </ul> </li> <li>Creating gameloop test context<ul> <li>Uploading app file</li> </ul> </li> </ul> </li> <li>Building and running android test matrix</li> <li>After run test (from this point the path is same as for android)</li> </ul> </li> </ul> </li> </ul> <p>where</p> <ul> <li><code>?</code> - investigate if implementation is correct or is performing some not necessary operations.</li> </ul>"},{"location":"refactor/investigation/#google-api-usage-function-call-tree","title":"Google API usage function call tree","text":"<ul> <li><code>LoginCommand</code> -&gt; <code>UserAuth/request</code></li> <li><code>CancelCommand</code><ul> <li><code>getLastArgs</code><ul> <li><code>IosArgs/validateRefresh</code> -&gt; <code>IosArgs/assertDevicesSupported</code></li> <li><code>AndroidArgs/validate</code><ul> <li><code>AndroidArgs/assertDevicesSupported</code><ul> <li><code>AndroidCatalog/supportedDeviceConfig</code> -&gt; <code>AndroidCatalog/deviceCatalog(projectId).models</code></li> <li><code>AndroidCatalog/androidModelIds</code> -&gt; <code>AndroidCatalog/deviceCatalog(projectId).models</code></li> <li><code>AndroidCatalog/androidVersionIds</code> -&gt; <code>AndroidCatalog/deviceCatalog(projectId).versions</code></li> <li><code>AndroidCatalog/getSupportedVersionId</code> -&gt; <code>AndroidCatalog/deviceCatalog(projectId).models</code></li> </ul> </li> <li><code>IArgs/checkResultsDirUnique</code> -&gt; <code>GcStorage/exist</code></li> </ul> </li> </ul> </li> <li><code>cancelLastRun</code> -&gt; <code>cancelMatrices</code> -&gt; <code>GcTestMatrix/cancel</code></li> </ul> </li> <li><code>RefreshCommand</code> -&gt; <code>refreshLastRun</code><ul> <li><code>getLastArgs</code><ul> <li><code>IosArgs/validateRefresh</code> -&gt; <code>IosArgs/assertDevicesSupported</code></li> <li><code>AndroidArgs/validate</code><ul> <li><code>AndroidArgs/assertDevicesSupported</code><ul> <li><code>AndroidCatalog/supportedDeviceConfig</code> -&gt; <code>AndroidCatalog/deviceCatalog(projectId).models</code></li> <li><code>AndroidCatalog/androidModelIds</code> -&gt; <code>AndroidCatalog/deviceCatalog(projectId).models</code></li> <li><code>AndroidCatalog/androidVersionIds</code> -&gt; <code>AndroidCatalog/deviceCatalog(projectId).versions</code></li> <li><code>AndroidCatalog/getSupportedVersionId</code> -&gt; <code>AndroidCatalog/deviceCatalog(projectId).models</code></li> </ul> </li> <li><code>IArgs/checkResultsDirUnique</code> -&gt; <code>GcStorage/exist</code></li> </ul> </li> </ul> </li> <li><code>refreshMatrices</code><ul> <li><code>GcTestMatrix/refresh</code></li> <li><code>SavedMatrix/updateWithMatrix</code> -&gt; <code>SavedMatrix/updatedSavedMatrix</code> -&gt; <code>TestMatrix/fetchTestOutcomeContext</code><ul> <li><code>TestMatrix/getToolResultsIds</code></li> <li><code>GcToolResults/listAllEnvironments</code></li> <li><code>GcToolResults/listAllSteps</code></li> </ul> </li> </ul> </li> </ul> </li> <li><code>ProvidedSoftwareListCommand</code> -&gt; <code>providedSoftwareAsTable</code> -&gt; <code>getProvidedSoftware</code></li> <li><code>IPBlocksListCommand</code> -&gt; <code>ipBlocksListAsTable</code> -&gt; <code>deviceIPBlocks</code></li> <li><code>NetworkProfilesDescribeCommand</code> -&gt; <code>networkProfileDescription</code> -&gt; <code>getNetworkConfiguration</code></li> <li> <p><code>NetworkProfilesListCommand</code> -&gt; <code>networkConfigurationAsTable</code> -&gt; <code>getNetworkConfiguration</code></p> </li> <li> <p><code>AndroidLocalesDescribeCommand</code> -&gt; <code>AndroidCatalog/getLocaleDescription</code> -&gt; <code>AndroidCatalog/getLocales</code></p> </li> <li><code>AndroidLocalesListCommand</code> -&gt; <code>AndroidCatalog/localesAsTable</code> -&gt; <code>AndroidCatalog/getLocales</code></li> <li><code>AndroidModelDescribeCommand</code> -&gt; <code>AndroidCatalog/describeModel</code> -&gt; <code>AndroidCatalog/getModels</code></li> <li><code>AndroidModelsListCommand</code> -&gt; <code>AndroidCatalog/devicesCatalogAsTable</code> -&gt; <code>AndroidCatalog/getModels</code></li> <li><code>AndroidOrientationsListCommand</code> -&gt; <code>AndroidCatalog/supportedOrientationsAsTable</code> -&gt; <code>AndroidCatalog/deviceCatalog</code></li> <li><code>AndroidVersionsDescribeCommand</code> -&gt; <code>AndroidCatalog/describeSoftwareVersion</code> -&gt; <code>AndroidCatalog/getVersionsList</code></li> <li><code>AndroidVersionsListCommand</code> -&gt; <code>AndroidCatalog/supportedVersionsAsTable</code> -&gt; <code>AndroidCatalog/getVersionsList</code></li> <li> <p><code>AndroidTestEnvironmentCommand</code></p> <ul> <li><code>AndroidModelsListCommand</code></li> <li><code>AndroidVersionsListCommand</code></li> <li><code>AndroidLocalesListCommand</code></li> <li><code>ProvidedSoftwareListCommand</code></li> <li><code>NetworkProfilesListCommand</code></li> <li><code>AndroidOrientationsListCommand</code></li> <li><code>IPBlocksListCommand</code></li> </ul> </li> <li> <p><code>IosLocalesDescribeCommand</code> -&gt; <code>IosCatalog/getLocaleDescription</code> -&gt; <code>IosCatalog/getLocales</code></p> </li> <li><code>IosLocalesListCommand</code> -&gt; <code>IosCatalog/localesAsTable</code> -&gt; <code>IosCatalog/iosDeviceCatalog</code></li> <li><code>IosModelDescribeCommand</code> -&gt; <code>IosCatalog/describeModel</code> -&gt; <code>IosCatalog/getModels</code></li> <li><code>IosModelsListCommand</code> -&gt; <code>IosCatalog/devicesCatalogAsTable</code> -&gt; <code>IosCatalog/getModels</code></li> <li><code>IosOrientationsListCommand</code> -&gt; <code>IosCatalog/supportedOrientationsAsTable</code> -&gt; <code>IosCatalog/iosDeviceCatalog</code></li> <li><code>IosVersionsDescribeCommand</code> -&gt; <code>IosCatalog/describeSoftwareVersion</code> -&gt; <code>IosCatalog/getVersionsList</code></li> <li><code>IosVersionsListCommand</code> -&gt; <code>IosCatalog/softwareVersionsAsTable</code> -&gt; <code>IosCatalog/getVersionsList</code></li> <li> <p><code>IosTestEnvironmentCommand</code></p> <ul> <li><code>IosModelsListCommand</code></li> <li><code>IosVersionsListCommand</code></li> <li><code>IosLocalesListCommand</code></li> <li><code>ProvidedSoftwareListCommand</code></li> <li><code>NetworkProfilesListCommand</code></li> <li><code>IosOrientationsListCommand</code></li> <li><code>IPBlocksListCommand</code></li> </ul> </li> <li> <p><code>AndroidRunCommand</code></p> <ul> <li><code>AndroidArgs/validate</code><ul> <li><code>AndroidArgs/assertDevicesSupported</code><ul> <li><code>AndroidCatalog/supportedDeviceConfig</code></li> <li><code>AndroidCatalog/androidModelIds</code></li> <li><code>AndroidCatalog/androidVersionIds</code></li> <li><code>AndroidCatalog/getSupportedVersionId</code></li> </ul> </li> <li><code>IArgs/checkResultsDirUnique</code> -&gt; <code>GcStorage/exist</code></li> </ul> </li> <li><code>AndroidArgs/runAndroidTests</code><ul> <li><code>GcAndroidDevice/build</code></li> <li><code>GcToolResults/createToolResultsHistory</code></li> <li><code>IArgs/uploadOtherFiles</code> -&gt; <code>GcStorage/upload</code></li> <li><code>AndroidArgs/uploadAdditionalApks</code> -&gt; <code>List&lt;String&gt;/uploadToGcloudIfNeeded</code> -&gt; <code>FileReference/uploadIfNeeded</code>-&gt; <code>GcStorage/upload</code></li> <li><code>AndroidArgs/uploadObbFiles</code> -&gt; <code>GcStorage/upload</code></li> <li><code>AndroidArgs/createAndroidTestContexts</code> -&gt; <code>List&lt;AndroidTestContext&gt;/setupShards</code>-&gt; <code>InstrumentationTestContext/downloadApks</code> -&gt; <code>FileReference/downloadIfNeeded</code> -&gt; <code>GcStorage/download</code></li> <li><code>List&lt;AndroidTestContext&gt;/dumpShards</code> -&gt; <code>GcStorage/upload</code></li> <li><code>List&lt;AndroidTestContext&gt;/upload</code> -&gt; <code>AndroidTestContext/upload</code><ul> <li><code>InstrumentationTestContext/upload</code> -&gt; <code>FileReference/uploadIfNeeded</code> -&gt; <code>GcStorage/upload</code></li> <li><code>RoboTestContext/upload</code> -&gt; <code>FileReference/uploadIfNeeded</code> -&gt; <code>GcStorage/upload</code></li> <li><code>SanityRoboTestContext/upload</code> -&gt; <code>FileReference/uploadIfNeeded</code> -&gt; <code>GcStorage/upload</code></li> <li><code>GameLoopContext/upload</code> -&gt; <code>FileReference/uploadIfNeeded</code> -&gt; <code>GcStorage/upload</code></li> </ul> </li> <li><code>GcAndroidTestMatrix/build</code></li> <li><code>AbstractGoogleJsonClientRequest&lt;T&gt;/executeWithRetry</code></li> <li><code>IArgs/afterRunTests</code><ul> <li><code>MatrixMap/printMatricesWebLinks</code> -&gt; <code>getOrUpdateWebLink</code> -&gt; <code>GcTestMatrix/refresh</code></li> </ul> </li> </ul> </li> <li><code>pollMatrices</code> -&gt; <code>matrixChangesFlow</code> -&gt; <code>GcTestMatrix/refresh</code></li> <li><code>Iterable&lt;TestMatrix&gt;/updateMatrixMap</code> -&gt; <code>SavedMatrix/updateWithMatrix</code> -&gt; <code>TestMatrix/fetchTestOutcomeContext</code><ul> <li><code>TestMatrix/getToolResultsIds</code></li> <li><code>GcToolResults/listAllEnvironments</code></li> <li><code>GcToolResults/listAllSteps</code></li> </ul> </li> <li><code>ReportManager/generate</code><ul> <li><code>ReportManager/parseTestSuite</code><ul> <li><code>refreshMatricesAndGetExecutions</code> -&gt; <code>refreshTestMatrices</code> -&gt; <code>GcTestMatrix/refresh</code></li> <li><code>List&lt;TestExecution&gt;/createJUnitTestResult</code> -&gt; <code>List&lt;TestExecution&gt;/createTestExecutionDataListAsync</code>-&gt; <code>TestExecution/createTestExecutionData</code> -&gt; <code>getAsync</code><ul> <li><code>GcToolResults/listTestCases</code></li> <li><code>GcToolResults/getStepResult</code></li> </ul> </li> </ul> </li> <li><code>CostReport.run</code> -&gt; <code>GcStorage/uploadReportResult</code></li> <li><code>MatrixResultsReport.run</code> -&gt; <code>GcStorage/uploadReportResult</code></li> <li><code>HtmlErrorReport.run</code> -&gt; <code>GcStorage/uploadReportResult</code></li> <li><code>JUnitReport.run</code> -&gt; <code>GcStorage/uploadReportResult</code></li> <li><code>refreshMatricesAndGetExecutions</code> -&gt; <code>refreshTestMatrices</code> -&gt; <code>GcTestMatrix/refresh</code></li> <li><code>ReportManager/processJunitResults</code><ul> <li><code>ReportManager/processFullJunitResult</code> -&gt; <code>List&lt;TestExecution&gt;/createJUnitTestResult</code> -&gt; <code>List&lt;TestExecution&gt;/createTestExecutionDataListAsync</code>-&gt; <code>TestExecution/createTestExecutionData</code> -&gt; <code>getAsync</code><ul> <li><code>GcToolResults/listTestCases</code></li> <li><code>GcToolResults/getStepResult</code></li> </ul> </li> <li><code>FullJUnitReport.run</code> -&gt; <code>GcStorage.uploadReportResult</code></li> </ul> </li> <li><code>ReportManager/createAndUploadPerformanceMetricsForAndroid</code> -&gt; <code>List&lt;Pair&lt;TestExecution, String&gt;&gt;.getAndUploadPerformanceMetrics</code> -&gt;<ul> <li><code>TestExecution.getPerformanceMetric</code> -&gt; <code>GcToolResults.getPerformanceMetric</code></li> <li><code>PerfMetricsSummary.upload</code> -&gt; <code>GcStorage.uploadPerformanceMetrics</code></li> </ul> </li> <li><code>GcStorage/uploadMatricesId</code></li> </ul> </li> <li><code>fetchArtifacts</code><ul> <li><code>Storage.BlobListOption.fields</code></li> <li><code>Storage.BlobListOption.prefix</code></li> <li><code>GcStorage.storage.list</code></li> <li><code>Blob.downloadTo</code></li> </ul> </li> <li><code>MatrixMap/printMatricesWebLinks</code> -&gt; <code>getOrUpdateWebLink</code> -&gt; <code>GcTestMatrix/refresh</code></li> </ul> </li> <li> <p><code>IosRunCommand</code></p> <ul> <li><code>IosArgs/validate</code><ul> <li><code>IosArgs/assertDevicesSupported</code><ul> <li><code>IosCatalog/supportedDevice</code></li> <li><code>IosCatalog/Device/getSupportedVersionId</code></li> </ul> </li> <li><code>IArgs/checkResultsDirUnique</code> -&gt; <code>GcStorage/exist</code></li> </ul> </li> <li><code>IosArgs/runIosTests</code><ul> <li><code>GcIosMatrix/build</code></li> <li><code>GcToolResults/createToolResultsHistory</code></li> <li><code>IArgs/uploadOtherFiles</code> -&gt; <code>GcStorage/upload</code></li> <li><code>IosArgs.uploadAdditionalIpas</code></li> <li><code>IosArgs.dumpShardsIfXcTest</code> -&gt; <code>GcStorage/upload</code></li> <li><code>IosArgs/createIosTestContexts</code><ul> <li><code>IosArgs.createXcTestContexts</code><ul> <li><code>IArgs.uploadIfNeeded</code> -&gt; <code>FileReference.uploadIfNeeded</code> -&gt; <code>GcStorage.upload</code></li> <li><code>GcStorage.uploadXCTestFile</code></li> </ul> </li> <li><code>IosArgs.createGameloopTestContexts</code><ul> <li><code>IArgs.uploadIfNeeded</code> -&gt; <code>FileReference.uploadIfNeeded</code> -&gt; <code>GcStorage.upload</code></li> </ul> </li> </ul> </li> <li><code>GcIosTestMatrix/build</code></li> <li><code>AbstractGoogleJsonClientRequest&lt;T&gt;/executeWithRetry</code></li> <li><code>IArgs/afterRunTests</code> - the rest of steps are same as for android</li> </ul> </li> </ul> </li> </ul>"},{"location":"refactor/proposal/","title":"Flank refactor proposal","text":""},{"location":"refactor/proposal/#motivation","title":"Motivation","text":"<p>The new opportunities like desktop UI or Corellium integration, requires more flexibility from the Flank. The flexibility in this case means replaceable presentation and external APIs, but also well organized and documented code base, easy to scale and navigate through.  </p>"},{"location":"refactor/proposal/#references","title":"References","text":"<ul> <li>investigation</li> </ul>"},{"location":"refactor/proposal/#architecture","title":"Architecture","text":""},{"location":"refactor/proposal/#layers-associations","title":"Layers associations","text":"<pre><code>presentation -&gt; domain\npresentation -&gt; utils\ndomain -&gt; utils\ndomain -&gt; data\nadapters -&gt; data\nadapters -&gt; external API\n</code></pre>"},{"location":"refactor/proposal/#consider-data-interfaces-as-boundaries","title":"Consider data &amp; interfaces as boundaries","text":"<p>Data &amp; interfaces in this case means communication bridge between flank domain code and external APIs. So those are boundaries from the domain perspective,  but from technical perspective those will be interfaces, type aliases, and structures. </p>"},{"location":"refactor/proposal/#package-structure","title":"Package structure","text":"<ul> <li>ftl<ul> <li>cli</li> <li>domain</li> <li>data</li> <li>adapters</li> <li>utils</li> </ul> </li> </ul>"},{"location":"refactor/proposal/#cli","title":"CLI","text":"<p>Wouldn't change a lot in comparison to current state. Should be thin as possible and aware only about domain layer API (top-level public functions and structures) and some simple utils.</p>"},{"location":"refactor/proposal/#requirements","title":"Requirements","text":"<ul> <li>Aware about<ul> <li>CLI library</li> <li>domain API - top-level public functions</li> <li>data</li> <li>adapters - for mapping results from the domain to console logs.</li> </ul> </li> <li>Not aware about<ul> <li>low-level domain functions</li> <li>helpers / libs</li> </ul> </li> <li>Consider awareness about <ul> <li>common utils (or have dedicated one).</li> </ul> </li> </ul>"},{"location":"refactor/proposal/#domain","title":"Domain","text":""},{"location":"refactor/proposal/#requirements_1","title":"Requirements","text":"<ul> <li>New package for grouping domain code.</li> <li>Domain package directly can contain only:<ul> <li>top-level public functions that represents use-cases(?).</li> <li>packages that contains low-level domain logic functions.</li> </ul> </li> <li>Top-level domain functions<ul> <li>are aware about<ul> <li>own private functions</li> <li>low-level domain functions from nested domain packages.</li> <li>flank utils</li> <li>flank internal helpers</li> </ul> </li> <li>are not aware about <ul> <li>other top-level domain function</li> <li>CLI</li> <li>external API libs</li> </ul> </li> <li>can produce flow of results</li> <li>are suspendable</li> </ul> </li> </ul>"},{"location":"refactor/proposal/#top-level-function","title":"Top-level function","text":"<p>Responsible to run domain logic directly or compose it using low-level domain functions, utils or API interfaces. For simplification, we can consider a simple common interface for all top-level functions. <pre><code>typealias UseCase&lt;A, R&gt; = suspend (A) -&gt; Flow&lt;R&gt;\n</code></pre></p>"},{"location":"refactor/proposal/#low-level","title":"Low-level","text":"<p>The domain-related functions, private or internal, useful for organizing complicated domain code into the smaller chunks, and necessary where it comes to reuse something. The composition of low-level function should be flat, because more nesting in depth, can make a code much harder to understand.</p>"},{"location":"refactor/proposal/#data","title":"Data","text":"<p>Will contain only data structures and interfaces,  which will be a bridge between domain and external APIs.  </p>"},{"location":"refactor/proposal/#requirements_2","title":"Requirements","text":"<ul> <li>New package for grouping wrappers and adapters for external APIs.</li> <li>Consider separated package in <code>ftl</code> only for interfaces and structures, shared between api adapters and domain.</li> <li>External API structures and function cannot leak to other layers.</li> </ul>"},{"location":"refactor/steps/","title":"Refactor steps","text":"<p>Steps below will be converted to a bunch of issues in epic scope.</p>"},{"location":"refactor/steps/#move-commands-to-correct-package","title":"Move commands to correct package","text":"<p>move to specified <code>package</code> the following <code>commands</code></p> <ol> <li><code>ftl.cli.firebase.test.android</code><ul> <li><code>AndroidLocalesCommand.kt</code></li> <li><code>AndroidModelsCommand.kt</code></li> <li><code>AndroidOrientationsCommand.kt</code></li> <li><code>AndroidVersionsCommand.kt</code></li> </ul> </li> <li><code>ftl.cli.firebase.test.ios</code><ul> <li><code>IosLocalesCommand.kt</code></li> <li><code>IosModelsCommand.kt</code></li> <li><code>IosOrientationsCommand.kt</code></li> <li><code>IosVersionsCommand.kt</code></li> </ul> </li> </ol>"},{"location":"refactor/steps/#extract-logic-from-cli","title":"Extract logic from CLI","text":"<ol> <li>Create package <code>ftl.domain</code> for domain layer</li> <li>For each CLI command that is marked <code>? !</code><ol> <li>Create associated domain function in domain package.</li> <li>Move the logic from command run method to domain function.</li> </ol> </li> </ol>"},{"location":"refactor/steps/#commands-to-domain-mappings","title":"Commands to domain mappings:","text":"<ul> <li><code>LoginCommand -------------------&gt; loginGoogleAccount</code></li> <li><code>AndroidLocalesDescribeCommand --&gt; describeAndroidLocales</code></li> <li><code>AndroidLocalesListCommand ------&gt; listAndroidLocales</code></li> <li><code>AndroidModelDescribeCommand ----&gt; describeAndroidModels</code></li> <li><code>AndroidModelsListCommand -------&gt; listAndroidModels</code></li> <li><code>AndroidOrientationsListCommand -&gt; listAndroidOrientations</code></li> <li><code>AndroidVersionsDescribeCommand -&gt; describeAndroidVersions</code></li> <li><code>AndroidVersionsListCommand -----&gt; listAndroidVersions</code></li> <li><code>AndroidDoctorCommand -----------&gt; runAndroidDoctor</code></li> <li><code>AndroidRunCommand --------------&gt; runAndroidTest</code></li> <li><code>AndroidTestEnvironmentCommand --&gt; describeAndroidTestEnvironment</code></li> <li><code>IosLocalesDescribeCommand ------&gt; describeIosLocales</code></li> <li><code>IosLocalesListCommand ----------&gt; listIosLocales</code></li> <li><code>IosModelDescribeCommand --------&gt; describeIosModels</code></li> <li><code>IosModelsListCommand -----------&gt; listIosModels</code></li> <li><code>IosOrientationsListCommand -----&gt; listIosOrientations</code></li> <li><code>IosVersionsDescribeCommand -----&gt; describeIosVersions</code></li> <li><code>IosVersionsListCommand ---------&gt; listIosVersions</code></li> <li><code>IosDoctorCommand ---------------&gt; runIosDoctor</code></li> <li><code>IosRunCommand ------------------&gt; runIosTest</code></li> <li><code>IosTestEnvironmentCommand ------&gt; describeIosTestEnvironment</code></li> <li><code>IPBlocksListCommand ------------&gt; listIPBlocks</code></li> <li><code>NetworkProfilesDescribeCommand -&gt; describeNetworkProfiles</code></li> <li><code>NetworkProfilesListCommand -----&gt; listNetworkProfiles</code></li> <li><code>ProvidedSoftwareListCommand ----&gt; listProvidedSoftware</code></li> <li><code>CancelCommand ------------------&gt; cancelLastRun</code></li> <li><code>RefreshCommand -----------------&gt; refreshLastRun</code></li> </ul>"},{"location":"refactor/steps/#files-in-domain-package","title":"Files in domain package","text":"<pre><code>ftl.domain\n\u251c\u2500\u2500 LoginGoogleAccount.kt\n\u251c\u2500\u2500 DescribeAndroidLocales.kt\n\u251c\u2500\u2500 ListAndroidLocales.kt\n\u251c\u2500\u2500 DescribeAndroidModels.kt\n\u251c\u2500\u2500 ListAndroidModels.kt\n\u251c\u2500\u2500 ListAndroidOrientations.kt\n\u251c\u2500\u2500 DescribeAndroidVersions.kt\n\u251c\u2500\u2500 ListAndroidVersions.kt\n\u251c\u2500\u2500 RunAndroidDoctor.kt\n\u251c\u2500\u2500 RunAndroidTest.kt\n\u251c\u2500\u2500 DescribeAndroidTestEnvironment.kt\n\u251c\u2500\u2500 DescribeIosLocales.kt\n\u251c\u2500\u2500 ListIosLocales.kt\n\u251c\u2500\u2500 DescribeIosModels.kt\n\u251c\u2500\u2500 ListIosModels.kt\n\u251c\u2500\u2500 ListIosOrientations.kt\n\u251c\u2500\u2500 DescribeIosVersions.kt\n\u251c\u2500\u2500 ListIosVersions.kt\n\u251c\u2500\u2500 RunIosDoctor.kt\n\u251c\u2500\u2500 RunIosTest.kt\n\u251c\u2500\u2500 DescribeIosTestEnvironment.kt\n\u251c\u2500\u2500 ListIPBlocks.kt\n\u251c\u2500\u2500 DescribeNetworkProfiles.kt\n\u251c\u2500\u2500 ListNetworkProfiles.kt\n\u251c\u2500\u2500 ListProvidedSoftware.kt\n\u251c\u2500\u2500 CancelLastRun.kt\n\u2514\u2500\u2500 RefreshLastRun.kt\n</code></pre>"},{"location":"refactor/steps/#use-filereference-abstraction-where-possible","title":"Use FileReference abstraction where possible","text":"<p>For convenience, all files that needs to be synchronized with the bucket, should treat as <code>FileReference</code> instead of <code>String</code>.</p>"},{"location":"refactor/steps/#commonargs","title":"CommonArgs","text":"<ul> <li><code>otherFiles</code></li> </ul>"},{"location":"refactor/steps/#androidargs","title":"AndroidArgs","text":"<ul> <li><code>appApk</code></li> <li><code>testApk</code></li> <li><code>additionalApks</code></li> <li><code>roboScript</code></li> <li><code>obbFiles</code></li> <li><code>additionalAppTestApks</code></li> </ul>"},{"location":"refactor/steps/#add-packages-for-data-layer","title":"Add packages for data layer","text":"<ol> <li>Add <code>ftl.interface</code></li> <li>Add <code>ftl.adapter</code></li> </ol>"},{"location":"refactor/steps/#create-abstraction-layer-for-external-api","title":"Create abstraction layer for external API","text":""},{"location":"refactor/steps/#important-note","title":"Important note!","text":"<p>Printing output to console is a part of presentation layer.</p>"},{"location":"refactor/steps/#authorization","title":"Authorization","text":""},{"location":"refactor/steps/#target","title":"Target","text":"<p><code>ftl/gc/UserAuth.kt</code></p>"},{"location":"refactor/steps/#interface","title":"Interface","text":"<p><code>ftl/data/AuthorizeUser.kt</code></p> <pre><code>package ftl.data\n\nobject UserAuthorization {\n    interface Request : () -&gt; UserAuthorization\n}\n</code></pre>"},{"location":"refactor/steps/#provided-software","title":"Provided software","text":""},{"location":"refactor/steps/#target_1","title":"Target","text":"<p><code>ftl/environment/ProvidedSoftwareCatalog.kt</code></p>"},{"location":"refactor/steps/#interface_1","title":"Interface","text":"<p><code>ftl/data/SoftwareCatalog.kt</code></p> <pre><code>package ftl.data\n\ndata class SoftwareCatalog(\n    val orchestratorVersion: String\n) {\n    interface Fetch : () -&gt; SoftwareCatalog\n}\n</code></pre>"},{"location":"refactor/steps/#presentation","title":"Presentation","text":"<pre><code>val softwareCatalogTable: suspend SoftwareCatalog.() -&gt; String = TODO()\n</code></pre>"},{"location":"refactor/steps/#ip-blocks-list","title":"IP Blocks List","text":""},{"location":"refactor/steps/#target_2","title":"Target","text":"<p><code>ftl/environment/ListIPBlocks.kt</code></p>"},{"location":"refactor/steps/#interface_2","title":"Interface","text":"<p><code>ftl/data/IpBlocks.kt</code></p> <pre><code>package ftl.data\n\ndata class IpBlock(\n    val block: String,\n    val form: String,\n    val addedDate: String\n) {\n\n    interface Fetch : () -&gt; List&lt;IpBlock&gt;\n}\n</code></pre>"},{"location":"refactor/steps/#presentation_1","title":"Presentation","text":"<pre><code>val ipBlocksTable: suspend List&lt;IpBlock&gt;.() -&gt; String = TODO()\n</code></pre>"},{"location":"refactor/steps/#network-profiles","title":"Network profiles","text":""},{"location":"refactor/steps/#target_3","title":"Target","text":"<p><code>ftl/environment/NetworkProfileDescription.kt</code></p>"},{"location":"refactor/steps/#interface_3","title":"Interface","text":"<p><code>ftl/data/NetworkProfile.kt</code></p> <pre><code>package ftl.data\n\ndata class NetworkProfile(\n    val id: String,\n    val downRule: Rule,\n    val upRule: Rule\n) {\n    data class Rule(\n        val bandwidth: String,\n        val delay: String,\n        val packetLossRatio: Float,\n        val packetDuplicationRatio: Float,\n        val burst: Float\n    )\n\n    interface Fetch : () -&gt; List&lt;NetworkProfile&gt;\n}\n</code></pre>"},{"location":"refactor/steps/#presentation_2","title":"Presentation","text":"<pre><code>val networkProfileDescription: suspend NetworkProfile.() -&gt; String = TODO()\nval networkProfileList: suspend List&lt;NetworkProfile&gt;.() -&gt; String = TODO()\n</code></pre>"},{"location":"refactor/steps/#locales","title":"Locales","text":""},{"location":"refactor/steps/#target_4","title":"Target","text":"<ul> <li><code>AndroidLocalesDescribeCommand</code> -&gt; <code>AndroidCatalog/getLocaleDescription</code> -&gt; <code>AndroidCatalog/getLocales</code></li> <li><code>AndroidLocalesListCommand</code> -&gt; <code>AndroidCatalog/localesAsTable</code> -&gt; <code>AndroidCatalog/getLocales</code></li> <li><code>IosLocalesDescribeCommand</code> -&gt; <code>IosCatalog/getLocaleDescription</code> -&gt; <code>IosCatalog/getLocales</code></li> <li><code>IosLocalesListCommand</code> -&gt; <code>IosCatalog/localesAsTable</code> -&gt; <code>IosCatalog/iosDeviceCatalog</code></li> </ul>"},{"location":"refactor/steps/#interface_4","title":"Interface","text":"<p><code>ftl/data/Locales.kt</code></p> <pre><code>package ftl.data\n\ndata class Locale(\n    val id: String,\n    val name: String,\n    val region: String,\n    val tags: List&lt;String&gt;,\n) {\n\n    data class Identity(\n        val projectId: String,\n        val platform: String,\n    )\n\n    interface Fetch : (Identity) -&gt; List&lt;Locale&gt;\n}\n</code></pre>"},{"location":"refactor/steps/#presentation_3","title":"Presentation","text":"<pre><code>val localeDescription: suspend Locale.() -&gt; String = TODO()\nval localeTable: suspend List&lt;Locale&gt;.() -&gt; String = TODO()\n</code></pre>"},{"location":"refactor/steps/#device-models","title":"Device models","text":""},{"location":"refactor/steps/#target_5","title":"Target","text":"<ul> <li><code>AndroidModelDescribeCommand</code> -&gt; <code>AndroidCatalog/describeModel</code> -&gt; <code>AndroidCatalog/getModels</code></li> <li><code>AndroidModelsListCommand</code> -&gt; <code>AndroidCatalog/devicesCatalogAsTable</code> -&gt; <code>AndroidCatalog/getModels</code></li> <li><code>IosModelDescribeCommand</code> -&gt; <code>IosCatalog/describeModel</code> -&gt; <code>IosCatalog/getModels</code></li> <li><code>IosModelsListCommand</code> -&gt; <code>IosCatalog/devicesCatalogAsTable</code> -&gt; <code>IosCatalog/getModels</code></li> <li><code>AndroidArgs/validate</code> -&gt; <code>AndroidArgs/assertDevicesSupported</code><ul> <li><code>AndroidCatalog/supportedDeviceConfig</code> -&gt; <code>AndroidCatalog/deviceCatalog(projectId).models</code></li> <li><code>AndroidCatalog/androidModelIds</code> -&gt; <code>AndroidCatalog/deviceCatalog(projectId).models</code></li> <li><code>AndroidCatalog/getSupportedVersionId</code> -&gt; <code>AndroidCatalog/deviceCatalog(projectId).models</code></li> </ul> </li> <li><code>IosArgs/validateRefresh</code> -&gt; <code>IosArgs/assertDevicesSupported</code> -&gt; <code>IosCatalog/iosDeviceCatalog(projectId).models</code></li> </ul>"},{"location":"refactor/steps/#interface_5","title":"Interface","text":"<p><code>ftl/data/DeviceModels.kt</code></p> <pre><code>package ftl.data\n\nobject DeviceModel {\n\n    data class Android(\n        val id: String,\n        val name: String,\n        val tags: List&lt;String&gt;,\n        val screenX: Int,\n        val screenY: Int,\n        val formFactor: String,\n        val screenDensity: Int,\n        val supportedVersionIds: List&lt;String&gt;,\n        val form: String,\n        val brand: String,\n        val codename: String,\n        val manufacturer: String,\n        val thumbnailUrl: String,\n        val supportedAbis: List&lt;String&gt;,\n        val lowFpsVideoRecording: Boolean,\n    ) {\n\n        interface Fetch : (projectId: String) -&gt; List&lt;Android&gt;\n    }\n\n    data class Ios(\n        val id: String,\n        val name: String,\n        val tags: List&lt;String&gt;,\n        val screenX: Int,\n        val screenY: Int,\n        val formFactor: String,\n        val screenDensity: Int,\n        val supportedVersionIds: List&lt;String&gt;,\n        val deviceCapabilities: List&lt;String&gt;,\n    ) {\n\n        interface Fetch : (projectId: String) -&gt; List&lt;Ios&gt;\n    }\n}\n</code></pre>"},{"location":"refactor/steps/#presentation_4","title":"Presentation","text":"<pre><code>val androidModelDescription: suspend DeviceModel.Android.() -&gt; String = TODO()\nval androidModelsTable: suspend List&lt;DeviceModel.Android&gt;.() -&gt; String = TODO()\nval iosModelDescription: suspend DeviceModel.Ios.() -&gt; String = TODO()\nval iosModelsTable: suspend List&lt;DeviceModel.Ios&gt;.() -&gt; String = TODO()\n</code></pre>"},{"location":"refactor/steps/#orientation","title":"Orientation","text":""},{"location":"refactor/steps/#target_6","title":"Target","text":"<ul> <li><code>AndroidOrientationsListCommand</code> -&gt; <code>AndroidCatalog/supportedOrientationsAsTable</code> -&gt; <code>AndroidCatalog/deviceCatalog</code></li> <li><code>IosOrientationsListCommand</code> -&gt; <code>IosCatalog/supportedOrientationsAsTable</code> -&gt; <code>IosCatalog/iosDeviceCatalog</code></li> </ul>"},{"location":"refactor/steps/#interface_6","title":"Interface","text":"<p><code>ftl/data/Orientation.kt</code></p> <pre><code>package ftl.data\n\ndata class Orientation(\n    val id: String,\n    val name: String,\n    val tags: String,\n) {\n    interface Fetch : (projectId: String, platform: String) -&gt; List&lt;Orientation&gt;\n}\n</code></pre>"},{"location":"refactor/steps/#presentation_5","title":"Presentation","text":"<pre><code>val orientationsTable: suspend List&lt;Orientation&gt;.() -&gt; String = TODO()\n</code></pre>"},{"location":"refactor/steps/#os-version","title":"OS Version","text":""},{"location":"refactor/steps/#target_7","title":"Target","text":"<ul> <li><code>AndroidVersionsListCommand</code> -&gt; <code>AndroidCatalog/supportedVersionsAsTable</code> -&gt; <code>AndroidCatalog/getVersionsList</code></li> <li><code>IosVersionsListCommand</code> -&gt; <code>IosCatalog/softwareVersionsAsTable</code> -&gt; <code>IosCatalog/getVersionsList</code></li> <li><code>AndroidArgs/validate</code> -&gt; <code>AndroidArgs/assertDevicesSupported</code> -&gt; <code>AndroidCatalog/androidVersionIds</code> -&gt; <code>AndroidCatalog/deviceCatalog(projectId).versions</code></li> </ul>"},{"location":"refactor/steps/#interface_7","title":"Interface","text":"<p><code>ftl/data/OsVersion.kt</code></p> <pre><code>package ftl.data\n\nobject OsVersion {\n\n    data class Android(\n        val apiLevel: Int,\n        val codeName: String,\n        val distribution: Distribution,\n        val id: String,\n        val releaseDate: Date,\n        val tags: List&lt;String&gt;,\n        val versionString: String,\n    ) {\n        interface Fetch : (projectId: String) -&gt; List&lt;Android&gt;\n    }\n\n    data class Ios(\n        val id: String,\n        val majorVersion: Int,\n        val minorVersion: Int,\n        val supportedXcodeVersionIds: List&lt;String&gt;,\n        val tags: List&lt;String&gt;,\n    ) {\n        interface Fetch : (projectId: String) -&gt; List&lt;Ios&gt;\n    }\n}\n</code></pre>"},{"location":"refactor/steps/#presentation_6","title":"Presentation","text":"<pre><code>val androidOsVersionDescription: suspend OsVersion.Android.() -&gt; String = TODO()\nval androidOsVersionsTable: suspend List&lt;OsVersion.Android&gt;.() -&gt; String = TODO()\nval iosOsVersionDescription: suspend OsVersion.Ios.() -&gt; String = TODO()\nval iosOsVersionsTable: suspend List&lt;OsVersion.Ios&gt;.() -&gt; String = TODO()\n</code></pre>"},{"location":"refactor/steps/#file-reference","title":"File reference","text":""},{"location":"refactor/steps/#target_8","title":"Target","text":"<ul> <li><code>FileReference</code></li> </ul>"},{"location":"refactor/steps/#interface_8","title":"Interface","text":"<p><code>ftl/data/FileReference.kt</code></p> <pre><code>data class FileReference(\n    val local: String = \"\",\n    val remote: String = \"\"\n) {\n    interface Exist : (FileReference) -&gt; Boolean\n    interface Upload : (FileReference) -&gt; FileReference\n    interface Download : (FileReference) -&gt; FileReference\n}\n</code></pre>"},{"location":"refactor/steps/#remote-storage-aka-gcstorage","title":"Remote storage aka GcStorage","text":""},{"location":"refactor/steps/#target_9","title":"Target","text":"<ul> <li><code>IArgs/checkResultsDirUnique</code></li> </ul>"},{"location":"refactor/steps/#interface_9","title":"Interface","text":"<p><code>ftl/data/RemoteStorage.kt</code></p> <pre><code>package ftl.data\n\nobject RemoteStorage {\n\n    data class Dir(\n        val bucket: String,\n        val path: String\n    )\n\n    class Data(\n        val path: String,\n        val bytes: ByteArray? = null // Use, when file under the given path doesn't exist.\n    )\n\n    interface Exist : (Dir) -&gt; Boolean\n\n    interface Upload : (Dir, Data) -&gt; Unit\n}\n</code></pre>"},{"location":"refactor/steps/#test-matrix-results-cancel-refresh","title":"Test matrix results, cancel &amp; refresh","text":""},{"location":"refactor/steps/#target_10","title":"Target","text":"<ul> <li><code>SavedMatrix</code></li> <li><code>TestOutcome</code></li> <li><code>TestSuiteOverviewData</code></li> <li><code>MatrixMap</code></li> <li><code>CancelCommand</code> -&gt; <code>cancelLastRun</code> -&gt; <code>cancelMatrices</code> -&gt; <code>GcTestMatrix/cancel</code></li> <li><code>RefreshCommand</code> -&gt; <code>refreshLastRun</code><ul> <li><code>refreshMatrices</code><ul> <li><code>GcTestMatrix/refresh</code></li> <li><code>SavedMatrix/updateWithMatrix</code> -&gt; <code>SavedMatrix/updatedSavedMatrix</code> -&gt; <code>TestMatrix/fetchTestOutcomeContext</code></li> </ul> </li> </ul> </li> <li><code>newTestRun</code><ul> <li><code>pollMatrices</code> -&gt; <code>matrixChangesFlow</code> -&gt; <code>GcTestMatrix/refresh</code></li> <li><code>Iterable&lt;TestMatrix&gt;/updateMatrixMap</code> -&gt; <code>SavedMatrix/updateWithMatrix</code> -&gt; <code>TestMatrix/fetchTestOutcomeContext</code></li> <li><code>ReportManager/generate</code><ul> <li><code>ReportManager/parseTestSuite</code><ul> <li><code>refreshMatricesAndGetExecutions</code> -&gt; <code>refreshTestMatrices</code> -&gt; <code>GcTestMatrix/refresh</code></li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"refactor/steps/#interface_10","title":"Interface","text":"<p><code>ftl/data/TestMatrix.kt</code></p> <pre><code>object TestMatrix {\n\n    data class Result(\n        val runPath: String,\n        val map: Map&lt;String, Data&gt;,\n    )\n\n    data class Data(\n        val matrixId: String = \"\",\n        val state: String = \"\",\n        val gcsPath: String = \"\",\n        val webLink: String = \"\",\n        val downloaded: Boolean = false,\n        val billableMinutes: BillableMinutes = BillableMinutes(),\n        val clientDetails: Map&lt;String, String&gt;? = null,\n        val gcsPathWithoutRootBucket: String = \"\",\n        val gcsRootBucket: String = \"\",\n        val axes: List&lt;Outcome&gt; = emptyList()\n    )\n\n    data class Outcome(\n        val device: String = \"\",\n        val outcome: String = \"\",\n        val details: String = \"\",\n        val suiteOverview: SuiteOverview = SuiteOverview()\n    )\n\n    data class SuiteOverview(\n        val total: Int = 0,\n        val errors: Int = 0,\n        val failures: Int = 0,\n        val flakes: Int = 0,\n        val skipped: Int = 0,\n        val elapsedTime: Double = 0.0,\n        val overheadTime: Double = 0.0\n    )\n\n    data class BillableMinutes(\n        val virtual: Long = 0,\n        val physical: Long = 0\n    )\n\n    data class Summary(\n        val billableMinutes: BillableMinutes,\n        val axes: List&lt;Outcome&gt;,\n    ) {\n        data class Identity(\n            val projectId: String,\n            val historyId: String,\n            val executionId: String,\n        )\n\n        interface Fetch : (Identity) -&gt; Summary\n    }\n\n    data class Identity(\n        val matrixId: String,\n        val projectId: String,\n    )\n\n    interface Cancel : (Identity) -&gt; Unit\n    interface Refresh : (Identity) -&gt; Data\n}\n</code></pre>"},{"location":"refactor/steps/#presentation_7","title":"Presentation","text":"<pre><code>TODO()\n</code></pre>"},{"location":"refactor/steps/#execute-android-tests-matrix","title":"Execute Android tests matrix","text":""},{"location":"refactor/steps/#target_11","title":"Target","text":"<ul> <li><code>AndroidRunCommand</code> -&gt; <code>AndroidArgs/runAndroidTests</code> -&gt; <code>GcAndroidTestMatrix/build</code></li> <li><code>AndroidTestConfig</code></li> </ul>"},{"location":"refactor/steps/#interface_11","title":"Interface","text":"<p><code>ftl/data/AndroidTestMatrix.kt</code></p> <pre><code>package ftl.data\n\nobject AndroidTestMatrix {\n\n    data class Config(\n        // args\n        val clientDetails: Map&lt;String, String&gt;?,\n        val resultsBucket: String,\n        val autoGoogleLogin: Boolean,\n        val networkProfile: String?,\n        val directoriesToPull: List&lt;String&gt;,\n        val obbNames: List&lt;String&gt;,\n        val environmentVariables: Map&lt;String, String&gt;,\n        val autograntPermissions: Boolean,\n        val testTimeout: String,\n        val performanceMetrics: Boolean,\n        val recordVideo: Boolean,\n        val flakyTestAttempts: Int,\n        val failFast: Boolean,\n        val project: String,\n        val resultsHistoryName: String?,\n\n        // build\n        val otherFiles: Map&lt;String, String&gt;,\n        val runGcsPath: String,\n        val devices: List&lt;Device&gt;,\n        val additionalApkGcsPaths: List&lt;String&gt;,\n        val obbFiles: Map&lt;String, String&gt;,\n    )\n\n    sealed class Type {\n        data class Instrumentation(\n            val appApkGcsPath: String,\n            val testApkGcsPath: String,\n            val testRunnerClass: String?,\n            val orchestratorOption: String?,\n            // sharding\n            val disableSharding: Boolean,\n            val testShards: ShardChunks,\n            val numUniformShards: Int?,\n            val keepTestTargetsEmpty: Boolean,\n            val environmentVariables: Map&lt;String, String&gt; = emptyMap(),\n            val testTargetsForShard: ShardChunks\n        ) : Type()\n\n        data class Robo(\n            val appApkGcsPath: String,\n            val flankRoboDirectives: List&lt;FlankRoboDirective&gt;?,\n            val roboScriptGcsPath: String?\n        ) : Type()\n\n        data class GameLoop(\n            val appApkGcsPath: String,\n            val testRunnerClass: String?,\n            val scenarioNumbers: List&lt;String&gt;,\n            val scenarioLabels: List&lt;String&gt;\n        ) : Type()\n    }\n\n    interface Execute : (Config, Type) -&gt; TestMatrix.Result\n}\n</code></pre>"},{"location":"refactor/steps/#presentation_8","title":"Presentation","text":"<pre><code>TODO()\n</code></pre>"},{"location":"refactor/steps/#execute-ios-tests-matrix","title":"Execute Ios tests matrix","text":""},{"location":"refactor/steps/#target_12","title":"Target","text":"<ul> <li><code>IosRunCommand</code> -&gt; <code>IosArgs/runIosTests</code> -&gt; <code>GcIosTestMatrix/build</code></li> <li><code>IosTestContext</code></li> </ul>"},{"location":"refactor/steps/#interface_12","title":"Interface","text":"<p><code>ftl/data/IosTestMatrix.kt</code></p> <pre><code>package ftl.data\n\nobject IosTestMatrix {\n\n    data class Config(\n        // args\n        val clientDetails: Map&lt;String, String&gt;?,\n        val networkProfile: String?,\n        val directoriesToPull: List&lt;String&gt;,\n        val testTimeout: String,\n        val recordVideo: Boolean,\n        val flakyTestAttempts: Int,\n        val failFast: Boolean,\n        val project: String,\n        val resultsHistoryName: String?,\n\n        // build\n        val devices: List&lt;Device&gt;,\n        val otherFiles: Map&lt;String, String&gt;,\n        val additionalIpasGcsPaths: List&lt;String&gt;,\n    )\n\n    sealed class Type {\n        data class XcTest(\n            val xcTestGcsPath: String,\n            val xcTestRunFileGcsPath: String,\n            val xcodeVersion: String,\n            val testSpecialEntitlements: Boolean,\n            val matrixGcsPath: String,\n        )\n\n        data class GameLoop(\n            val appGcsPath: String,\n            val scenarios: List&lt;Int&gt;,\n            val matrixGcsPath: String,\n        )\n    }\n\n    interface Execute : (Config, Type) -&gt; TestMatrix.Result\n}\n</code></pre>"},{"location":"refactor/steps/#presentation_9","title":"Presentation","text":"<pre><code>TODO()\n</code></pre>"},{"location":"refactor/steps/#junit-results","title":"JUnit results","text":""},{"location":"refactor/steps/#target_13","title":"Target","text":"<ul> <li><code>ReportManager/generate</code> -&gt; <code>ReportManager/parseTestSuite</code><ul> <li><code>ReportManager/processXmlFromFile</code></li> <li><code>refreshMatricesAndGetExecutions</code> -&gt; <code>List&lt;TestExecution&gt;/createJUnitTestResult</code></li> </ul> </li> </ul>"},{"location":"refactor/steps/#interface_13","title":"Interface","text":"<p><code>ftl/data/JUnitTestResult.kt</code></p> <pre><code>package ftl.data\n\nobject JUnitTest {\n\n    @JacksonXmlRootElement(localName = \"testsuites\")\n    data class Result(\n        @JsonInclude(JsonInclude.Include.NON_EMPTY)\n        @JacksonXmlProperty(localName = \"testsuite\")\n        var testsuites: MutableList&lt;Suite&gt;? = null\n    ) {\n        data class ApiIdentity(\n            val projectId: String,\n            val matrixIds: List&lt;String&gt;\n        )\n        interface GenerateFromApi : (ApiIdentity) -&gt; Result\n\n        interface ParseFromFiles : (File) -&gt; Result\n    }\n\n    data class Suite(\n        @JacksonXmlProperty(isAttribute = true)\n        var name: String,\n\n        @JacksonXmlProperty(isAttribute = true)\n        var tests: String, // Int\n\n        @JacksonXmlProperty(isAttribute = true)\n        var failures: String, // Int\n\n        @JacksonXmlProperty(isAttribute = true)\n        var flakes: Int? = null,\n\n        @JacksonXmlProperty(isAttribute = true)\n        var errors: String, // Int\n\n        @JsonInclude(JsonInclude.Include.NON_NULL)\n        @JacksonXmlProperty(isAttribute = true)\n        var skipped: String?, // Int. Android only\n\n        @JacksonXmlProperty(isAttribute = true)\n        var time: String, // Double\n\n        @JsonInclude(JsonInclude.Include.NON_NULL)\n        @JacksonXmlProperty(isAttribute = true)\n        val timestamp: String?, // String. Android only\n\n        @JacksonXmlProperty(isAttribute = true)\n        val hostname: String? = \"localhost\", // String.\n\n        @JsonInclude(JsonInclude.Include.NON_NULL)\n        @JacksonXmlProperty(isAttribute = true)\n        val testLabExecutionId: String? = null, // String.\n\n        @JacksonXmlProperty(localName = \"testcase\")\n        var testcases: MutableCollection&lt;Case&gt;?,\n\n        // not used\n        @JsonInclude(JsonInclude.Include.NON_NULL)\n        val properties: Any? = null, // &lt;properties /&gt;\n\n        @JsonInclude(JsonInclude.Include.NON_NULL)\n        @JacksonXmlProperty(localName = \"system-out\")\n        val systemOut: Any? = null, // &lt;system-out /&gt;\n\n        @JsonInclude(JsonInclude.Include.NON_NULL)\n        @JacksonXmlProperty(localName = \"system-err\")\n        val systemErr: Any? = null // &lt;system-err /&gt;\n    )\n\n    data class Case(\n        // name, classname, and time are always present except for empty test cases &lt;testcase/&gt;\n        @JacksonXmlProperty(isAttribute = true)\n        val name: String?,\n\n        @JacksonXmlProperty(isAttribute = true)\n        val classname: String?,\n\n        @JacksonXmlProperty(isAttribute = true)\n        val time: String?,\n\n        // iOS contains multiple failures for a single test.\n        // JUnit XML allows arbitrary amounts of failure/error tags\n        @JsonInclude(JsonInclude.Include.NON_NULL)\n        @JacksonXmlProperty(localName = \"failure\")\n        val failures: List&lt;String&gt;? = null,\n\n        @JsonInclude(JsonInclude.Include.NON_NULL)\n        @JacksonXmlProperty(localName = \"error\")\n        val errors: List&lt;String&gt;? = null,\n\n        @JsonInclude(JsonInclude.Include.CUSTOM, valueFilter = FilterNotNull::class)\n        val skipped: String? = \"absent\" // used by FilterNotNull to filter out absent `skipped` values\n    ) {\n\n        // Consider to move all properties to constructor if will doesn't conflict with parser\n\n        @JsonInclude(JsonInclude.Include.NON_NULL)\n        var webLink: String? = null\n\n        @JacksonXmlProperty(isAttribute = true)\n        var flaky: Boolean? = null // use null instead of false\n    }\n\n    @Suppress(\"UnusedPrivateClass\")\n    private class FilterNotNull {\n        override fun equals(other: Any?): Boolean {\n            // other is null     = present\n            // other is not null = absent (default value)\n            return other != null\n        }\n\n        override fun hashCode(): Int {\n            return javaClass.hashCode()\n        }\n    }\n}\n</code></pre>"},{"location":"refactor/steps/#performance-metrics","title":"Performance Metrics","text":""},{"location":"refactor/steps/#target_14","title":"Target","text":"<p><code>GcToolResults/getPerformanceMetric</code></p>"},{"location":"refactor/steps/#interface_14","title":"Interface","text":"<p><code>ftl/data/PerfMetrics.kt</code></p> <pre><code>package ftl.data\n\nobject PerfMetrics {\n\n    // based on com.google.api.services.toolresults.model.PerfMetricsSummary\n    data class Summary(\n        val appStartTime: AppStartTime? = null,\n        val graphicsStats: GraphicsStats? = null,\n        val perfEnvironment: PerfEnvironment? = null,\n        val perfMetrics: List&lt;String&gt;? = null,\n        val executionId: String? = null,\n        val historyId: String? = null,\n        val projectId: String? = null,\n        val stepId: String? = null,\n    )\n\n    data class GraphicsStats(\n        val buckets: List&lt;Bucket&gt;? = null,\n        val highInputLatencyCount: Long? = null,\n        val jankyFrames: Long? = null,\n        val missedVsyncCount: Long? = null,\n        val p50Millis: Long? = null,\n        val p90Millis: Long? = null,\n        val p95Millis: Long? = null,\n        val p99Millis: Long? = null,\n        val slowBitmapUploadCount: Long? = null,\n        val slowDrawCount: Long? = null,\n        val slowUiThreadCount: Long? = null,\n        val totalFrames: Long? = null,\n    ) {\n        data class Bucket(\n            val frameCount: Long?,\n            val renderMillis: Long?,\n        )\n    }\n\n    data class AppStartTime(\n        val fullyDrawnTime: Duration? = null,\n        val initialDisplayTime: Duration? = null,\n    )\n\n    data class PerfEnvironment(\n        val cpuInfo: CPUInfo? = null,\n        val memoryInfo: MemoryInfo? = null,\n    )\n\n    data class CPUInfo(\n        val cpuProcessor: String? = null,\n        val cpuSpeedInGhz: Float? = null,\n        val numberOfCores: Int? = null,\n    )\n\n    data class MemoryInfo(\n        val memoryCapInKibibyte: Long? = null,\n        val memoryTotalInKibibyte: Long? = null,\n    )\n\n    data class Identity(\n        val executionId: String,\n        val historyId: String,\n        val projectId: String,\n        val stepId: String,\n    )\n\n    interface Fetch : (Identity) -&gt; Summary\n}\n</code></pre>"},{"location":"refactor/steps/#fetching-artifacts","title":"Fetching Artifacts","text":""},{"location":"refactor/steps/#target_15","title":"Target","text":"<ul> <li><code>FetchArtifacts.kt</code></li> </ul>"},{"location":"refactor/steps/#interface_15","title":"Interface","text":"<p><code>ftl/data/PerfMetrics.kt</code></p> <pre><code>package ftl.data\n\nobject Artifacts {\n\n    data class Identity(\n        val gcsPathWithoutRootBucket: String,\n        val gcsRootBucket: String,\n        val regex: List&lt;Regex&gt;,\n        val blobPath: String,\n        val downloadPath: DownloadPath,\n    )\n\n    data class DownloadPath(\n        val localResultDir: String,\n        val useLocalResultDir: Boolean,\n        val keepFilePath: Boolean,\n    )\n\n    interface Fetch: (Identity) -&gt; List&lt;String&gt;\n}\n</code></pre>"},{"location":"refactor/flank_run/flank_run/","title":"Flank run refactor","text":""},{"location":"refactor/flank_run/flank_run/#references","title":"References","text":"<ul> <li>https://github.com/Flank/flank/issues/1317 </li> </ul>"},{"location":"refactor/flank_run/flank_run/#insights","title":"Insights","text":""},{"location":"refactor/flank_run/flank_run/#fix-import-dependencies","title":"Fix import dependencies","text":"<p>Only the cli commands can be aware of run package. So any code inside the run package which is imported somewhere else then cli,  must be reorganized and moved outside the run package.</p>"},{"location":"refactor/flank_run/flank_run_refactor_sdd/","title":"Flank run refactor [Not complete]","text":""},{"location":"refactor/flank_run/flank_run_refactor_sdd/#references","title":"References","text":"<ul> <li><code>https://github.com/Flank/flank/issues/1317</code></li> </ul>"},{"location":"refactor/flank_run/flank_run_refactor_sdd/#motivation","title":"Motivation","text":"<p>Flank run is getting bigger over the time. Currently, the amount of code related to test run is large, so it could be hard to understand and keep in mind the whole process. To make the work more convenient, faster and scalable, we should re-think and reorganize the code between packages and files.</p>"},{"location":"refactor/flank_run/flank_run_refactor_sdd/#goals","title":"Goals","text":"<ul> <li><code>All logic related to flank run grouped in one root package</code></li> <li><code>Package structure flat as possible.</code></li> <li><code>Flank run process simplified to sequence of synchronous atomic steps.</code></li> <li><code>Packages and code are easy to identify as steps.</code></li> </ul>"},{"location":"refactor/flank_run/flank_run_refactor_sdd/#non-goals","title":"Non-Goals","text":"<ul> <li><code>Refactor code related to other commands than flank run</code></li> </ul>"},{"location":"refactor/flank_run/flank_run_refactor_sdd/#design","title":"Design","text":"<p>Explain and diagram the technical design</p> <p>Identify risks and edge cases</p>"},{"location":"refactor/flank_run/flank_run_refactor_sdd/#api","title":"API","text":"<p>What will the proposed API look like?</p>"},{"location":"refactor/flank_run/flank_run_refactor_sdd/#results","title":"Results","text":"<p>What was the outcome of the project?</p>"},{"location":"refactor/flank_run/flank_run_refactor_sdd/#dependencies","title":"Dependencies","text":"<p>What is the project blocked on?</p> <p>What will be impacted by the project?</p>"},{"location":"refactor/flank_run/flank_run_refactor_sdd/#files","title":"Files","text":""},{"location":"refactor/flank_run/flank_run_refactor_sdd/#ftlrun","title":"ftl/run","text":"<pre><code>ftl/run/\n\u251c\u2500\u2500 CancelLastRun.kt\n\u251c\u2500\u2500 DumpShards.kt\n\u251c\u2500\u2500 NewTestRun.kt\n\u251c\u2500\u2500 RefreshLastRun.kt\n\u251c\u2500\u2500 common\n\u2502   \u251c\u2500\u2500 FetchArtifacts.kt\n\u2502   \u251c\u2500\u2500 GetLastArgs.kt\n\u2502   \u251c\u2500\u2500 GetLastGcsPath.kt\n\u2502   \u251c\u2500\u2500 GetLastMatrices.kt\n\u2502   \u251c\u2500\u2500 PollMatrices.kt\n\u2502   \u251c\u2500\u2500 PrettyPrint.kt\n\u2502   \u2514\u2500\u2500 UpdateMatrixFile.kt\n\u251c\u2500\u2500 exception\n\u2502   \u251c\u2500\u2500 ExceptionHandler.kt\n\u2502   \u251c\u2500\u2500 FlankException.kt\n\u2502   \u2514\u2500\u2500 FlankExitCodes.kt\n\u251c\u2500\u2500 model\n\u2502   \u251c\u2500\u2500 AndroidMatrixTestShards.kt\n\u2502   \u251c\u2500\u2500 AndroidTestContext.kt\n\u2502   \u251c\u2500\u2500 AndroidTestShards.kt\n\u2502   \u251c\u2500\u2500 IosTestContext.kt\n\u2502   \u2514\u2500\u2500 TestResult.kt\n\u251c\u2500\u2500 platform\n\u2502   \u251c\u2500\u2500 RunAndroidTests.kt\n\u2502   \u251c\u2500\u2500 RunIosTests.kt\n\u2502   \u251c\u2500\u2500 android\n\u2502   \u2502   \u251c\u2500\u2500 AndroidTestConfig.kt\n\u2502   \u2502   \u251c\u2500\u2500 CreateAndroidLoopConfig.kt\n\u2502   \u2502   \u251c\u2500\u2500 CreateAndroidTestConfig.kt\n\u2502   \u2502   \u251c\u2500\u2500 CreateAndroidTestContext.kt\n\u2502   \u2502   \u251c\u2500\u2500 CreateInstrumentationConfig.kt\n\u2502   \u2502   \u251c\u2500\u2500 CreateRoboConfig.kt\n\u2502   \u2502   \u251c\u2500\u2500 GetAndroidMatrixShards.kt\n\u2502   \u2502   \u251c\u2500\u2500 ResolveApks.kt\n\u2502   \u2502   \u251c\u2500\u2500 UploadApks.kt\n\u2502   \u2502   \u2514\u2500\u2500 UploadOtherFiles.kt\n\u2502   \u251c\u2500\u2500 common\n\u2502   \u2502   \u251c\u2500\u2500 AfterRunTests.kt\n\u2502   \u2502   \u251c\u2500\u2500 BeforeRunMessage.kt\n\u2502   \u2502   \u2514\u2500\u2500 BeforeRunTests.kt\n\u2502   \u2514\u2500\u2500 ios\n\u2502       \u251c\u2500\u2500 CreateGameloopTestContext.kt\n\u2502       \u251c\u2500\u2500 CreateIosTestContext.kt\n\u2502       \u2514\u2500\u2500 CreateXcTestContext.kt\n\u2514\u2500\u2500 status\n    \u251c\u2500\u2500 ExecutionStatus.kt\n    \u251c\u2500\u2500 ExecutionStatusListPrinter.kt\n    \u251c\u2500\u2500 ExecutionStatusPrinter.kt\n    \u251c\u2500\u2500 OutputStyle.kt\n    \u2514\u2500\u2500 TestMatrixStatusPrinter.kt\n</code></pre>"},{"location":"refactor/flank_run/flank_run_refactor_sdd/#dependencies_1","title":"Dependencies","text":"<ul> <li><code>ftl/args/AndroidArgs.kt</code></li> <li><code>ftl/args/AndroidArgsCompanion.kt</code></li> <li><code>ftl/args/ArgsHelper.kt</code></li> <li><code>ftl/args/CalculateShardsResult.kt</code></li> <li><code>ftl/args/FlankRoboDirective.kt</code></li> <li><code>ftl/args/IArgs.kt</code></li> <li><code>ftl/args/IgnoredTestCases.kt</code></li> <li><code>ftl/args/IosArgs.kt</code></li> <li><code>ftl/args/IosArgsCompanion.kt</code></li> <li><code>ftl/args/ShardChunks.kt</code></li> <li><code>ftl/args/ValidateAndroidArgs.kt</code></li> <li><code>ftl/args/ValidateIosArgs.kt</code></li> <li><code>ftl/args/yml/AppTestPair.kt</code></li> <li><code>ftl/config/FtlConstants.kt</code></li> <li><code>ftl/filter/TestFilters.kt</code></li> <li><code>ftl/gc/GcAndroidDevice.kt</code></li> <li><code>ftl/gc/GcAndroidTestMatrix.kt</code></li> <li><code>ftl/gc/GcIosMatrix.kt</code></li> <li><code>ftl/gc/GcIosTestMatrix.kt</code></li> <li><code>ftl/gc/GcStorage.kt</code></li> <li><code>ftl/gc/GcTesting.kt</code></li> <li><code>ftl/gc/GcTestMatrix.kt</code></li> <li><code>ftl/gc/GcToolResults.kt</code></li> <li><code>ftl/http/ExecuteWithRetry.kt</code></li> <li><code>ftl/ios/xctest/XcTestData.kt</code></li> <li><code>ftl/ios/xctest/XcTestRunFlow.kt</code></li> <li><code>ftl/ios/xctest/common/Util.kt</code></li> <li><code>ftl/json/MatrixMap.kt</code></li> <li><code>ftl/json/SavedMatrix.kt</code></li> <li><code>ftl/reports/output/OutputReport.kt</code></li> <li><code>ftl/reports/output/OutputReportLoggers.kt</code></li> <li><code>ftl/reports/util/ReportManager.kt</code></li> <li><code>ftl/shard/Chunk.kt</code></li> <li><code>ftl/shard/Shard.kt</code></li> <li><code>ftl/shard/TestCasesCreator.kt</code></li> <li><code>ftl/util/Artifacts.kt</code></li> <li><code>ftl/util/FileReference.kt</code></li> <li><code>ftl/util/FlankTestMethod.kt</code></li> <li><code>ftl/util/FlowExt.kt</code></li> <li><code>ftl/util/MatrixState.kt</code></li> <li><code>ftl/util/ObfuscationGson.kt</code></li> <li><code>ftl/util/ShardCounter.kt</code></li> <li><code>ftl/util/StopWatch.kt</code></li> <li><code>ftl/util/TestMatrixExtension.kt</code></li> </ul>"},{"location":"refactor/flank_run/flank_run_refactor_sdd/#testing","title":"Testing","text":"<p>How will the project be tested?</p>"},{"location":"refactor/flank_run/flank_run_refactor_sdd/#alternatives-considered-optional","title":"Alternatives Considered [optional]","text":"<p>Summarize alternative designs (pros &amp; cons)</p>"},{"location":"refactor/flank_run/flank_run_refactor_sdd/#timeline-optional-for-regular-tigers","title":"Timeline [optional for regular tigers]","text":"<p>Document milestones and deadlines.</p> <p>DONE:</p> <p>-</p> <p>NEXT:</p> <p>-</p>"}]}